{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\git_local_repository\\\\yangoos57\\\\ML\\\\[inria] scikit-learn course'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set and get Hyperparameters in scikit-learn\n",
    "\n",
    "We recall that hyperparameters refer to the parameter that will control the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_df = pd.read_csv('data/phpMawTba.csv').drop(columns='education-num')\n",
    "\n",
    "target = adult_df['class']\n",
    "data = adult_df[['age','capital-gain','capital-loss','hours-per-week']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = Pipeline(steps=[('preprocessor',StandardScaler()),('classifier',LogisticRegression())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79557785, 0.80049135, 0.79965192, 0.79873055, 0.80436118])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_results = cross_val_score(model,data,target)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Linear model에서 C라는 parameter은 모델을 얼마나 regularization하는지를 결정한다.\n",
    "\n",
    "regularization ?\n",
    "\n",
    "* Pipeline에서 parameter을 수정하려면 <model_name>__<parameter_name>으로 해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7873552003785396"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_params(classifier__C = 1e-3)\n",
    "cv_results = cross_val_score(model,data,target)\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory\n",
      "steps\n",
      "verbose\n",
      "preprocessor\n",
      "classifier\n",
      "preprocessor__copy\n",
      "preprocessor__with_mean\n",
      "preprocessor__with_std\n",
      "classifier__C\n",
      "classifier__class_weight\n",
      "classifier__dual\n",
      "classifier__fit_intercept\n",
      "classifier__intercept_scaling\n",
      "classifier__l1_ratio\n",
      "classifier__max_iter\n",
      "classifier__multi_class\n",
      "classifier__n_jobs\n",
      "classifier__penalty\n",
      "classifier__random_state\n",
      "classifier__solver\n",
      "classifier__tol\n",
      "classifier__verbose\n",
      "classifier__warm_start\n"
     ]
    }
   ],
   "source": [
    "for param in model.get_params() :\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()['classifier__C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7873552003785396 | 0.0018873549930111077\n",
      "0.799332617870851 | 0.003165928979859665\n",
      "0.7995987637941779 | 0.002778046832848365\n",
      "0.7997625702457313 | 0.0028378701400111547\n",
      "0.7997830452662062 | 0.0028046734661818177\n"
     ]
    }
   ],
   "source": [
    "for c in [1e-3,1e-2,1e-1,1,10] :\n",
    "    model.set_params(classifier__C=c)\n",
    "    cv_results = cross_val_score(model,data,target)\n",
    "    print(cv_results.mean(), '|', cv_results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적의 모델을 찾기 위해서는 하나의 테스트셋을 여러 모델에 적용한 뒤 그 결과값인 test_score을 비교하면 된다.\n",
    "\n",
    "최적의 모델을 선정하고 난 뒤에는 새로운 테스트 셋으로 model_score을 추출해야한다. 왜냐하면 test_score은 모델을 선택할때 이미 사용했기 때문이다.\n",
    "\n",
    "이 말의 50%정도만 이해한듯.test_score이 independent가 더이상 아니라는데, 새로운 test를 통해 나온 accuracy라는 사실은 변함없지 않나.\n",
    "\n",
    "그리고 test_data라는 말이 개별적으로 train한 뒤 test_set으로 다시 scoring을 찾았다는 말 아닌가? 그런데 굳이 모델을 선별한 뒤 또 한번 새로운 test_set을 구해서 점수를 메기는걸까?\n",
    "\n",
    "뒷장에서 설명이 나온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, train_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### columntransformer : 데이터 가공 없이 원하는 type을 추출하여 원하는 preprocessor를 적용시킬 수 있도록 돕는 절차임.\n",
    "쉽게 생각해 데이터를 가공할 컨베이어 벨트를 미리 만들어 놓는다고 보면 될 듯. 원하는 데이터 유형(categorical 또는 numerical)을 택한 뒤 해당 columns에 preprocessing을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "categorical_preprocessor = OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1)\n",
    "\n",
    "preprocessor = ColumnTransformer([('categorical', categorical_preprocessor,selector(dtype_include='object'))], remainder='passthrough', sparse_threshold=0)\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline([('preprocessor', preprocessor),('classifier',HistGradientBoostingClassifier(random_state=42))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 || 3\n",
      "score :  0.794\n",
      "best_score : 0.7937141687141687\n",
      "0.01 || 10\n",
      "score :  0.810\n",
      "best_score : 0.8100941850941851\n",
      "0.01 || 30\n",
      "score :  0.810\n",
      "best_score : 0.8100941850941852\n",
      "0.1 || 3\n",
      "score :  0.812\n",
      "best_score : 0.8123464373464373\n",
      "0.1 || 10\n",
      "score :  0.820\n",
      "best_score : 0.8201269451269451\n",
      "0.1 || 30\n",
      "score :  0.815\n",
      "1 || 3\n",
      "score :  0.816\n",
      "1 || 10\n",
      "score :  0.806\n",
      "1 || 30\n",
      "score :  0.800\n",
      "10 || 3\n",
      "score :  0.545\n",
      "10 || 10\n",
      "score :  0.469\n",
      "10 || 30\n",
      "score :  0.580\n",
      "final_best_score : 0.8201269451269451\n",
      "max_leaf_nodes : {'learning-rate': 0.1, 'max_leaf_nodes': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "learning_rate = [0.01,0.1,1,10]\n",
    "max_leaf_nodes = [3, 10, 30]\n",
    "\n",
    "best_score = 0\n",
    "best_params ={}\n",
    "\n",
    "for lr in learning_rate :\n",
    "    for mln in max_leaf_nodes :\n",
    "        print(lr,\"||\",mln)\n",
    "        model.set_params(classifier__learning_rate = lr, classifier__max_leaf_nodes = mln)\n",
    "        scores = cross_val_score(model, data_train, target_train, cv=2)\n",
    "        mean_score =scores.mean()\n",
    "        print(f'score : {mean_score : .3f}')\n",
    "        if mean_score > best_score :\n",
    "            best_score = mean_score\n",
    "            best_params = {'learning-rate' : lr, 'max_leaf_nodes': mln}\n",
    "            print(f'best_score : {best_score}')\n",
    "print(f'final_best_score : {best_score}')\n",
    "print(f'max_leaf_nodes : {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8286584429543943"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr = best_params['learning-rate']\n",
    "best_mln = best_params['max_leaf_nodes']\n",
    "\n",
    "model.set_params(classifier__learning_rate = best_lr, classifier__max_leaf_nodes = best_mln)\n",
    "\n",
    "model.fit(data_train,target_train)\n",
    "\n",
    "test_score = model.score(data_test, target_test)\n",
    "\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b32ab0203d4274b325f86ba61b5b3c6bc5e3032e9f578fcc84de2c2aec614dff"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
