{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n",
    "모델 자체가 복잡하다 보니 같은 데이터를 처리하더라도 간단한 모델에 보다 몇십배 많은 시간이 걸린다. \n",
    "\n",
    "효과적인 모델을 구축하기 위해서 보다 높은 hyperparameter을 설정할 수 있지만 computing cost와 generalization performance 둘다 만족할 수 있는 값을 구해야한다. \n",
    "\n",
    "* n_estimators => main parameter\n",
    "  \n",
    "* max_depth => Symmetric tree 개수를 결정함\n",
    "* max_leaf_nodes => node 당 최대 leaf 개수\n",
    "\n",
    "> ❗Be aware that with random forest, trees are generally deep since we are seeking to overfit each tree on each bootstrap sample because this will be mitigated by combining them altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "target *= 100  # rescale the target in k$\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>100</td>\n",
       "      <td>40.856181</td>\n",
       "      <td>0.693953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>41.285779</td>\n",
       "      <td>0.840210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>44.084379</td>\n",
       "      <td>0.794622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>47.136405</td>\n",
       "      <td>0.956875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>49.334952</td>\n",
       "      <td>0.748772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>49.511881</td>\n",
       "      <td>0.867570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>49.955527</td>\n",
       "      <td>0.892436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>54.604095</td>\n",
       "      <td>0.808515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>61.440435</td>\n",
       "      <td>0.975260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>73.063948</td>\n",
       "      <td>0.693810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_n_estimators param_max_leaf_nodes  mean_test_error  std_test_error\n",
       "0                500                  100        40.856181        0.693953\n",
       "2                 10                  100        41.285779        0.840210\n",
       "7                100                   50        44.084379        0.794622\n",
       "8                  1                  100        47.136405        0.956875\n",
       "6                 50                   20        49.334952        0.748772\n",
       "1                100                   20        49.511881        0.867570\n",
       "9                 10                   20        49.955527        0.892436\n",
       "3                500                   10        54.604095        0.808515\n",
       "4                  5                    5        61.440435        0.975260\n",
       "5                  5                    2        73.063948        0.693810"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_distributions = {\n",
    "    \"n_estimators\": [1, 2, 5, 10, 20, 50, 100, 200, 500],\n",
    "    \"max_leaf_nodes\": [2, 5, 10, 20, 50, 100],\n",
    "}\n",
    "search_cv = RandomizedSearchCV(\n",
    "    RandomForestRegressor(n_jobs=2), param_distributions=param_distributions,\n",
    "    scoring=\"neg_mean_absolute_error\", n_iter=10, random_state=0, n_jobs=2,\n",
    ")\n",
    "search_cv.fit(data_train, target_train)\n",
    "\n",
    "columns = [f\"param_{name}\" for name in param_distributions.keys()]\n",
    "columns += [\"mean_test_error\", \"std_test_error\"]\n",
    "cv_results = pd.DataFrame(search_cv.cv_results_)\n",
    "cv_results[\"mean_test_error\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[\"std_test_error\"] = cv_results[\"std_test_score\"]\n",
    "cv_results[columns].sort_values(by=\"mean_test_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomizedSearchCV : 최적의 model 하나만을 추출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average, our random forest regressor makes an error of 41.91 k$\n"
     ]
    }
   ],
   "source": [
    "error = -search_cv.score(data_test, target_test)\n",
    "print(f\"On average, our random forest regressor makes an error of {error:.2f} k$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-boosting decision trees\n",
    "* n_estimators : tree 개수\n",
    "\n",
    "* max_depth : tree 변수\n",
    "    > With this consideration in mind, the deeper the trees, the faster the residuals will be corrected and less learners are required. Therefore, n_estimators should be increased if max_depth is lower. \n",
    "\n",
    "\n",
    "\n",
    "* max_leaf_nodes : tree 변수\n",
    "  \n",
    "* Learning_rate : online learning과 관련있는걸로 아는데 의미는 내가 아는 것과 다른가 봄\n",
    "    > we would like the tree to try to correct all possible errors or only a fraction of them. A small learning-rate value would only correct the residuals of very few samples. If a large learning-rate is set (e.g., 1), we would fit the residuals of all samples. So, with a very low learning-rate, we will need more estimators to correct the overall error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "hist_gbdt = HistGradientBoostingRegressor(max_iter=1000, early_stopping=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'max_depth': [3, 8],\n",
    "    'max_leaf_nodes': [15, 31],\n",
    "    'learning_rate': [0.1, 1],\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(estimator=hist_gbdt, param_grid=params,n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=5, shuffle = True, random_state= 0)\n",
    "cv_results = cross_validate(grid_cv,data,target, n_jobs=2, cv=cv, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031483767082097436"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test_score'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.839 0.006\n"
     ]
    }
   ],
   "source": [
    "print(f\"{cv_results['test_score'].mean():.3f} {cv_results['test_score'].std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_leaf_nodes': 15}\n",
      "# trees: 528\n",
      "{'learning_rate': 0.1, 'max_depth': 8, 'max_leaf_nodes': 15}\n",
      "# trees: 447\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_leaf_nodes': 15}\n",
      "# trees: 576\n",
      "{'learning_rate': 0.1, 'max_depth': 8, 'max_leaf_nodes': 15}\n",
      "# trees: 290\n",
      "{'learning_rate': 0.1, 'max_depth': 8, 'max_leaf_nodes': 15}\n",
      "# trees: 414\n"
     ]
    }
   ],
   "source": [
    "# solution\n",
    "for estimator in cv_results[\"estimator\"]:\n",
    "    print(estimator.best_params_)\n",
    "    print(f\"# trees: {estimator.best_estimator_.n_iter_}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b32ab0203d4274b325f86ba61b5b3c6bc5e3032e9f578fcc84de2c2aec614dff"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
