{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\git_local_repository\\\\yangoos57\\\\ML\\\\Hands_On_Data_preprocessing_in_python\\\\Part3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distinction of Data redundancy and Data reduction.\n",
    "\n",
    "Data redundancy is about having the same information presented under more than one attribute.\n",
    "\n",
    "Data reduction is about reducing the size of data due to one of the following three reasons\n",
    "\n",
    "* High-Dimensional Visualizations : 사람들은 3~5 차원 이상의 그래프를 이해하는데 어려움을 느낀다.\n",
    "\n",
    "* Computational Cost : 불필요하게 많은 계산을 필요로 한다.\n",
    "* Curse of Dimensionality : variable이 많다고 정확도가 높아지는 건 아니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the objectives of data reduction\n",
    "1. data reduction seeks to obtain a reduced representation of the dataset that is much smaller in volume.\n",
    "   \n",
    "2. it tries to closely maintain the integrity of the original data, which means making sure that data reduction will not lead to including bias and critical information being lost in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of data reduction\n",
    "\n",
    "- Numerosity data reduction : It performs data reduction by reducing the number of data objects or rows in a dataset.\n",
    "  * Random Sampling\n",
    "    \n",
    "  * Strafied Sampling\n",
    "  * Random over/under sampling\n",
    "\n",
    "- dimenionality data reduction : It performs data reduction by rducing the number of dimensions or attributes in a dataset.\n",
    "  * Linear regression\n",
    "    \n",
    "  * Decision Tree\n",
    "  * Random Forest\n",
    "  * Brute-force Computational Dimension reduction\n",
    "  * principal component analysis\n",
    "  * Functional data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerosity data reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = pd.read_csv('data/ch13/Customer Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 360 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score :  0.7353535353535353\n",
      "Best parameters :  {'criterion': 'entropy', 'max_depth': 10, 'min_impurity_decrease': 0.005, 'min_samples_split': 40}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1080 out of 1080 | elapsed:    7.2s finished\n"
     ]
    }
   ],
   "source": [
    "y = customer_df['Churn']\n",
    "xs = customer_df.drop(columns='Churn')\n",
    "param_grid = {'criterion' : ['gini','entropy'], 'max_depth' : [10,20,30,40,50,60], 'min_samples_split' : [10,20,30,40,50], 'min_impurity_decrease' : [0,0.001,0.005,0.01,0.05,0.1]}\n",
    "gridsearch = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=3, scoring='recall', verbose=1)\n",
    "gridsearch.fit(xs,y)\n",
    "print('Best Score : ', gridsearch.best_score_)\n",
    "print('Best parameters : ', gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 360 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score :  0.7430555555555555\n",
      "Best parameters :  {'criterion': 'entropy', 'max_depth': 10, 'min_impurity_decrease': 0.005, 'min_samples_split': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1080 out of 1080 | elapsed:    6.6s finished\n"
     ]
    }
   ],
   "source": [
    "customer_df_rs = customer_df.sample(1000, random_state=1)\n",
    "y = customer_df_rs['Churn']\n",
    "xs = customer_df_rs.drop(columns='Churn')\n",
    "param_grid = {'criterion' : ['gini','entropy'], 'max_depth' : [10,20,30,40,50,60], 'min_samples_split' : [10,20,30,40,50], 'min_impurity_decrease' : [0,0.001,0.005,0.01,0.05,0.1]}\n",
    "gridsearch = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=3, scoring='recall', verbose=1)\n",
    "gridsearch.fit(xs,y)\n",
    "print('Best Score : ', gridsearch.best_score_)\n",
    "print('Best parameters : ', gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.843\n",
      "1    0.157\n",
      "Name: Churn, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "n, s = 1000, len(customer_df)\n",
    "r = n/s\n",
    "sample_df = customer_df.groupby('Churn', group_keys=False).apply(lambda sdf : sdf.sample(round(len(sdf)*r)))\n",
    "\n",
    "print(sample_df.Churn.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Random over/undersampling\n",
    " random over/undersampling은 표본을 5:5 비율로 추출한다. \n",
    "\n",
    " over/undersampling을 사용하기 위한 조건 두가지\n",
    " 1. the dependent attribute is binary, meaning that it only has two class labels.\n",
    " 2. there are significantly more of one class label than the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    250\n",
      "0    250\n",
      "Name: Churn, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_df = customer_df.groupby('Churn', group_keys=False).apply(lambda sdf : sdf.sample(round(250)))\n",
    "\n",
    "print(sample_df.Churn.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b32ab0203d4274b325f86ba61b5b3c6bc5e3032e9f578fcc84de2c2aec614dff"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
