# UDemy AWS

## Global Services, Region

### Global Service

- IAM, Route 53, CloudFront, WAF 등
- Region을 선택할 필요가 없음.
- AWS Global infrastructure

### Region-scoped

- EC2, Elastic Beanstalk, Lambda …. 등

### Region

하나의 독립적인 서비스. Data Center의 집합이다. ~~서비스는 리전 크기를 벗어나지 못한다.(리전이 가장 큰 단위이며 그 이상을 초과하는 서비스는 존재하지 않는다.)~~  Global Service는 region을 넘는 서비스이다.

### Region 선택 기준

- compliance : 해당 국가의 법률 준수 여부
- proximity : low latency
- Available Services : 리전마다 제공 가능한 서비스가 다름
- Pricing : 리전마다 가격이 다름

### Availability Zones

- Region에 2 ~ 6 개의  AZ가 존재하며(보통 3개) AZ에는 2 ~ 4개의 Data Center가 존재한다.
- 물리적으로 분리되어 있기 때문에 재난 대비가 가능하다.

### Edge Locations

## IAM

### IAM 이란

- Identity and access management, **Global Service**
- Group으로 권한을 설정할 수 있다. Group 내부에는 사용자만 포함 가능하다.(Group 내부에 Group을 넣는 건 불가능하다.)
- 특정 사용자가 여러 그룹에 속할 수 있다.
- Json으로 권한을 부여한다.
- Least priviledge Principle : 제한된 권한을 제한된 사용자에게 준다.

### IAM Policy(정책)

- inline policy : user에 직접 적용하는 policy
- 직접 만들거나 기존에 있는 정책을 사용할 수 있음

### IAM Multi Factor Authentification(MFA)

- Password + Device = MFA
- virtual MFA Device : google authentificator
- Physical Device : u2f

## EC2

- Bootstrap : launching commands when a machine starts.(Docker의 cmd 맞나. 그거와 같은 기능인듯)
- EC2 Create의 Advanced Details ⇒ User data =  Boot strap이다.

### EC2 종류

- T, M : General Purpose ⇒ 범용 목적
- C : Compute Optimized ⇒ required High performance Cpu
- R,X,M : Memory Optimized
- I, D : Stroage Optimized

### Security Groups = Firewall on EC2

- 기본세팅으로 ec2로 들어오는 모든 Inbound는 통제하고outbound는 통제하지 않는다.
- EC2 외부에 존재하는 것 인만큼 알맞는 방식으로 Security Group 설정을 해야 EC2에 접근할 수 있다.
- EC2로 접속할 때 컴퓨터가 계속해서 대기하는 모습(Timeout 상황)이라면 Security Group 문제 때문이다.
- 허용 단위를 security Group으로도 설정할 수 있다. ex) A라는 EC2의 Security Group에 S1이라는 Security Group을 Inbound Traffic에 허용한다면, S1 Security Group을 사용하는 EC2들 모두는 A와 통신이 가능하게 된다.
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled.png)
    

### Classic Ports

- 22 = SSH(Secure Shell) - log into a linux instance
- 21 = FTP(File Transfer Protocol)
- 22 = SFTP(Secure File Transfer Protocol) - upload files using SSH
- 80 = HTTP
- 443 = HTTPS
- 3389 = RDP(Remote Desktop Protocol) - log into a window instance

### EC2 Purchasing Options

- On-Demand Instances – short workload, predictable pricing, pay by second
- Reserved (1 & 3 years)
• Reserved Instances – long workloads
• Convertible Reserved Instances – long workloads with flexible instances
- Savings Plans (1 & 3 years) –commitment to an amount of usage, long workload • Spot Instances – short workloads, cheap, can lose instances (less reliable)
• Dedicated Hosts – book an entire physical server, control instance placement
• Dedicated Instances – no other customers will share your hardware
- Capacity Reservations – reserve capacity in a specific AZ for any duration
- **EC2 On Demand**
• Pay for what you use:
• Linux or Windows - billing per second, after the first minute • All other operating systems - billing per hour
• Has the highest cost but no upfront payment
• No long-term commitment
• Recommended for short-term and un-interrupted workloads, where you can't predict how the application will behave
- **EC2 Reserved Instances**
• Up to 72% discount compared to On-demand
• You reserve a specific instance attributes (Instance Type, Region,Tenancy, OS)
    
    • Reservation Period – 1 year (+discount) or 3 years (+++discount)
    • Payment Options – No Upfront (+), Partial Upfront (++), All Upfront (+++) 
    
    • Reserved Instance’s Scope – Regional or Zonal (reserve capacity in an AZ)
    • Recommended for steady-state usage applications (think database)
    • You can buy and sell in the Reserved Instance Marketplace
    • Convertible Reserved Instance
    • Can change the EC2 instance type, instance family, OS, scope and tenancy • Up to 66% discount
    
- **EC2 Savings Plans**
• Get a discount based on long-term usage (up to 72% - same as RIs)
    
    • Commit to a certain type of usage ($10/hour for 1 or 3 years)
    • Usage beyond EC2 Savings Plans is billed at the On-Demand price
    • Locked to a specific instance family & AWS region (e.g., M5 in us-east-1)
    • Flexible across:
    
    • Instance Size (e.g., m5.xlarge, m5.2xlarge) • OS (e.g., Linux, Windows)
    • Tenancy (Host, Dedicated, Default)
    
- **EC2 Spot Instances**
• Can get a discount of up to 90% compared to On-demand
• Instances that you can “lose” at any point of time if your max price is less than the current spot price
• The MOST cost-efficient instances in AWS
• Useful for workloads that are resilient to failure
    
    • Batch jobs
    • Data analysis
    • Image processing
    • Any distributed workloads
    • Workloads with a flexible start and end time
    • Not suitable for critical jobs or databases
    

- **EC2 Dedicated Hosts**
• A physical server with EC2 instance capacity fully dedicated to your use
• Allows you address compliance requirements and use your existing server- bound software licenses (per-socket, per-core, pe—VM software licenses)
• Purchasing Options:
    
    • On-demand – pay per second for active Dedicated Host
    • Reserved - 1 or 3 years (No Upfront,Partial Upfront,All Upfront)
    
    • The most expensive option
    • Useful for software that have complicated licensing model (BYOL – Bring Your
    Own License)
    • Or for companies that have strong regulatory or compliance needs
    
- **EC2 Capacity Reservations**
• Reserve On-Demand instances capacity in a specific AZ for any duration
• You always have access to EC2 capacity when you need it
• No time commitment (create/cancel anytime), no billing discounts
• Combine with Regional Reserved Instances and Savings Plans to benefit from billing discounts
• You’re charged at On-Demand rate whether you run instances or not
• Suitable for short-term, uninterrupted workloads that needs to be in a
specific AZ

### Spot Request

- Spot instance 사용하는 옵션, request type을 설정 잘해야함. one-time은 한 번만  persistent는 자동으로  instance를 관리하는 기능임(kubernetes에도 있는 기능인데 이름이 기억나진 않음)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%201.png)

### Spot Fleets

- Spot Request를 통해 만들 수 있다.

## EC2-Network

### Public IP & Private IP

- Public IP : 인터넷에서 접근 가능
- Private IP : 사설 네트워크에서만 적용
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%202.png)
    

### Placement Groups

- EC2를 배치하는 전략
- Cluster—clusters instances into a low-latency group in a single Availability Zone
    - Pros: Great network (10 Gbps bandwidth between instances with Enhanced Networking enabled - recommended)
    • Cons: If the rack fails, all instances fails at the same time
    • Use case:
    • Big Data job that needs to complete fast
    • Application that needs extremely low latency and high network throughput
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%203.png)
    
- Spread—spreads instances across underlying hardware (max 7 instances per group per AZ)
    
    Pros:
    • Can span across Availability
    • Reduced risk is simultaneous failure
    • EC2 Instances are on different physical hardware
    Zones (AZ)
    • Cons:
    • Limited to 7 instances per AZ
    per placement group • Use case:
    • Application that needs to maximize high availability
    • Critical Applications where each instance must be isolated from failure from each other
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%204.png)
    
- Partition—spreads instances across many different partitions (which rely on different sets of racks) within an AZ. Scales to 100s of EC2 instances per group (Hadoop, Cassandra, Kafka)
    - Up to 7 partitions per AZ
    - Can span across multiple AZs in the
    - Up to 100s of EC2 instances
    - The instances in a partition do not share racks with the instances in the other partitions
    - A partition failure can affect many EC2 but won’t affect other partitions
    - EC2 instances get access to the partition information as metadata
    - Use cases: HDFS, HBase, Cassandra, Kafka
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%205.png)
    

### Elastic Network Interfaces(ENI)

- virtual network card
- ENI를 사용해서 네트워크 장애를 쉽게 해결 할 수 있다는데, 이해가 되진 않음.
- ENI에 대한 참고자료(나중에 필요하면 읽자.)
    - [https://aws.amazon.com/ko/blogs/aws/new-elastic-network-interfaces-in-the-virtual-private-cloud/](https://aws.amazon.com/ko/blogs/aws/new-elastic-network-interfaces-in-the-virtual-private-cloud/)

### Instance Stop과 Terminate 차이

- Stop – the data on disk (EBS) is kept intact in the next start
- Terminate – any EBS volumes (root) also set-up to be destroyed is lost

### EC2 Hibernate

- Hibernate = 동면(=겨울잠), 절전
- The in-memory (RAM) state is preserved
- The instance boot is much faster! (the OS is not stopped / restarted)
- Under the hood: the RAM state is written to a file in the root EBS volume
- The root EBS volume must be encrypted
- Use cases:
    - Long-running processing
    - Saving the RAM state
    - Services that take time to initialize
- 원리
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%206.png)
    

EC2 Hibernate – Good to know
• Supported Instance Families – C3, C4, C5, I3, M3, M4, R3, R4,T2,T3, ...
• Instance RAM Size – must be less than 150 GB.
• Instance Size – not supported for bare metal instances.
• AMI – Amazon Linux 2, Linux AMI, Ubuntu, RHEL, CentOS & Windows... • Root Volume – must be EBS, encrypted, not instance store, and large
• Available for On-Demand, Reserved and Spot Instances • An instance can NOT be hibernated more than 60 days

## Elastic Block Store(EBS)

- EC2에서 사용하는 Storage이자 network로 연결
- 같은 AZ에 있는 EC2만 연결 가능함. 다른 AZ에 있는 EC2에 사용하려면 Snapshot을 만들어서 사용해야한다.
- 하나의 EC2에 EBS 여러 개를 사용할 수 있음.

### EBS Snapshots

- 기본 기능

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%207.png)

- 추가 기능
    - EBS Snapshot Archive
    - Recycle Bin for EBS Snapshots
        - Snapshot을 바로 지우지 않고 Recycle Bin에서 삭제되도록 안전 장치를 만드는 서비스
    - Fast Sanpshot Restore(FSR)
- Snapshot을 만든 다음 Create from Snapshot 기능을 사용해 다른 AZ에서 만들 수 있음.

### AMAZON Machine Image(AMI)

- 도커 이미지와 같은 기능인듯

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%208.png)

### EC2 Instance Store

- EC2와 물리적으로 연결된 스토리지
- 고성능 하드웨어 디스크가 필요할 경우 사용한다.

### EBS Volumes come in 6 types

- gp2 / gp3 (SSD): General purpose SSD volume that balances price and performance for a wide variety of workloads
- io1 / io2 (SSD): Highest-performance SSD volume for mission-critical low-latency or high-throughput workloads
- st1 (HDD): Low cost HDD volume designed for frequently accessed, throughput- intensive workloads
- sc1 (HDD): Lowest cost HDD volume designed for less frequently accessed workloads
- EBS Volumes are characterized in Size | Throughput | IOPS (I/O Ops Per Sec) • When in doubt always consult the AWS documentation – it’s good!
- **Only gp2/gp3 and io1/io2 can be used as boot volumes**

### General Purpose SSD

- Cost effective storage, low-latency
- System boot volumes,Virtual desktops, Development and test environments • 1 GiB - 16TiB
- gp3: IOPS를 수동으로 설정 가능
    - Baseline of 3,000 IOPS and throughput of 125 MiB/s
    - Can increase IOPS up to 16,000 and throughput up to 1000 MiB/s independently
- gp2: IOPS와 용량이 연결되어 있음
    - Small gp2 volumes can burst IOPS to 3,000
    - Size of the volume and IOPS are linked, max IOPS is 16,000
    - 3 IOPS per GB, means at 5,334 GB we are at the max IOPS

### Provisioned IOPS (PIOPS) SSD

- IOPS 16000 이상이 필요할 경우
- Critical business applications with sustained IOPS performance Or applications that need more than 16,000 IOPS
- Great for databases workloads (sensitive to storage perf and consistency)
- io1/io2 (4 GiB - 16 TiB):
    - Max PIOPS: 64,000 for Nitro EC2 instances & 32,000 for other
    - Can increase PIOPS independently from storage size
    - io2 have more durability and more IOPS per GiB (at the same price as io1)
    - io2 Block Express (4 GiB – 64 TiB):
        - Sub-millisecond latency
        - Max PIOPS: 256,000 with an IOPS:GiB ratio of 1,000:1
    - **Supports EBS Multi-attach**

### EBS Multi-Attach – io1/io2 family

- **io1/io2 only support EBS Multi-Attach**
- Attach the same EBS volume to multiple EC2 instances in the same AZ
- Each instance has full read & write permissions to the high-performance volume
- Use case:
• Achieve higher application availability in clustered
Linux applications (ex:Teradata)
• Applications must manage concurrent write operations
- **Up to 16 EC2 Instances at a time**
- **Must use a file system that’s cluster-aware** (not
XFS, EXT4, etc...)

### Hard Disk Drives (HDD)

- Cannot be a boot volume
- 125 GiB to 16TiB
- Throughput Optimized HDD (st1)
- Big Data, Data Warehouses, Log Processing • Max throughput 500 MiB/s – max IOPS 500
- Cold HDD (sc1):
• For data that is infrequently accessed
• Scenarios where lowest cost is important
• Max throughput 250 MiB/s – max IOPS 250

### EBS Encryption

- encrypted volume 만들기
    - 방법 1 : EBS를 처음 만들때 encryption 기능을 사용한다.
    - 방법 2 : unencrpyted EBS의 snapshot을 활용해 volume을 새로 생성하는 과정에서 encryption을 활성화해서 만든다.
- encrypted volume snapshot 만들기
    - encrpted volume을 새로 만들어서 스냅샷을 만드는 것 외에는 없다.

### Elastic File System(EFS) = NFS (network file system

- 기본 개념
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%209.png)
    
- **EFS works with EC2 instances in multi-AZ**
- Highly available, scalable, expensive (3x gp2), pay per use
- Use cases: content management, web serving, data sharing,Wordpress
- Uses NFSv4.1 protocol
- Uses security group to control access to EFS
- **Compatible with Linux based AMI (not Windows)**
- Encryption at rest using KMS
- POSIX file system (~Linux) that has a standard file API
- **File system scales automatically, pay-per-use, no capacity planning!**

### EFS 모드

- **EFS Scale**
    - 1000s of concurrent NFS clients, 10 GB+ /s throughput
    - Grow to Petabyte-scale network file system, automatically
- **Performance Mode (set at EFS creation time)**
    - General Purpose (default) – latency-sensitive use cases (web server, CMS, etc...)
    - Max I/O – higher latency, throughput, highly parallel (big data, media processing)
- **Throughput Mode**
    - Bursting – 1TB = 50MiB/s + burst of up to 100MiB/s
    - Provisioned – set your throughput regardless of storage size, ex: 1 GiB/s for 1 TB storage
    - Elastic – automatically scales throughput up or down based on your workloads
    • Up to 3GiB/sforreadsand1GiB/sforwrites
        
        • Usedforunpredictableworkloads
        

### EFS - Storage Tiers

- Standard: for frequently accessed files
- Infrequent access (EFS-IA): cost to retrieve files, lower price to store. Enable EFS-IA with a Lifecycle Policy

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2010.png)

### Storage Class

- Standard: Multi-AZ, great for production
- One Zone: One AZ, great for dev, backup enabled by default, compatible with IA (EFS One Zone-IA)
    - **Over 90% in cost savings**

### EBS vs EFS – Elastic Block Storage

**EBS**

- one instance (except multi-attach io1/io2)
- are locked at the Availability Zone (AZ) level
- gp2: IO increases if the disk size increases
- io1: can increase IO independently

**To migrate an EBS volume across AZ** 

- Take a snapshot
- Restore the snapshot to another AZ
- EBS backups use IO and you shouldn’t run them while your application is handling a lot of traffic
- **Root EBS Volumes of instances get terminated by default if the EC2 instance gets terminated. (you can disable that)**

**EFS**

- **Mounting 100s of instances across AZ**
- EFS share website files (WordPress)
- **Only for Linux Instances (POSIX)**
- EFS has a higher price point than EBS
- Can leverage EFS-IA for cost savings
- Remember : EFS vs EBS vs Instance Store

## Scalability & Availability

**Vertical Scalability**

- Vertical scalability is very common for non
distributed systems, such as a database.
- RDS, ElastiCache are services that can scale
ver tically.
- There’s usually a limit to how much you can
vertically scale (hardware limit)

**Horizontal Scalability** 

- Horizontal scaling implies distributed systems.
- AWS에서는 Scale out / in이라는 용어를 사용함.

**High Availability**

- High availability means running your
application / system in at least 2 data
centers (== Availability Zones)
- The goal of high availability is to survive a data center loss
- The high availability can be passive (for RDS Multi AZ for example)

## Load Balancing

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2011.png)

### Why use a load balancer?

- Spread load across multiple downstream instances
- Expose a single point of access (DNS) to your application
- Seamlessly handle failures of downstream instances
- Do regular health checks to your instancesHealth Checks
• Health Checks are crucial for Load Balancers
• They enable the load balancer to know if instances it forwards traffic to are available to reply to requests
• The health check is done on a port and a route (/health is common)
• If the response is not 200 (OK), then the instance is unhealthy
- Provide SSL termination (HTTPS) for your websites
- Enforce stickiness with cookies
- High availability across zones
- Separate public traffic from private traffic

### Types of load balancer on AWS

- Application Load Balancer (v2 - new generation) – 2016
    - ALB HTTP, HTTPS,WebSocket
- Network Load Balancer (v2 - new generation) – 2017 – NLB
    - TCP,TLS(secureTCP),UDP
- Gateway Load Balancer – 2020 – GWLB
    - Operates at layer 3 (Network layer) – IP Protocol

### Load Balancer Security Groups

- EC2의 Security Group의 Source를 Load Balancer의 Security Group으로 설정해서, Traffic이 Load Balancer를 통해서 들어오게 할 수 있음.

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2012.png)

### Application Load Balacner - HTTP Based Traffic

- Layer 7(HTTP,HTTPS)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2013.png)

### APP Load Balancer의 Target Group 종류

• EC2 instances (can be managed by an Auto Scaling Group) – HTTP 
• ECS tasks (managed by ECS itself) – HTTP
• Lambda functions – HTTP request is translated into a JSON event 
• IP Addresses – must be private IPs

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2014.png)

### Network Load Balancer - TCP & UDP Based

- Network load balancers (Layer 4) allow to:
    - Forward TCP & UDP traffic to your instances
    - Handle millions of request per seconds
    - Less latency ~100 ms (vs 400 ms for ALB)
- **NLB has one static IP per AZ**, and supports assigning Elastic IP (helpful for whitelisting specific IP)
- NLB are used for extreme performance,TCP or UDP traffic
- Not included in the AWS free tier

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2015.png)

### Network Load Balancer - Target Groups

- EC2 instances
- IP Addresses – must be private IPs
- Application Load Balancer
- Health Checks support the TCP, HTTP and HTTPS Protocols

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2016.png)

### Gateway Load Balancer - Layer 3

- IP Packet 검사용으로 사용
- Example: Firewalls, Intrusion Detection and Prevention Systems, Deep Packet Inspection Systems, payload manipulation, …
- Operates at Layer 3 (Network Layer) – IP Packets
- Combines the following functions:
    - Transparent Network Gateway – single entry/exit
    - Load Balancer – distributes traffic to your virtual appliances
- **Uses the GENEVE protocol on port 6081**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2017.png)

### Gateway Load Balancer –Target Groups

- EC2 instances
- IP Addresses – must be private IPs

### Sticky Sessions

- Load Balancer를 사용할 때 client와 특정 instance를 계속 연결시키는 기능
- Application-based Cookies
- Duration-based Cookies

### Cross-Zone Load Balancing

- 기본개념

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2018.png)

- Application Load Balancer
• Enabled by default (can be disabled at the Target Group level)
    
    • No charges for inter AZ data
    
- Network Load Balancer & Gateway Load Balancer
    
    • Disabled by default
    • You pay charges ($) for inter AZ data if enabled
    

### Server Name Indication(SNI)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2019.png)

- **SNI solves the problem of loading multiple SSL certificates onto one web server (to serve multiple websites)**
- It’s a “newer” protocol, and requires the client to indicate the hostname of the target server in the initial SSL handshake
- The server will then find the correct certificate, or return the default one
- Application Load Balancer (v2)
• Supports multiple listeners with multiple SSL certificates
    
    • Uses Server Name Indication (SNI) to make it work
    
- Network Load Balancer (v2)
• Supports multiple listeners with multiple SSL certificates
• Uses Server Name Indication (SNI) to make it work

### Connection Draining

- Instance 연결을 종료하고자 할 때 중단 기간을 둬서 안정적으로 종료할 수 있게 만드는 기능

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2020.png)

### 문제

Question 5:

**Application Load Balancer를 사용해 EC2 인스턴스에서 호스팅된 웹사이트의 트래픽을 분배하고 있습니다. 그런데 여러분의 웹사이트가 Application Load Balancer의 IP 주소인 사설 IPv4 주소에서 들어오는 트래픽만을 확인하고 있는 것으로 나타났습니다. 이런 경우, 웹사이트로 연결된 클라이언트들의 IP 주소를 받으려면 어떻게 해야 할까요?**

Application Load Balancer를 사용하여 EC2 인스턴스에 트래픽을 배분하는 경우, 요청을 받게 되는 IP 주소는 ALB의 사설 IP 주소가 됩니다. 클라이언트의 IP 주소를 받기 위해, ALB는 클라이언트의 IP 주소를 포함하고 있는 X-Forwarded-For라는 헤더를 추가합니다.

Question 9:

**Application Load Balancer는 트래픽을 다른 대상 그룹으로 라우팅할 수 있습니다. 이때 확인할 내용으로 사용할 수 없는 것을 고르세요.**

답 : ALB는 URL 경로, 호스트 이름, HTTP 헤더 및 쿼리 문자열을 기반으로 트래픽을 다른 대상 그룹으로 라우팅할 수 있습니다.

Question 11:

**규정 준수를 위해, 고정된 정적 IP 주소를 최종 사용자에게 노출하여 사용자들이 안정적이고, 규제 기관의 승인을 받은 방화벽 규칙을 작성할 수 있도록 하려 합니다. 이런 경우, 다음 중 어떤 종류의 Elastic Load Balancer를 사용해야 할까요?**

Network Load Balancer는 AZ 당 하나의 정적 IP 주소를 가지며, 여기에 탄력적 IP 주소를 연결할 수 있습니다. Application Load Balancer와 Classic Load Balancer를 정적 DNS 이름으로 사용할 수 있습니다.

## Auto Scaling Group

- ASG are free (you only pay for the underlying EC2 instances)
- ASG Launch Template
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2021.png)
    

### Auto Scaling - CloudWatch Alarms & Scaling

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2022.png)

- Auto Scaling과 CloudWatch가 다이렉트로 연결 되어있음.
- It is possible to scale an ASG based on CloudWatch alarms
- An alarm monitors a metric (such as Average CPU, or a custom metric)
- Metrics such as Average CPU are computed for the overall ASG instances
- Based on the alarm:
• We can create scale-out policies (increase the number of instances)
• We can create scale-in policies (decrease the number of instances)

### Dynamic Scaling Policy

- **Target Tracking Scaling**
• Most simple and easy to set-up
• Example: I want the average ASG CPU to stay at around 40%
- **Simple / Step Scaling**
• When a CloudWatch alarm is triggered (example CPU > 70%), then add 2 units • When a CloudWatch alarm is triggered (example CPU < 30%), then remove 1
- **Scheduled Actions**
• Anticipate a scaling based on known usage patterns
• Example: increase the min capacity to 10 at 5 pm on Fridays

### Predictive Scaling

- Predictive scaling: continuously forecast load and schedule scaling ahead
    - Using Machine Learning

### Good Metrics to scale on

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2023.png)

- **CPUUtilization:** Average CPU utilization across your instances
- **RequestCountPerTarget:** to make sure the number of requests per EC2 instances is stable
- **Average Network In / Out** (if you’re application is network bound)
- Any custom metric (that you push using CloudWatch)

### Scaling Cooldowns

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2024.png)

- After a scaling activity happens, you are in the cooldown period (default 300 seconds)
- During the cooldown period, the ASG will not launch or terminate additional instances (to allow for metrics to stabilize)
- Advice: Use a ready-to-use AMI to reduce configuration time in order to be serving request fasters and reduce the cooldown period

## **Relational Database Service(**RDS)

### Advantage over using RDS versus deploying DB on EC2

- **RDS: Automates setup, operation, and scaling of database in AWS**
- RDS is a managed service:
    - Automated provisioning, OS patching
    - Continuous backups and restore to specific timestamp (Point in Time Restore)!
    - Monitoring dashboards
    - Read replicas for improved read performance
    - **Multi AZ setup for DR (Disaster Recovery)**
    - Maintenance windows for upgrades
    - Scaling capability (vertical and horizontal)
    - **Storage backed by EBS (gp2 or io1)**
    - **BUT you can’t SSH into your instances**

### RDS – Storage Auto Scaling

- Helps you increase storage on your RDS DB instance dynamically
- **When RDS detects you are running out of free database storage, it scales automatically**
- Avoid manually scaling your database storage
- You have to set Maximum Storage Threshold (maximum limit
- Automatically modify storage if:
    - Free storage is less than 10% of allocated storage
    - Low-storage lasts at least 5 minutes
    - 6 hours have passed since last modification
    for DB storage)
    - Useful for applications with unpredictable workloads
    - Supports all RDS database engines (MariaDB, MySQL,PostgreSQL, SQL Server, Oracle)

### RDS Read Replicas for read scalability

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2025.png)

- **Up to 5 Read Replicas**
- **Within AZ, Cross AZ or Cross Region**
- **Replication is ASYNC, so reads are eventually consistent**
- Replicas can be promoted to their own DB
- Applications must update the connection

### RDS Read Replicas – Network Cost

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2026.png)

- In AWS there’s a network cost when data goes from one AZ to another
- **For RDS Read Replicas within the same region, you don’t pay that fee**

### RDS Multi AZ (Disaster Recovery)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2027.png)

- **SYNC replication**
- One DNS name – automatic app
- **failover to standby**
- **Increase availability**
- Failover in case of loss of AZ, loss of network, instance or storage failure
- No manual intervention in apps
- Not used for scaling
- **Note:The Read Replicas be setup as Multi AZ for Disaster Recovery (DR)**

### RDS – From Single-AZ to Multi-AZ

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2028.png)

- **Zero downtime operation (no need to stop the DB)**
- Just click on “modify” for the database
- The following happens internally:
    - A snapshot is taken
    - A new DB is restored from the snapshot in a new AZ
    - Synchronization is established between the two databases

### **RDS Custom**

- **Managed Oracle and Microsoft SQL Server Database with OS and
database customization**

****

## Aurora

- Aurora is a proprietary technology from AWS (not open sourced)
- Postgres and MySQL are both supported as Aurora DB (that means your drivers will work as if Aurora was a Postgres or MySQL database)
- **Aurora is “AWS cloud optimized” and claims 5x performance improvement over MySQL on RDS, over 3x the performance of Postgres on RDS**
- **Aurora storage automatically grows in increments of 10GB, up to 128 TB.**
- **Aurora can have up to 15 replicas and the replication process is faster than MySQL (sub 10 ms replica lag)**
- **Failover in Aurora is instantaneous. It’s HA (High Availability) native.**
- Aurora costs more than RDS (20% more) – but is more efficient

### Aurora High Availability and Read Scaling

- 6 copies of your data across 3 AZ:
    - 4 copies out of 6 needed for writes
    - 3 copies out of 6 need for reads
    - Self healing with peer-to-peer replication
    - Storage is striped across 100s of volumes
- One Aurora Instance takes writes (master)
- Automated failover for master in less than 30 seconds
- Master + up to 15 Aurora Read Replicas serve reads
- Support for Cross Region Replication

### Aurora DB Cluseter

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2029.png)

### Features of Aurora

- Automatic fail-over
- Backup and Recovery
- Isolation and security
- Industry compliance
- Push-button scaling
- Automated Patching with Zero Downtime
- Advanced Monitoring
- Routine Maintenance
- Backtrack: restore data at any point of time without using backups

### Aurora Replicas-Auto Scaling

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2030.png)

### Aurora Specialty

- **Custom Endpoint**
    - Define a subset of Aurora Instances as a Custom Endpoint
    - Example: Run analytical queries on specific replicas
    - **The Reader Endpoint is generally not used after defining Custom Endpoints**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2031.png)
    

- **Serverless**
    - **Automated database instantiation and auto-scaling based on actual usage**
    - Good for infrequent, intermittent or unpredictable workloads
    - No capacity planning needed
    - Pay per second, can be more cost-effective
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2032.png)
    
- **Multi-Master**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2033.png)
    
- **Global Aurora**
    - Aurora Cross Region Read Replicas:
        - Useful for disaster recovery
        - Simple to put in place
    - Aurora Global Database (recommended):
        - 1 Primary Region (read / write)
        - **Up to 5 secondary (read-only) regions, replication lag is less than 1 second**
        - Up to 16 Read Replicas per secondary region
        - Helps for decreasing latency
        - Promoting another region (for disaster recovery) has an RTO of < 1 minute
        - Typical cross-region replication takes less than 1 second
- **Aurora Machine Learning**
    - Enables you to add ML-based predictions to your applications via SQL
    - Simple, optimized, and secure integration between Aurora and AWS ML services

### Backup

- **Restoring a RDS / Aurora backup or a snapshot creates a new database**
- **RDS Backups**
    - Automated backups:
    • Daily full backup of the database (during the backup window)
    • Transaction logs are backed-up by RDS every 5 minutes
    • => ability to restore to any point in time (from oldest backup to 5 minutes ago)
        
        • 1 to 35 days of retention, set 0 to disable automated backups
        
- Manual DB Snapshots
• Manually triggered by the user
• Retention of backup for as long as you want
- Restoring MySQL RDS database from S3
    
    • Create a backup of your on-premises database
    • Store it on Amazon S3 (object storage)
    • Restore the backup file onto a new RDS instance running MySQL
    
- **Trick: in a stopped RDS database, you will still pay for storage. If you plan on stopping it for a long time, you should snapshot & restore instead**
- **Aurora Backup**
    - Automated backups
    • 1 to 35 days (cannot be disabled)
    • point-in-time recovery in that timeframe
    - Manual DB Snapshots
    • Manually triggered by the user
    • Retention of backup for as long as you want
    - Restoring MySQL Aurora cluster from S3
    • Create a backup of your on-premises database using Percona XtraBackup
    • Store the backup file on Amazon S3
    • Restore the backup file onto a new Aurora cluster running MySQL
    - Aurora Database Cloning
    • Create a new Aurora DB Cluster from an existing one
    • Faster than snapshot & restore
    • Uses copy-on-write protocol
    • Initially, the new DB cluster uses the same data volume as the original DB cluster (fast and efficient – no copying is needed)
    • When updates are made to the new DB cluster data, then additional storage is allocated and data is copied to be separated
    • Very fast & cost-effective
    • Useful to create a “staging” database from a “production” database without impacting the production database

### RDS & Aurora Security

- **At-rest encryption:**
    - Database master & replicas encryption using AWS KMS – must be defined as launch time
    - If the master is not encrypted, the read replicas cannot be encrypted
    - To encrypt an un-encrypted database, go through a DB snapshot & restore as encrypted
- **In-flight encryption:** TLS-readybydefault,usetheAWSTLSrootcertificates client-side
- **IAM Authentication:** IAM roles to connect to your database (instead of username/pw)
- **Security Groups:** Control Network access to your RDS / Aurora DB
- **No SSH available except on RDS Custom**
- Audit Logs can be enabled and sent to CloudWatch Logs for longer retention

### RDS Proxy

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2034.png)

- Fully managed database proxy for RDS
- **Allows apps to pool and share DB connections established with the database**
- **Improving database efficiency by reducing the stress on database resources (e.g., CPU, RAM) and minimize open connections (and timeouts)**
- **Serverless, autoscaling, highly available (multi-AZ)**
- Reduced RDS & Aurora failover time by up 66%
- Supports RDS (MySQL, PostgreSQL, MariaDB, MS SQL Server) and Aurora (MySQL, PostgreSQL)
- No code changes required for most apps
- Enforce IAM Authentication for DB, and securely
- store credentials in AWS Secrets Manager
- **RDS Proxy is never publicly accessible (must be accessed from VPC)**

### 문제

Question 4:

**RDS 데이터베이스에 읽기 전용 복제본을 설정해 두었지만, 소셜 미디어 포스트를 업데이트할 시 업데이트가 바로 이루어지지 않는다는 점에 대해 사용자들이 불만을 토로하고 있습니다. 이 경우, 가능성이 있는 원인은 무엇일까요?**
• **애플리케이션에 버그가 존재함**
• **읽기 전용 복제본은 비동기 복제를 지니므로, 사용자들은 최종 일관성만을 읽게 됨**
• **그 대신 다중 AZ를 설정했었어야 함**

답 : 읽기 전용 복제본은 비동기 복제를 지니므로, 사용자들은 최종 일관성만을 읽게 됨

Question 11:

**RDS PostgreSQL 데이터베이스의 특정 리전에서 정전이 발생했을 때 데이터베이스가 신속하게 다른 AWS 리전에서 읽고 쓰는 작업을 할 수 있도록 재해 복구 전략을 수립하려고 합니다. DR 데이터베이스는 가용성이 매우 높아야 합니다. 가장 적합한 방식은 무엇입니까?**

답 : 다른 리전에 읽기 전용 복제본을 만들고 해당 읽기 전용 복제본에서 다중 AZ를 활성화한다.

Question 14:

**암호화되지 않은 RDS DB 인스턴스를 암호화하는 방법은 무엇인가요?**

답 : 암호화되지 않은 RDS DB 인스턴스의 스냅샷을 생성하고, 스냅샷을 복사해 암호화 활성화하기 박스를 체크한 뒤, RDS DB인스턴스를 암호화되지 않은 스냅샷에서 복구하기.

Question 18:**프로덕션에서 실행 중인 한 애플리케이션이 Aurora 클러스터를 데이터베이스로 사용하고 있습니다. 여러분의 개발 팀은 필요할 경우 많은 양의 워크로드를 수행할 수 있는, 스케일이 축소된 애플리케이션에서 애플리케이션의 버전을 실행하려 합니다. 애플리케이션은 대부분의 시간 동안 사용되지 않습니다. CIO는 여러분에게 팀을 도와 비용을 최소화하는 동시에 이를 달성해 줄 것을 요청했습니다. 어떤 방법을 사용해야 할까요?**

답
• Aurora 글로벌 데이터베이스 사용하기
• RDS 데이터베이스 사용하기
**• Aurora 서버리스 사용하기**
• EC2에 Aurora를 실행하고, EC2 인스턴스가 밤에는 차단되도록 하는 스크립트 작성하기

## Elastic Cache

• The same way RDS is to get managed Relational Databases...
• **ElastiCache is to get managed Redis or Memcached**
• Caches are in-memory databases with really high performance, low latency
• Helps reduce load off of databases for read intensive workloads
• Helps make your application stateless
• AWS takes care of OS maintenance / patching, optimizations, setup, configuration, monitoring, failure recovery and backups
• **Using ElastiCache involves heavy application code changes**

### ElastiCache Solution Architecture - DB Cache

• Applications queries ElastiCache, if not available, get from RDS and store in ElastiCache.
• Helps relieve load in RDS
• Cache must have an invalidation strategy to make sure only the most current data is used in there.

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2035.png)

### ElastiCache Solution Architecture – User Session Store

• User logs into any of the application
• The application writes the session data into ElastiCache
• The user hits another instance of our application
• The instance retrieves the data and the user is already logged in

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2036.png)

### **ElastiCache – Redis vs Memcached**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2037.png)

### Cache Security

- **ElastiCache do not supports IAM Authentication for Redis**
- **IAM policies on ElastiCache are only used for AWS API-level security**

### Patterns for Elastic Cache

- **Lazy Loading:** all the read data is cached, data can become stale in cache
- **Write Through:** Adds or update data in the cache when written to a DB (no stale data)
- **Session Store:** store temporary session data in a cache (using TTL features)
- Quote:There are only two hard things in Computer Science: cache invalidation and naming things

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2038.png)

## Route53

### DNS Terminologies

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2039.png)

- **Domain Registrar:** Amazon Route 53, GoDaddy, ...
- **DNS Records:** A, AAAA, CNAME, NS, ...
- **Zone File:** contains DNS records
- **Name Server:** resolves DNS queries (Authoritative or Non-Authoritative)
- **Top Level Domain (TLD)**: .com, .us, .in, .gov, .org, ...
- **Second Level Domain (SLD)**: [amazon.com](http://amazon.com/), [google.com](http://google.com/), ...

### How DNS Works

- Cache TTL을 설정하면 IP address가 바뀌더라도 설정한 기간 동안은 기존 IP address로 접속을 시도함.
- 

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2040.png)

### Route 53 – Records

- How you want to route traffic for a domain
- Each record contains:
    - Domain/subdomain Name – e.g., example.com
    - Record Type – e.g., A or AAAA
    - Value – e.g., 12.34.56.78
    - Routing Policy – how Route 53 responds to queries
    - TTL – amount of time the record cached at DNS Resolvers
- Route 53 supports the following DNS record types:
    - (must know)**A** /AAAA / **CNAME** / **NS**
    - **A:** Map a hostname to IPv4
    - **CNAME:** Map a hostname to another hostname
        
        **CNAME을 쓰기보단 Alias를 쓰는 방법이 더 효과적임.**
        
        • The target is a domain name which must have an A or AAAA record
        • Can’t create a CNAME record for the top node of a DNS namespace (Zone Apex)
        • Example: you can’t create for example.com, but you can create for www.example.com
        
    - **NS**: Name Servers for the Hosted Zone

### CNAME vs Alias

- **AWS Resources (Load Balancer, CloudFront...) expose an AWS hostname**: lb1-1234.us-east-2.elb.amazonaws.com and you want myapp.mydomain.com
- **CNAME:**
    - **Points a hostname to any other hostname**. (app.mydomain.com => blabla.anything.com)
    - ONLY FOR NON ROOT DOMAIN (aka. something.mydomain.com)
- **Alias:**
    - **Points a hostname to an AWS Resource** (app.mydomain.com => blabla.amazonaws.com)
    - Works for ROOT DOMAIN and NON ROOT DOMAIN (aka mydomain.com)
    - **Free of charge**
    - **Native health check**

### Alias

- Maps a hostname to an AWS resource
- An extension to DNS functionality
- Automatically recognizes changes in the resource’s IP addresses
- Unlike CNAME, it can be used for the top node of a DNS namespace (Zone Apex), e.g.: example.com
- **Alias Record is always of type A/AAAA for AWS resources (IPv4 / IPv6)**
- **You can’t set the TTL**
- **Alias Records Targets**
    - **You cannot set an ALIAS record for an EC2 DNS name**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2041.png)
    

### Route 53 – Hosted Zones

- **A container for records that define how to route traffic to a domain and its subdomains**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2042.png)
    
- **Public Hosted Zones** – contains records that specify how to route traffic on the Internet (public domain names) [application1.mypublicdomain.com](http://application1.mypublicdomain.com/)
- **Private Hosted Zones** – contain records that specify how you route traffic within one or more VPCs (private domain names) application1.company.internal
- You pay $0.50 per month per hosted zone

### Route 53 – RecordsTTL (TimeTo Live)

- High TTL – e.g., 24 hr
• Less traffic on Route 53
• Possibly outdated records
- Low TTL – e.g., 60 sec.
• More traffic on Route 53 ($$)
• Records are outdated for less time
• Easy to change records
- Except for Alias records,TTL is mandatory for each DNS record

### **Route 53 – Routing Policies**

- **Don’t get confused by the word *“Routing”***
    
    • It’s not the same as Load balancer routing which routes the traffic
    • DNS does not route any traffic, it only responds to the DNS queries
    
- **Simple**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2043.png)
    
    - **I**f multiple values are returned, a random one is chosen by the client
    - When Alias enabled, specify only one AWS resource
    - Can’t be associated with Health Checks
- **Weighted**
    - Can be associated with Health Checks
    - Assign a weight of 0 to a record to stop sending
    traffic to a resource
    ****
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2044.png)
    
- **Latency based**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2045.png)
    
    - Redirect to the resource that has the least latency close to us
    - Super helpful when latency for users is a priority
    - Latency is based on traffic between users and AWS
    Regions
    - Can be associated with Health Checks (has a failover
    capability)
- **Failover**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2046.png)
    
- **Geolocation**
    - Different from Latency-based!
    - This routing is based on user location Specify location by Continent, Country or by US State (if there’s overlapping, most precise location selected)
    - **Should create a “Default” record (in case there’s no match on location)**
- **Geoproximity (using Route 53 Traffic Flow feature)**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2047.png)
    
- **Multi-Value Answer**
    - **Use when routing traffic to multiple resources**
    - **Multi-Value is not a substitute for having an ELB**

### Health Checks

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2048.png)

- **HTTP Health Checks are only for public resources**
- Health Check => Automated DNS Failover:
    1. **Health checks that monitor an endpoint (application, server, other AWS resource)**
        1. **About 15 global health checkers will check the
        endpoint health**
            
            • Healthy/UnhealthyThreshold–3(default)
            • Interval – 30 sec (can set to 10 sec – higher cost)
            Supported protocol:HTTP, HTTPS and TCP
            • If > 18% of health checkers report the endpoint is
            healthy, Route 53 considers it Healthy. Otherwise, it’s Unhealthy
            • Ability to choose which locations you want Route 53 to use
            
        2. **Configure you router/firewall to allow incoming
        requests from Route 53 Health Checkers**
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2049.png)
        
    2. **Health checks that monitor other health
    checks (Calculated Health Checks)**
        1. Combine the results of multiple Health
        Checks into a single Health Check
        2. You can use OR, AND, or NOT
        Can monitor up to 256 Child Health Checks
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2050.png)
        
        1. 
    3. **Health checks that monitor CloudWatch
    Alarms (full control !!) – e.g., throttles of
    DynamoDB, alarms on RDS, custom metrics,
    ... (helpful for private resources)**
        1. **Route 53 health checkers are outside the
        VPC.**
        2. **They can’t access private endpoints
        (private VPC or on-premises resource)**
        3. You can create a CloudWatch Metric and
        associate a CloudWatch Alarm, then
        create a Health Check that checks the
        alarm itself
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2051.png)
        

## Beanstalk

- **Elastic Beanstalk is a developer centric view of deploying an application on AWS**
- It uses all the component’s we’ve seen before: EC2, ASG, ELB, RDS, ...
- Managed service
    - Automatically handles capacity provisioning, load balancing, scaling, application health monitoring, instance configuration, ...
    - Just the application code is the responsibility of the developer

### Components

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2052.png)

- **Application:** collection of Elastic Beanstalk components (environments,versions, configurations, ...)
- **Application Version:** an iteration of your application code
- **Environment**
    - Collection of AWS resources running an application version (only one application version at a time)
    - Tiers:
        - WebServerEnvironmentTier
            
            ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2053.png)
            
        - WorkerEnvironmentTier
            
            ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2054.png)
            

## S3

- **Many websites use Amazon S3 as a backbon**

### Use Case

- Backup and storage
- Disaster Recovery
- Archive
- Hybrid Cloud storage
- Application hosting
- Media hosting
- Data lakes & big data analytics
- Software delivery
- Static website

### Buckets

- Amazon S3 allows people to store objects (files) in “buckets” (directories)
- **Buckets must have a globally unique name (across all regions all accounts)**
- Buckets are defined at the region level
- **S3 looks like a global service but buckets are created in a region**

### S3 Object - Key

- Objects (files) have a Key
- **The key is the FULL path:**
    - s3://my-bucket/my_file.txt
    - s3://my-bucket/my_folder1/another_folder/my_file.txt
- The key is composed of prefix + object name
    - s3://my-bucket/my_folder1/another_folder/my_file.txt
- **There’s no concept of “directories” within buckets (although the UI will trick you to think otherwise)**

### S3 Object - Contents

- Object values are the content of the body:
    - Max. Object Size is 5TB (5000GB)
    - **If uploading more than 5GB, must use “multi-part upload”**
- **Metadata** (list of text key / value pairs – system or user metadata)
- **Tags** (Unicode key / value pair – up to 10) – useful for security / lifecycle
- **Version ID** (if versioning is enabled)

### Amazon S3 – Security

- **User-Based**
• IAM Policies – which API calls should be allowed for a specific user from IAM
- **Resource-Based**
• Bucket Policies – bucket wide rules from the S3 console - allows cross account 
• Object Access Control List (ACL) – finer grain (can be disabled)
• Bucket Access Control List (ACL) – less common (can be disabled)
- Note: an IAM principal can access an S3 object if
    - The user IAM permissions ALLOW it
    - **OR** the resource policy ALLOWS it
    - **AND** there’s no explicit DENY
- Encryption: encrypt objects in Amazon S3 using encryption keys

### S3 Bucket Policies

- JSON based policies
• Resources: buckets and objects
• Effect: Allow / Deny
• Actions: Set of API to Allow or Deny
• Principal:The account or user to apply the policy to
- **Use S3 bucket for policy to**:
• Grant public access to the bucket
• Force objects to be encrypted at upload
• Grant access to another account (Cross Account)
- **Public Access - use Bucket Policy**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2055.png)
    

### **IAM Permssions**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2056.png)

### **IAM Role**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2057.png)

### Bucket settings for Block Public Access

- **These settings were created to prevent company data leaks**
- I**f you know your bucket should never be public, leave these on**
- Can be set at the account level

### Amazon S3 - Versioning

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2058.png)

- **You can version your files in Amazon S3**
- **Protect against unintended deletes (ability to restore a version)**
- **Easy roll back to previous version**
- Notes:
    - **Any file that is not versioned prior to enabling versioning will have version “null”**
    - Suspending versioning does not delete the previous versions

### Amazon S3 – Replication (CRR & SRR)

- Must enable Versioning in source and destination buckets
- **Cross-Region Replication (CRR)**
- **Same-Region Replication (SRR)**
- Buckets can be in different AWS accounts
- **Copying is asynchronous**
- Must give proper IAM permissions to S3
- Use cases:
    - CRR – compliance, lower latency access, replication across accounts
    - SRR – log aggregation, live replication between production and test accounts

### Amazon S3 – Replication (Notes)

- **After you enable Replication, only new objects are replicated**
- For DELETE operations
    - Can replicate delete markers from source to target (optional setting)
    - Deletions with a version ID are not replicated (to avoid malicious deletes)
- **There is no “chaining” of replication**
    - If bucket 1 has replication into bucket 2, which has replication into bucket 3
    - Then objects created in bucket 1 are not replicated to bucket 3

### S3 Durability and Availability

- **Durability:**
    - High durability (99.999999999%, 11 9’s) of objects across multiple AZ
    - If you store 10,000,000 objects with Amazon S3, you can on average expect to incur a loss of a single object once every 10,000 years
    - Same for all storage classes
- **Availability:**
    - Measures how readily available a service is
    - Varies depending on storage class
    - Example: S3 standard has 99.99% availability = not available 53 minutes a year

### S3 Storage Class Comparision

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2059.png)

### Amazon S3 – Moving between Storage Classes

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2060.png)

- You can transit objects between storage classes
- For infrequently accessed object, move them to Standard IA
- For archive objects that you don’t need fast access to, move them to Glacier or Glacier Deep Archive
- **Moving objects can be automated using a Lifecycle Rules**

### Amazon S3 – Lifecycle Rules

- **Transition Actions** – configure objects to transition to another storage class
    - Move objects to Standard IA class 60 days after creation
    - Move to Glacier for archiving after 6 months
- **Expiration actions** – configure objects to expire (delete) after some time
    - Access log files can be set to delete after a 365 days
    - **Can be used to delete old versions of files (if versioning is enabled)**
    - **Can be used to delete incomplete Multi-Part uploads**
- Rules can be created for a certain prefix (example: s3://mybucket/mp3/*)
- Rules can be created for certain objectsTags (example:Department:Finance)

### Amazon S3 Analytics – Storage Class Analysis

- **Help you decide when to transition objects to the right storage class**
- Recommendations for Standard and Standard IA
- Does NOT work for One-Zone IA or Glacier
- Report is updated daily
- 24 to 48 hours to start seeing data analysis
- **Good first step to put together Lifecycle Rules (or improve them)!**

### **S3 – Requester Pays**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2061.png)

### S3 Event Notifications

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2062.png)

### **S3 Event Notifications with Amazon EventBridge**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2063.png)

### **S3 – Baseline Performance**

- Amazon S3 automatically scales to high request rates, latency 100-200 ms
- **Your application can achieve at least 3,500 PUT/COPY/POST/DELETE**
- **5,500 GET/HEAD requests per second per prefix in a bucket.**

### S3 Performance

- **Multi-Part upload:**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2064.png)
    
    - recommended for files > 100MB,must use for files > 5GB
    - Can help parallelize uploads (speed up transfers)
- **S3 Transfer Acceleration**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2065.png)
    
    - I**ncrease transfer speed by transferring file to an AWS edge location which will forward the data to the S3 bucket in the target region**
    - Compatible with multi-part upload
- **S3 Byte-Range Fetches**
    - Parallelize GETs by requesting specific byte ranges
    - Better resilience in case of failures
    - Can be used to speed up downloads
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2066.png)
        
    - Can be used to retrieve only partial data (for example the head of a file)
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2067.png)
        

### **S3 Select & Glacier Select**

- Retrieve less data using SQL by performing server-side filtering
- **Can filter by rows & columns (simple SQL statements)**
- Less network transfer, less CPU cost client-side

### S3 Batch Operations

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2068.png)

- S3 작업을 일정부분 자동화하기 위한 방법
- Perform bulk operations on existing S3 objects with a single request, example:
    - Modify object metadata & properties
    - Copy objects between S3 buckets
    - Encrypt un-encrypted objects
    - ModifyACLs,tags
    - Restore objects from S3 Glacier
    - Invoke Lambda function to perform custom action on
- A job consists of a list of objects, the action to perform, and optional parameters
- S3 Batch Operations manages retries, tracks progress, sends completion notifications, generate reports ...
- You can use S3 Inventory to get object list and use S3 Select to filter your objects

## S3 - Security

- You can encrypt objects in S3 buckets using one of 4 methods
- Server-Side Encryption (SSE)
    - **Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3) – Enabled by Default**
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2069.png)
        
        - **Encryption using keys handled, managed, and owned by AWS** - Object is encrypted server-side
        - Encryption type is AES-256
        - Must set header "x-amz-server-side-encryption": "AES256"
        - Enabled by default for new buckets & new objects
    - **Server-Side Encryption with KMS Keys stored in AWS KMS (SSE-KMS)**
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2070.png)
        
        - **Encryption using keys handled and managed by AWS KMS (Key Management Service)**
        - KMS advantages: user control + audit key usage using CloudTrail
        - Object is encrypted server side
        - Must set header "x-amz-server-side-encryption": "aws:kms"
        - **SSE-KMS Limitation**
            
            ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2071.png)
            
            - If you use SSE-KMS, you may be impacted by the KMS limits
            - When you upload, it calls the GenerateDataKey KMS API
            - When you download, it calls the Decrypt KMS API
    - **Server-Side Encryption with Customer-Provided Keys (SSE-C)**
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2072.png)
        
        - **Server-Side Encryption using keys fully managed by the customer outside of AWS**
        - Amazon S3 does NOT store the encryption key you provide
        - HTTPS must be used
        - **Encryption key must provided in HTTP headers, for every HTTP request made**
- **Client-Side Encryption**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2073.png)
    
    - **Use client libraries such as Amazon S3 Client-Side Encryption Library**
    - **Clients must encrypt data themselves before sending to Amazon S3**
    - Clients must decrypt data themselves when retrieving from Amazon S3
    - Customer fully manages the keys and encryption cycle
    

### CORS - Cross-Origin Resource Sharing

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2074.png)

- **Origin = scheme (protocol) + host (domain) + port**
    - example: [https://www.example.com](https://www.example.com/) (implied port is 443 for HTTPS, 80 for HTTP)
    - Web Browser based mechanism to allow requests to other origins while
    - Same origin: [**http://example.com/**app1](http://example.com/app1) & [**http://example.com/**app2](http://example.com/app2)
    - Different origins: [http://**www.**example.com](http://www.example.com/) & [http://**other**.example.com](http://other.example.com/)
- **The requests won’t be fulfilled unless the other origin allows for the requests, using CORS Headers (example: Access-Control-Allow-Origin)**

### **Amazon S3 – CORS**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2075.png)

- **If a client makes a cross-origin request on our S3 bucket, we need to enable the correct CORS headers**
- It’s a popular exam question
- You can allow for a specific origin or for * (all origins)

### S3- MFA

- MFA (Multi-Factor Authentication) – force users to generate a code on a device (usually a mobile phone or hardware) before doing important operations on S3
- **MFA will be required to:**
    - **Permanently delete an object version**
    - **Suspend Versioning on the bucket**
- MFA won’t be required to:
    - Enable Versioning
    - List deleted versions
- **To use MFA Delete, Versioning must be enabled on the bucket**
- Only the bucket owner (root account) can enable/disable MFA Delete

### S3 Access Logs

- **For audit purpose, you may want to log all access to S3 buckets**
- Any request made to S3, from any account, authorized or denied, will be logged into another S3 bucket
- That data can be analyzed using data analysis tools...
- **The target logging bucket must be in the same AWS region**
- **Do not set your logging bucket to be the monitored bucket**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2076.png)
    
    - **It will create a logging loop, and your bucket will grow exponentially**

### Amazon S3 – Pre-Signed URLs

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2077.png)

- Generate pre-signed URLs using the S3 Console, AWS CLI or SDK
- URL Expiration
    - S3 Console – 1 min up to 720 mins (12 hours)
    - AWS CLI – configure expiration with --expires-in parameter in seconds (default 3600 secs, max. 604800 secs ~ 168 hours)
- **Users given a pre-signed URL inherit the permissions of the user that generated the URL for GET / PUT**
- Examples:
    - **Allow only logged-in users to download a premium video from your S3 bucket**
    - Allow an ever-changing list of users to download files by generating URLs dynamically
    - **Allow temporarily a user to upload a file to a precise location in your S3 bucket**
    

### S3 Glacier Vault Lock

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2078.png)

- **Adopt a WORM (Write Once Read Many) model**
- Create a Vault Lock Policy
- Lock the policy for future edits
(can no longer be changed or deleted)
- Helpful for compliance and data retention

### S3 Object Lock (versioning must be enabled)

- **Adopt a WORM (Write Once Read Many) model**
- Block an object version deletion for a specified amount of time
- **Retention mode - Compliance:**
    - **Object versions can't be overwritten or deleted by any user, including the root user**
    - Objects retention modes can't be changed, and retention periods can't be shortened
- **Retention mode - Governance:**
    - **Most users can't overwrite or delete an object version or alter its lock settings**
    - **Some users have special permissions to change the retention or delete the object**
- **Retention Period:** protect the object for a fixed period, it can be extended
- **Legal Hold:**
    - protect the object indefinitely, independent from retention period
    - can be freely placed and removed using the s3:PutObjectLegalHold IAM permission

### **S3 – Access Points**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2079.png)

- **Access Points simplify security management for S3 Buckets**
- Each Access Point has:
    - **its own DNS name (Internet Origin or VPC Origin)**
    - an access point policy (similar to bucket policy) – manage security at scale
- **S3 - Access Points**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2080.png)
    
    - **We can define the access point to be accessible only from within the VPC**
    - You must create a VPC Endpoint to access the Access Point (Gateway or Interface Endpoint)
    - The VPC Endpoint Policy must allow access to the target bucket and Access Point

### S3 Object Lambda

- **Use AWS Lambda Functions to change the object before it is retrieved by the caller application**
- **Only one S3 bucket is needed, on top of which we create S3 Access Point and S3 Object Lambda Access Points.**
- **Use Cases:**
    - Redacting personally identifiable information for analytics or non- production environments.
    - Converting across data formats,such as converting XML to JSON.
    - Resizing and watermarking images on the fly using caller-specific details, such as the user who requested the object.

## Global Infrastructure

### Amazon CloudFront

- Content Delivery Network (CDN)
- Improves read performance, content is cached at the edge
- Improves users experience
- 216 Point of Presence globally (edge
locations)
- **DDoS protection (because worldwide), integration with Shield, AWS Web Application Firewall**

### CloudFront – Origins

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2081.png)

- **S3 bucket**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2082.png)
    
    - **For distributing files and caching them at the edge**
    - **Enhanced security with CloudFront Origin Access Control (OAC)**
    - OAC is replacing Origin Access Identity(OAI)
    - CloudFront can be used as an ingress (to upload files to S3)
- **CloudFront vs S3 Cross Region Replication**
    - CloudFront:
        - **Global Edge network**
        - Files are cached for a TTL (maybe a day)
        - Great for static content that must be available everywhere
    - Cross Region Replication:
        - **Must be setup for each region you want replication to happen**
        - Files are updated in near real-time
        - Read only
        - Great for dynamic content that needs to be available at low-latency in few regions
- **Custom Origin (HTTP)**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2083.png)
    
    - Application Load Balancer
    - EC2 instance
    - S3 website (must first enable the bucket as a static S3 website)
    - Any HTTP backend you want

### CloudFront Geo Restriction

- **You can restrict who can access your distribution**
    - **Allowlist:** Allow your users to access your content only if they're in one of the countries on a list of approved countries.
    - **Blocklist:** Prevent your users from accessing your content if they're in one of the countries on a list of banned countries.
- The “country” is determined using a 3rd party Geo-IP database
- Use case: Copyright Laws to control access to content

### CloudFront – Price Classes

- You can reduce the number of edge locations for cost reduction
    - Three price classes:
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2084.png)
        
    1. Price Class All: all regions – best performance
    2. Price Class 200: most regions, but excludes the most expensive regions
    3. Price Class 100: only the least expensive regions

### CloudFront -Cache Invalidations

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2085.png)

- **In case you update the back-end origin, CloudFront doesn’t know about it and will only get the refreshed content after the TTL has expired**
- **However, you can force an entire or partial cache refresh (thus bypassing the TTL) by performing a CloudFront Invalidation**
- You can invalidate all files (*) or a special path (/images/*)

### AWS Global Accelerator

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2086.png)

- **Leverage the AWS internal network to route to your application**
- 2 Anycast IP are created for your application
- The Anycast IP send traffic directly to Edge Locations
- The Edge locations send the traffic to your application
- **Global Accelerator Works with Elastic IP, EC2 instances, ALB, NLB, public or private**
- **Consistent Performance**
    - **Intelligent routing to lowest latency and fast regional failover**
    - No issue with client cache (because the IP doesn’t change)
    - **Internal AWS network**
- **Health Checks**
    - **Global Accelerator performs a health check of your applications**
    - Helps make your application global (failover less than 1 minute for unhealthy) - Great for disaster recovery (thanks to the health checks)
- **Security**
    - **only 2 external IP need to be whitelisted**
    - **DDoS protection thanks to AWS Shield**

### Unicast IP vs Anycast IP

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2087.png)

- **Unicast IP:** one server holds one IP address Client
- **Anycast IP: all servers hold the same IP address and the client is routed to the nearest one**

### AWS Global Accelerator vs CloudFront

- They both use the AWS global network and its edge locations around the world
- Both services integrate with AWS Shield for DDoS protection.
- **CloudFront**
    - **Improves performance for both cacheable content (such as images and videos)**
    - **Dynamic content(such as API acceleration and dynamic site delivery)**
    - Content is served at the edge
- **Global Accelerator**
    - Improves performance for a wide range of applications over TCP or UDP
    - **Proxying packets at the edge to applications running in one or more AWS Regions.**
    - Good fit for non-HTTP use cases,such as gaming(UDP),IoT(MQTT),or VoiceoverIP
    - Good for HTTP use cases that require static IP addresses
    - Good for HTTP use cases that required deterministic,fast regional failover

## **Advanced Storage on AWS**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2088.png)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2089.png)

### Snowball Edge (for data transfers)

- **Physical data transport solution:move TBs or PBs of data in or out of AWS**
- Alternative to moving data over the network (and paying network fees)
- Pay per data transfer job
- Provide block storage and Amazon S3-compatible object storage
- **Snowball Edge Storage Optimized**
    - **80 TB of HDD capacity for block volume and S3 compatible object storage**
- **Snowball Edge Compute Optimized**
    - 42 TB of HDD or 28TB NVMe capacity for block volume and S3 compatible object storage
- **Use cases: large data cloud migrations, disaster recovery**

### AWS Snowcone & Snowcone SSD

- **Small, portable computing, anywhere, rugged & secure, withstands harsh environments**
- Light (4.5 pounds, 2.1 kg)
- Device used for edge computing, storage, and data
transfer
- Snowcone – 8 TB of HDD Storage
- Snowcone SSD – 14 TB of SSD Storage
- Use Snowcone where Snowball does not fit (space- constrained environment)
- Must provide your own battery / cables
- **Can be sent back to AWS offline, or connect it to
internet and use AWS DataSync to send data**

### AWS Snowmobile

- Transfer exabytes of data (1 EB = 1,000 PB = 1,000,000 TBs)
- Each Snowmobile has 100 PB of capacity (use multiple in parallel)
- High security: temperature controlled, GPS, 24/7 video surveillance - Better than Snowball if you transfer more than 10 PB

### What is Edge Computing?

- **Process data while it’s being created on an edge location**
    - **A truck on the road,a ship on the sea,a mining station underground**
- **These locations may have**
    - Limited / no internet access
    - Limited / no easy access to computing power
- **We setup a Snowball Edge / Snowcone device to do edge computing**
- **Use cases of Edge Computing:**
    - Preprocess data
    - Machine learning at the edge
    - Transcoding media streams
- **Eventually (if need be) we can ship back the device to AWS (for transferring data for example)**

### Snow Family – Edge Computing

- Snowcone & Snowcone SSD (smaller)
    - 2 CPUs, 4 GB of memory, wired or wireless access - USB-C power using a cord or the optional battery
- Snowball Edge – Compute Optimized
    - 104 vCPUs, 416 GiB of RAM
    - Optional GPU (useful for video processing or machine learning) - 28 TB NVMe or 42TB HDD usable storage
- Snowball Edge – Storage Optimized
    - Upto 40 vCPUs,80 GiB of RAM, 80TBstorage
    - Object storage clustering available
- All: Can run EC2 Instances & AWS Lambda functions (using AWS IoT Greengrass)
- Long-term deployment options: 1 and 3 years discounted pricing

### AWS OpsHub

- Historically, to use Snow Family devices, you needed a CLI (Command Line Interface tool)
- Today, you can use AWS OpsHub (a software you install on your computer / laptop) to manage your Snow Family Device

### Solution Architecture: Snowball into Glacier

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2090.png)

- **Snowball cannot import to Glacier directly**
- **You must use Amazon S3 first, in combination with an S3 lifecycle policy**

### Amazon FSx

- **Launch 3rd party high-performance file systems on AWS**

### Amazon FSx for Windows (File Server)

- FSx for Windows is a fully managed Windows file system share drive
- **Supports SMB protocol & Windows NTFS**
- Microsoft Active Directory integration,ACLs,user quotas
- **Can be mounted on Linux EC2 instances**
- Supports Microsoft's Distributed File System (DFS) Namespaces (group files across multiple FS)
- Scale up to 10s of GB/s, millions of IOPS, 100s PB of data
- Storage Options:
    - SSD – latency sensitive workloads (databases, media processing, data analytics, ...)
    - HDD – broad spectrum of workloads (home directory, CMS, ...)
- Can be accessed from your on-premises infrastructure (VPN or Direct Connect)
- Can be configured to be Multi-AZ (high availability)
- **Data is backed-up daily to S3**

### Amazon FSx for Lustre

- Lustre is a type of parallel distributed file system, for large-scale computing
- The name Lustre is derived from “Linux” and “cluster
- **Machine Learning, High Performance Computing (HPC)**
- Video Processing, Financial Modeling, Electronic Design Automation
- Scales up to 100s GB/s, millions of IOPS, sub-ms latencies
- Storage Options:
    - SSD – low-latency, IOPS intensive workloads, small & random file operations
    - HDD – throughput-intensive workloads, large & sequential file operations
- Seamless integration with S3
    - Can “read S3” as a file system (through FSx)
    - Can write the output of the computations back to S3 (through FSx)
- Can be used from on-premises servers (VPN or Direct Connect)

### FSx Lustre - File System Deployment Options

- **Scratch File System - short-term processing**
    - **Temporary storage**
    - Data is not replicated (doesn’t persist if file server fails)
    - **High burst (6x faster, 200MBps per TiB)**
    - Usage: short-term processing, optimize
    costs
- **Persistent File System - long-term processing**
    - **Long-term storage**
    - **Data is replicated within same AZ**
    - Replace failed files within minutes
    - Usage: long-term processing, sensitive data

### Amazon FSx for NetApp ONTAP

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2091.png)

- Managed NetApp ONTAP on AWS
- **File System compatible with NFS, SMB, iSCSI protocol**
- Move workloads running on ONTAP or NAS to AWS
- Works with:
    - Linux
    - Windows
    - MacOS
    - VMware Cloud on AWS
    - Amazon Workspaces & AppStream 2.0
    - Amazon EC2, ECS and EKS
- Storage shrinks or grows automatically
- Snapshots,replication,low-cost,compression and data
- **Point-in-time instantaneous cloning (helpful for testing new workloads)**

### Amazon FSx for OpenZFS

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2092.png)

- Managed OpenZFS file system on AWS
- **File System compatible with NFS (v3, v4, v4.1, v4.2)**
- Move workloads running on ZFS to AWS
- Works with:
    - Linux
    - Windows
    - MacOS
    - VMware Cloud on AWS
- **Up to 1,000,000 IOPS with < 0.5ms latency**
- Snapshots, compression and low-cost
- **Point-in-time instantaneous cloning (helpful for testing new workloads)**

### Hybrid Cloud for Storage

- **”hybrid cloud” - Part of your infrastructure is on the cloud - Part of your infrastructure is on-premises**
- **This can be due to**
    - Long cloud migrations
    - Security requirements
    - Compliance requirements
    - IT strategy
- **S3 is a proprietary storage technology (unlike EFS / NFS), so how do you expose the S3 data on-premises?**
    - AWS Storage Gateway!

### AWS Gateway

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2093.png)

### AWS Storage Gateway

- **Bridge between on-premises data and cloud data**
- Use cases:
    - disaster recovery
    - backup & restore
    - tiered storage
    - on-premises cache & low-latency files access
- **S3 File Gateway**
    - **Configured S3 buckets are accessible using the NFS and SMB protocol**
    - **Most recently used data is cached in the file gateway**
    - Supports S3 Standard, S3 StandardIA, S3 OneZoneA, S3 IntelligentTiering
    - Transition to S3 Glacier using a Lifecycle Policy
    - Bucket access using IAM roles for each File Gateway
    - SMB Protocol has integration with Active Directory (AD) for user authentication
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2094.png)
    
- **FSx File Gateway**
    - Native access to Amazon FSx for Windows File Server
    - **Local cache for frequently accessed data**
    - Windows native compatibility (SMB, NTFS, Active Directory...) - Useful for group file shares and home directories
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2095.png)
    
- **Volume Gateway**
    - **Block storage using iSCSI protocol backed by S3**
    - **Backed by EBS snapshots which can help restore on-premises volumes!**
    - **Cached volumes: low latency access to most recent data**
    - **Stored volumes: entire dataset is on premise, scheduled backups to S3**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2096.png)
    
- **Tape Gateway**
    - Some companies have backup processes using physical tapes (!)
    - With Tape Gateway, companies use the same processes but, in the cloud - VirtualTape Library (VTL) backed by Amazon S3 and Glacier
    - Back up data using existing tape-based processes (and iSCSI interface)
    - Works with leading backup software vendors
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2097.png)
    
- **Hardware Appliance**
    - **Using Storage Gateway means you need on-premises virtualization**
    - Otherwise, you can use a Storage Gateway Hardware Appliance
    - You can buy it on [amazon.com](http://amazon.com/)
    - Works with File Gateway,Volume Gateway,
    - Has the required CPU, memory, network, SSD cache resources
    - Helpful for daily NFS backups in small data centers
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2098.png)
    
    ### AWS Transfer Familiy
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2099.png)
    
    - **A fully-managed service for file transfers into and out of Amazon S3 or Amazon EFS using the FTP protocol**
    - Supported Protocols
        - AWS Transfer for FTP (File Transfer Protocol (FTP))
        - AWS Transfer for FTPS (File Transfer Protocol over SSL (FTPS))
        - AWS Transfer for SFTP (Secure File Transfer Protocol (SFTP))
    - Managed infrastructure, Scalable, Reliable, Highly Available (multi-AZ)
    - Pay per provisioned endpoint per hour + data transfers in GB
    - Store and manage users’ credentials within the service
    - Integrate with existing authentication systems (Microsoft Active Directory, LDAP, Okta, Amazon Cognito, custom)
    - Usage: sharing files, public datasets, CRM, ERP, ...
    
    ### AWS DataSync
    
    - **Move large amount of data to and from**
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20100.png)
        
        - On-premises / other cloud to AWS (NFS, SMB, HDFS, S3 API...) – needs agent
        - AWS to AWS (different storage services) – no agent needed
    - **Can synchronize to:**
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20101.png)
        
        - Amazon S3 (any storage classes – including Glacier)
        - Amazon EFS
        - Amazon FSx (Windows, Lustre, NetApp, OpenZFS...)
    - **Replication tasks can be scheduled hourly, daily, weekly**
    - File permissions and metadata are preserved (NFS POSIX, SMB...)
    - One agent task can use 10 Gbps, can setup a bandwidth limit

## DB Summary

### Data base Types

- **RDBMS** (= SQL / OLTP): RDS, Aurora – great for joins
- **NoSQL database** – no joins, no SQL : DynamoDB (~JSON), ElastiCache (key / value pairs), Neptune (graphs), DocumentDB (for MongoDB), Keyspaces (for Apache Cassandra)
- **Object Store**: S3 (for big objects) / Glacier (for backups / archives)
- **Data Warehouse (= SQL Analytics / BI)**: Redshift (OLAP), Athena, EMR
- **Search**: OpenSearch (JSON) – free text, unstructured searches
- **Graphs**: Amazon Neptune – displays relationships between data
- **Ledger**: Amazon Quantum Ledger Database
- **Time series**: Amazon Timestream

### Amazon RDS – Summary

- Managed PostgreSQL / MySQL / Oracle / SQL Server / MariaDB / Custom - Provisioned RDS Instance Size and EBS Volume Type & Size
- Auto-scaling capability for Storage
- Support for Read Replicas and Multi AZ
- Security through IAM, Security Groups, KMS , SSL in transit
- Automated Backup with Point in time restore feature (up to 35 days)
- Manual DB Snapshot for longer-term recovery
- Managed and Scheduled maintenance (with downtime)
- Support for IAM Authentication, integration with Secrets Manager
- RDS Custom for access to and customize the underlying instance (Oracle & SQL Server)
- Use case: Store relational datasets (RDBMS / OLTP), perform SQL queries, transactions

### Amazon Aurora – Summary

- Compatible API for PostgreSQL/MySQL,separation of storage and compute
- **Storage : data is stored in 6 replicas,across 3 AZ – highly available,self-healing,auto-scaling**
- Compute : Cluster of DB Instance across multiple AZ, auto-scaling of ReadReplicas
- Cluster : Custom endpoints for writer and reader DB instances
- Same security / monitoring / maintenance features as RDS
- Know the backup & restore options for Aurora
- **Aurora Serverless – for unpredictable/intermittent workloads,no capacity planning**
- **Aurora Multi-Master** – for continuous writes failover (high write availability)
- **Aurora Global:** up to 16 DB Read Instances in each region, < 1 second storage replication
- **Aurora Machine Learning:** perform ML using SageMaker & Comprehend on Aurora
- **Aurora Database Cloning:** new cluster from existing one,faster than restoring a snapshot
- Use case: same as RDS, but with less maintenance / more flexibility / more performance / more features

### Amazon ElastiCache – Summary

- Managed Redis / Memcached (similar offering as RDS, but for caches)
- In-memory data store, sub-millisecond latency
- Select an ElastiCache instance type (e.g., cache.m6g.large)
- Support for Clustering (Redis) and Multi AZ, Read Replicas (sharding)
- Security through IAM, Security Groups, KMS, Redis Auth
- Backup / Snapshot / Point in time restore feature
- Managed and Scheduled maintenance
- Requires some application code changes to be leveraged
- Use Case: Key/Value store, Frequent reads, less writes, cache results for DB queries, store session data for websites, cannot use SQL.

### Amazon DynamoDB – Summary

- AWS proprietary technology, managed serverless NoSQL database, millisecond latency
- **Capacity modes: provisioned capacity with optional auto-scaling or on-demand capacity**
- Can replace ElastiCache as a key/value store (storing session data for example, using TTL feature)
- Highly Available,Multi AZ by default,Read and Writes are decoupled, transaction capability
- **DAX cluster for read cache, microsecond read latency**
- Security, authentication and authorization is done through IAM
- Event Processing: DynamoDB Streams to integrate with AWS Lambda, or Kinesis Data Streams
- Global Table feature : active-active setup
- Automated backups up to 35 days with PITR (restore to new table), or on-demand backups
- Export to S3 without using RCU within the PITR window,import from S3 without using WCU
- **Great to rapidly evolve schemas**
- Use Case: Serverless applications development (small documents 100s KB), distributed serverless cache

### Amazon S3 – Summary

- S3 is a... key / value store for objects
- Great for bigger objects, not so great for many small objects
- Serverless, scales infinitely, max object size is 5 TB, versioning capability
- Tiers: S3 Standard, S3 Infrequent Access, S3 Intelligent, S3 Glacier + lifecycle policy
- Features: Versioning, Encryption, Replication, MFA-Delete, Access Logs...
- Security: IAM, Bucket Policies, ACL, Access Points, Object Lambda, CORS, Object/Vault Lock - Encryption: SSE-S3, SSE-KMS, SSE-C, client-side,TLS in transit, default encryption
- Batch operations on objects using S3 Batch, listing files using S3 Inventory
- Performance:Multi-partupload,S3TransferAcceleration,S3Select
- Automation: S3 Event Notifications (SNS, SQS, Lambda, EventBridge)
- Use Cases: static files, key value store for big files, website hosting

### DocumentDB

- Aurora is an “AWS-implementation” of PostgreSQL / MySQL ...
- **DocumentDB is the same for MongoDB (which is a NoSQL database)**
- MongoDB is used to store, query, and index JSON data
- Similar “deployment concepts” as Aurora
- Fully Managed, highly available with replication across 3 AZ
- DocumentDB storage automatically grows in increments of 10GB, up to 64 TB.
- Automatically scales to workloads with millions of requests per seconds

### Amazon Neptune

- **Fully managed graph database**
- A popular graph dataset would be a social network
- Users have friends
- Posts have comments
- Comments have likes from users
- Users share and like posts...
- Highly available across 3 AZ, with up to 15 read replicas
- Build and run applications working with highly connected
datasets – optimized for these complex and hard queries
- Can store up to billions of relations and query the graph with milliseconds latency
- Highly available with replications across multiple AZs
- Great for knowledge graphs (Wikipedia), fraud detection,
recommendation engines, social networking

### Amazon Keyspaces (for Apache Cassandra)

- Apache Cassandra is an open-source NoSQL distributed database
- A managed Apache Cassandra-compatible database service
- Serverless, Scalable, highly available, fully managed by AWS
- Automatically scale tables up/down based on the application’s traffic
- Tables are replicated 3 times across multiple AZ
- Using the Cassandra Query Language (CQL)
- Single-digit millisecond latency at any scale, 1000s of requests per second - Capacity: On-demand mode or provisioned mode with auto-scaling
- Encryption, backup, Point-In-Time Recovery (PITR) up to 35 days
- Use cases: store IoT devices info, time-series data, ...

### Amazon QLDB

- 회계 DB라고 생각하자. Ledger : 회계장부
- QLDB stands for ”Quantum Ledger Database”
- **A ledger is a book recording financial transactions**
- FullyManaged,Serverless,Highavailable,Replicationacross3AZ
- Used to review history of all the changes made to your application data over time
- Immutable system: no entry can be removed or modified, cryptographically verifiable
- 2-3x better performance than common ledger blockchain frameworks, manipulate data using SQL
- **Difference with Amazon Managed Blockchain: no decentralization component, in accordance with financial regulation rules**
[https://docs.aws.amazon.com/qldb/latest/developerguide/ledger-structure.html](https://docs.aws.amazon.com/qldb/latest/developerguide/ledger-structure.html)

### Amazon Timestream

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20102.png)

- Fully managed, fast, scalable, serverless time series database
- Automatically scales up/down to adjust capacity
- Store and analyze trillions of events per day
- **1000s times faster & 1/10th the cost of relational databases**
- Scheduled queries, multi-measure records, SQL compatibility
- Data storage tiering: recent data kept in memory and historical data kept in a cost-optimized storage
- Built-in time series analytics functions (helps you identify patterns in your data in near real-time)
- Encryption in transit and at rest
- **Use cases: IoT apps, operational applications, real-time analytics, ...**

## **AWS Integration & Messaging**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20103.png)

### Amazon SQS

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20104.png)

### SQS – Producing Messages

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20105.png)

- **Produced to SQS using the SDK (SendMessage API)**
- **The message is persisted in SQS until a consumer deletes it**
- Message retention: default 4 days, up to 14 days
- Example: send an order to be processed
    - Order id
    - Customer id
    - Any attributes you want
- SQS standard: unlimited throughput

### SQS – Consuming Messages

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20106.png)

- **Consumers (running on EC2 instances, servers, or AWS Lambda)...**
- **Poll SQS for messages (receive up to 10 messages at a time)**
- Process the messages (example: insert the message into an RDS database)
- **Delete the messages using the DeleteMessage API**

### SQS – Multiple EC2 Instances Consumers

- **SQS with Auto Scaling Group (ASG)**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20107.png)

- **SQS to decouple between application tiers**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20108.png)

- **Consumers receive and process messages in parallel**
- At least once delivery
- Best-effort message ordering
- **Consumers delete messages after processing them**
- We can scale consumers horizontally to improve throughput of processing

### Amazon SQS - Security

- **Encryption:**
    - In-flight encryption using HTTPS API
    - At-rest encryption using KMS keys
    - Client-side encryption if the client wants to perform encryption/decryption itself
- **Access Controls:** IAM policies to regulate access to the SQS API
- **SQS Access Policies (similar to S3 bucket policies)**
    - Useful for cross-account access to SQS queues
    - Useful for allowing other services (SNS, S3...) to write to an SQS queue

### SQS – Message Visibility Timeout

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20109.png)

- After a message is polled by a consumer, it becomes invisible to other consumers
- By default, the “message visibility timeout” is 30 seconds
- That means the message has 30 seconds to be processed
- After the message visibility timeout is over, the message is “visible” in SQS
- If a message is not processed within the visibility timeout, it will be processed twice
- **A consumer could call the ChangeMessageVisibility API to get more time**
- If visibility timeout is high (hours), and consumer crashes, re-processing will take time
- If visibility timeout is too low (seconds), we may get duplicates

### Amazon SQS - Long Polling

- When a consumer requests messages from the queue, it can optionally “wait” for messages to arrive if there are none in the queue
- This is called Long Polling
- **LongPolling decreases the number of API calls made to SQS while increasing the efficiency and reducing latency of your application**
- The wait time can be between 1 sec to 20 sec (20 sec preferable)
- Long Polling is preferable to Short Polling
- Long polling can be enabled at the queue level
or at the API level using WaitTimeSeconds

### Amazon SQS – Standard Queue

- Oldest offering (over 10 years old)
- Fully managed service, used to decouple applications
- Attributes:
    - Unlimited throughput, unlimited number of messages in queue
    - Default retention of messages: 4 days, maximum of 14 days
    - **Low latency (<10 ms on publish and receive)**
    - **Limitation of 256KB per message sent**
- Can have duplicate messages (at least once delivery, occasionally)
- Can have out of order messages (best effort ordering)

### Amazon SQS – FIFO Queue

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20110.png)

- FIFO = First In First Out (ordering of messages in the queue)
- **Limited throughput: 300 msg/s without batching, 3000 msg/s with**
- Exactly-once send capability (by removing duplicates)
- **Messages are processed in order by the consumer**

### SQS as a buffer to database writes

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20111.png)

### Amazon SNS

- **Pub / Sub Pattern**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20112.png)

- The “event producer” only sends message to one SNS topic
- As many “event receivers” (subscriptions) as we want to listen to the SNS topic notifications
- **Each subscriber to the topic will get all the messages (note: new feature to filter messages)**
- Up to 12,500,000 subscriptions per topic
- 100,000 topics limit

### Amazon SNS – How to publish

- **Topic Publish (using the SDK)**
    - Create a topic
    - Create a subscription (or many)
    - Publish to the topic
- **Direct Publish (for mobile apps SDK)**
    - Create a platform application
    - Create a platform endpoint
    - Publish to the platform endpoint
    - Works with Google GCM, Apple APNS, Amazon ADM...

### Amazon SNS – Security

- **Encryption:**
    - In-flight encryption using HTTPS API
    - At-rest encryption using KMS keys
    - Client-side encryption if the client wants to perform encryption/decryption itself
- **Access Controls:** IAM policies to regulate access to the SNS API
- **SNS Access Policies (similar to S3 bucket policies)**
    - Useful for cross-account access to SNS topics
    - **Useful for allowing other services ( S3...) to write to an SNS topic**

### SNS + SQS: Fan Out

- **Fanout - Chat GPT**
    
    In computer science and distributed systems, the fanout pattern is a messaging pattern where a message is broadcast to multiple recipients simultaneously. The term "fanout" refers to the branching out of a message as it is distributed to multiple recipients, much like the branches of a fan.
    
    In this pattern, a sender sends a single message to a message broker or message queue, which then distributes the message to multiple receivers. Each receiver consumes the message independently, and the sender is not aware of the number of receivers or their identities.
    
    The fanout pattern is commonly used in publish-subscribe messaging systems, where a message is published to a topic and is delivered to all subscribers who have subscribed to that topic. It can also be used in other messaging scenarios where a message needs to be delivered to multiple recipients in a scalable and efficient manner.
    

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20113.png)

- **Push once in SNS, receive in all SQS queues that are subscribers**
- Fully decoupled, no data loss
- SQS allows for: data persistence, delayed processing and retries of work
- Ability to add more SQS subscribers over time
- Make sure your SQS queue access policy allows for SNS to write
- Cross-Region Delivery: works with SQS Queues in other regions

### Application: S3 Events to multiple queues

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20114.png)

- For the same combination of: event type (e.g. object create) and prefix
(e.g. images/) you can only have one S3 Event rule
- If you want to send the same S3 event to many SQS queues, use fan-out

### **Application: SNS to Amazon S3 through Kinesis Data Firehose**

- **SNS can send to Kinesis and therefore we can have the following solutions architecture:**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20115.png)
    

### FIFO Topic

- FIFO = First In First Out (ordering of messages in the topic)
- Similar features as SQS FIFO:
    - Ordering by Message Group ID (all messages in the same group are ordered)
    - Deduplication using a Deduplication ID or Content Based Deduplication
- **Can only have SQS FIFO queues as subscribers**
- Limited throughput (same throughput as SQS FIFO)

### Message Filtering

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20116.png)

### Kinesis Data Streams

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20117.png)

- **Stream Data Storage라고 보는게 좋을 듯**
- **개별 Shard에 Partition Key와 DataBlob으로 구성 된 Record를 저장한다.**
- Retention between 1 day to 365 days
- Ability to reprocess (replay) data
- Once data is inserted in Kinesis, it can’t be deleted (immutability)
- Data that shares the same partition goes to the same shard (ordering)
- **Producers: AWS SDK, Kinesis Producer Library (KPL), Kinesis Agent**
- **Consumers:**
    - Write your own: Kinesis Client Library (KCL), AWS SDK
    - Managed: AWS Lambda, Kinesis Data Firehose, Kinesis Data Analytics,

### Kinesis Data Streams – Capacity Modes

- **Provisioned mode:**
    - You choose the number of shards provisioned, scale manually or using API
    - **Each shard gets 1MB/s in (or 1000 records per second)**
    - **Each shard gets 2MB/s out (classic or enhanced fan-out consumer)**
    - You pay per shard provisioned per hour
- **On-demand mode:**
    - No need to provision or manage the capacity
    - **Default capacity provisioned (4 MB/s in or 4000 records per second)**
    - Scales automatically based on observed throughput peak during the last 30 days
    - Pay per stream per hour & data in/out per GB

### Kinesis Data Streams Security

- Control access / authorization using IAM policies
- Encryption in flight using HTTPS endpoints
- Encryption at rest using KMS
- You can implement encryption/decryption of data on client side (harder)
- VPC Endpoints available for Kinesis to access within VPC
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20118.png)
    
- Monitor API calls using CloudTrail

### Kinesis Firehose

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20119.png)

- **ETL 서비스**
- **주로 Kinesis Data Stream에 저장된 Record를 ETL하여 필요한 서비스에 저장한다.**
- Fully Managed Service, no administration, automatic scaling, serverless - AWS: Redshift / Amazon S3 / OpenSearch
    - 3rd party partner: Splunk / MongoDB / DataDog / NewRelic / ...
    - Custom: send to any HTTP endpoint
    - Pay for data going through Firehose
- **Near Real Time**
    - **60 seconds latency minimum for non full batches**
    - **Or minimum 1MB of data at a time**
- Supports many data formats, conversions, transformations, compression
- Supports custom data transformations using AWS Lambda
- **Can send failed or all data to a backup S3 bucket**

### Kinesis Data Streams vs Firehose

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20120.png)

### Ordering data into kinesis

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20121.png)

- Imagine you have 100 trucks (truck_1, truck_2, ... truck_100) on the road sending their GPS positions regularly into AWS.
- You want to consume the data in order for each truck, so that you can track their movement accurately.
- How should you send that data into Kinesis?
- Answer : send using a “Partition Key” value of the “truck_id”
- **The same key will always go to the same shard**

### Ordering data into SQS

- For SQS standard, there is no ordering.
- For SQS FIFO, if you don’t use a Group ID, messages are consumed in the order they are sent, with only one consumer
- You want to scale the number of consumers, but you want messages to be “grouped” when they are related to each other
- Then you use a Group ID (similar to Partition Key in Kinesis)

### **Kinesis vs SQS ordering**

- **Kinesis Data Streams:**
    - On average you’ll have 20 trucks per shard
    - Trucks will have their data ordered within each shard
    - The maximum amount of consumers in parallel we can have is 5
    - Can receive up to 5 MB/s of data
- **SQS FIFO**
    - You only have one SQS FIFO queue
    - You will have 100 Group ID
    - You can have up to 100 Consumers (due to the 100 Group ID)
    - You have up to 300 messages per second (or 3000 if using batching)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20122.png)

### Amazon MQ

- SQS, SNS are “cloud-native” services: proprietary protocols from AWS
- **Traditional applications running from on-premises may use open protocols such as:MQTT,AMQP,STOMP,Openwire,WSS**
- When migrating to the cloud, instead of re-engineering the application to use SQS and SNS, we can use Amazon MQ
- **Amazon MQ is a managed message broker service for**
- Amazon MQ doesn’t “scale” as much as SQS / SNS
- Amazon MQ runs on servers, can run in Multi-AZ with failover
- Amazon MQ has both queue feature (~SQS) and topic features (~SNS)

### Amazon MQ - High Availability

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20123.png)

## AWS Container

### Docker vs Virtual Machines

- **Docker : Resources are shared with the host => many containers on one server**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20124.png)

### Amazon ECS - EC2 Launch Type

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20125.png)

- **EC2 Launch Type: you must provision & maintain the infrastructure (the EC2 instances)**
- **Each EC2 Instance must run the ECS Agent to register in the ECS Cluster**
- AWS takes care of starting / stopping containers

### Amazon ECS – Fargate LaunchType

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20126.png)

- Launch Docker containers on AWS
- **You do not provision the infrastructure (no EC2 instances to manage)**
- It’s all Serverless!
- You just create task definitions
- AWS just runs ECSTasks for you based on the CPU / RAM you need
- To scale, just increase the number of tasks. Simple - no more EC2 instances

### Amazon ECS – IAM Roles for ECS

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20127.png)

- **Instance Profile 과 Task Role 차이를 이해하자**
- EC2 Instance Profile **(EC2 Launch Type only)**:
    - Used by the ECS agent
    - Makes API calls to ECS ser vice ECR
    - Send container logs to CloudWatch Logs
    - Pull Docker image from ECR
    - Reference sensitive data in Secrets Manager or SSM Parameter Store
- **ECSTask Role:**
    - Allows each task to have a specific role
    - Use different roles for the different ECS Services you run
    - **Task Role is defined in the task definition**

### Amazon ECS – Load Balancer Integrations

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20128.png)

- **Application Load Balancer** supported and works for most use cases
- Network Load Balancer recommended only for high throughput / high performance use cases, or **to pair it with AWS Private Link**

### Amazon ECS – Data Volumes (EFS)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20129.png)

- **Mount EFS file systems onto ECS tasks**
- Works for both EC2 and Fargate launch types
- Tasks running in any AZ will share the same data in the EFS file system
- Fargate + EFS = Serverless
- Use cases: persistent multi-AZ shared storage for
your containers
- **Note: Amazon S3 cannot be mounted as a file system**

### ECS Service Auto Scaling

- Automatically increase/decrease the desired number of ECS tasks
- **Amazon ECS Auto Scaling uses AWS Application Auto Scaling**
    - ECS Service Average CPU Utilization
    - ECS Service Average Memory Utilization-Scale on RAM
    - ALB Request Count Per Target–metric coming from the ALB
- **Target Tracking** – scale based on target value for a specific CloudWatch metric
- **Step Scaling** – scale based on a specified CloudWatch Alarm
- **Scheduled Scaling** – scale based on a specified date/time (predictable changes)
- **ECS Service Auto Scaling (task level) ≠ EC2 Auto Scaling (EC2 instance level)**
    - **ECS Service Auto Scaling = Task(=container) Auto scaling**
    - **ECS Capacity provider = EC2(=Instance) Auto Scaling**
- **Fargate Auto Scaling is much easier to setup (because Serverless)**

### EC2 Launch Type – Auto Scaling EC2 Instances

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20130.png)

- Accommodate ECS Service Scaling by adding underlying EC2 Instances
- **Auto Scaling Group Scaling**
    - Scale your ASG based on CPU Utilization
    - Add EC2 instances over time
- **ECS Cluster Capacity Provider**
    - Used to automatically provision and scale the infrastructure for your ECSTasks
    - Capacity Provider paired with an Auto Scaling Group
    - Add EC2 Instances when you’re missing capacity (CPU, RAM...)

### Arichtecture
****

- **ECS tasks invoked by Event Bridge**
    - ETL이라 보면 될 듯.
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20131.png)
    
- **ECS tasks invoked by Event Bridge Schedule**
    - Batch Processing
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20132.png)
    
- **ECS – SQS Queue Example**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20133.png)
    

### Amazon ECR

- ECR = Elastic Container Registry
- **Store and manage Docker images on AWS**
- Private and Public repository (Amazon ECR Public Gallery [https://gallery.ecr.aws](https://gallery.ecr.aws/))
- Fully integrated with ECS, backed by Amazon S3
- Access is controlled through IAM (permission
errors => policy)
- Supports image vulnerability scanning, versioning, image tags, image lifecycle, ...

### Amazon EKS Overview

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20134.png)

- Amazon EKS = Amazon Elastic Kubernetes Service
- It is a way to launch managed Kubernetes clusters on AWS
- Kubernetes is an open-source system for automatic deployment, scaling and management of containerized (usually Docker) application
- It’s an alternative to ECS, similar goal but different API
- **EKS supports EC2 if you want to deploy worker nodes or Fargate to deploy serverless containers**
- Use case: if your company is already using Kubernetes on-premises or in another cloud, and wants to migrate to AWS using Kubernetes
- Kubernetes is cloud-agnostic (can be used in any cloud – Azure, GCP...)
- **For multiple regions, deploy one EKS cluster per region**
- Collect logs and metrics using CloudWatch Container Insights

### Amazon EKS – Node Types

- **Managed Node Groups**
    - Creates and manages Nodes (EC2 instances) for you
    - Nodes are part of an ASG managed by EKS - Supports On-Demand or Spot Instances
- **Self-Managed Nodes**
    - Nodes created by you and registered to the EKS cluster and managed by an ASG
    - You can use prebuilt AMI - Amazon EKS Optimized AMI - Supports On-Demand or Spot Instances
- **AWS Fargate**
    - No maintenance required; no nodes managed

### Amazon EKS – Data Volumes

- Need to specify StorageClass manifest on your EKS cluster
- Leverages a Container Storage Interface (CSI) compliant driver
- Support for...
    - Amazon EBS
    - Amazon EFS (works with Fargate)
    - Amazon FSx for Lustre
    - Amazon FSx for NetApp ONTAP

### AWS App Runner

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20135.png)

- **Fully managed service that makes it easy to deploy web applications and APIs at scale**
- **No infrastructure experience required**
- Start with your source code or container image
- Automatically builds and deploy the web app
- Automatic scaling, highly available, load balancer, encryption
- VPC access support
- Connect to database, cache, and message queue services
- Use cases: web apps, APIs, microservices, rapid production deployments

## Serverless

### Severless AWS Service

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20136.png)

- AWS Lambda, DynamoDB, AWS Cognito
- AWS API Gateway, Amazon S3, AWS SNS & SQS
- AWS Kinesis Data Firehose, Aurora Serverless,
- Step Functions, Fargate

### Why AWS Lambda

**EC2**

- Virtual Servers in the Cloud
- Limited by RAM and CPU
- Continuously running
- Scaling means intervention to add / remove servers

**Lambda**

- Virtual functions – no servers to manage! - Limited by time - short executions
- Run on-demand
- Scaling is automated!

### Benefits of AWS Lambda

- **Easy Pricing:**
    - **Pay per request and compute time**
    - Free tier of 1,000,000 AWS Lambda requests and 400,000 GBs of compute time
- **Integrated with the whole AWS suite of services**

### AWS Lambda Pricing: example

- You can find overall pricing information here:
[https://aws.amazon.com/lambda/pricing/](https://aws.amazon.com/lambda/pricing/)
- **Pay per calls:**
    - First 1,000,000 requests are free
    - $0.20 per 1 million requests thereafter ($0.0000002 per request)
- Pay per duration: (in increment of 1 ms)
    - 400,000 GB-seconds of compute time per month for FREE - == 400,000 seconds if function is 1GB RAM
    - == 3,200,000 seconds if function is 128 MB RAM
    - After that $1.00 for 600,000 GB-seconds
- It is usually very cheap to run AWS Lambda so it’s very popular

### AWS Lambda Limits to Know - per region

- **Execution:**
    - **Memory allocation: 128 MB – 10GB (1 MB increments)**
    - **Maximum execution time: 900 seconds (15 minutes)**
    - **Environment variables (4 KB)**
    - **Disk capacity in the “function container” (in /tmp): 512 MB to 10GB - Concurrency executions: 1000 (can be increased)**
- **Deployment:**
    - **Lambda function deployment size (compressed .zip): 50 MB**
    - **Size of uncompressed deployment (code + dependencies): 250 MB**
    - **Can use the /tmp directory to load other files at startup**
    - **Size of environment variables: 4 KB**

### Customization At The Edge

- **Many modern applications execute some form of the logic at the edge**
- Edge Function:
    - A code that you write and attach to CloudFront distributions
    - Runs close to your users to minimize latency
- **CloudFront provides two types: CloudFront Functions & Lambda@Edge**
- You don’t have to manage any servers, deployed globally
- Fully serverless

### CloudFront Functions & Lambda@Edge Use Cases

- Website Security and Privacy
- **Dynamic Web Application at the Edge**
- Search Engine Optimization (SEO)
- Intelligently Route Across Origins and Data Centers - Bot Mitigation at the Edge
- Real-time Image Transformation
- **A/BTesting**
- User Authentication and Authorization
- User Prioritization
- User Tracking and Analytics

### CloudFront Functions

- **Native feature of CloudFront (manage code entirely within CloudFront)**
- **Lightweight functions written in JavaScript**
- **Transform request attributes (headers, cookies, query strings, URL) to create an optimal Cache Key**
- Used to change CloudFront requests and responses:
    - **Viewer Request: after CloudFront receives a request from a viewer**
    - **Viewer Response: before CloudFront forwards the response to the viewer**
- Header manipulation
- Insert/modify/delete HTTP headers in the request or response
- URL rewrites or redirects
- Request authentication & authorization
    - Create and validate user-generated tokens (e.g., JWT) to allow/deny requests

### Lambda@Edge

- **Lambda functions written in NodeJS or Python**
- Scales to 1000s of requests/second
- Used to change CloudFront requests and responses:
    - Viewer Request – after CloudFront receives a request from a
    viewer
    - Origin Request – before CloudFront forwards the request to the origin
    - Origin Response – after CloudFront receives the response from the origin
    - Viewer Response – before CloudFront forwards the response to the viewer
- **Author your functions in one AWS Region (us-east-1), then CloudFront replicates to its locations**
- Longer execution time (several ms)
- Adjustable CPU or memory
- Your code depends on a 3rd libraries (e.g., AWS SDK to access other AWS services)
- Network access to use external services for processing
- File system access or access to the body of HTTP requests

### CloudFront Functions vs. Lambda@Edge - Use Cases

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20137.png)

### Lambda by default

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20138.png)

- **By default, your Lambda function is launched outside your own VPC (in an AWS-owned VPC)**
- **Therefore, it cannot access resources in your VPC (RDS, ElastiCache, internal ELB...)**

### Lambda in VPC

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20139.png)

- **You must define the VPC ID, the Subnets and the Security Groups**
- **Lambda will create an ENI (Elastic Network Interface) in your subnets**

### Lambda with RDS Proxy

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20140.png)

- If Lambda functions directly access your database, they may open too many connections under high load
- **RDS Proxy**
    - Improve scalability by pooling and sharing DB
    connections
    - Improve availability by reducing by 66% the failover time and preserving connections
    - Improve security by enforcing IAM authentication and storing credentials in Secrets Manager
- **The Lambda function must be deployed in your VPC, because RDS Proxy is never publicly accessible**

### Invoking Lambda from RDS & Aurora

- Invoke Lambda functions from within your DB instance
- Allows you to process data events from within a database
- Supported for RDS for PostgreSQL and Aurora MySQL
- Must allow outbound traffic to your Lambda function from within your DB instance (Public, NAT GW,VPC Endpoints)
- DB instance must have the required permissions to invoke the Lambda function (Lambda Resource-based Policy & IAM Policy)

### RDS Event Notifications

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20141.png)

- **Notifications that tells information about the DB instance itself (created, stopped, start, ...)**
- You don’t have any information about the data itself
- Subscribe to the following event categories: DB instance, DB snapshot, DB Parameter Group, DB Security Group, RDS Proxy, Custom Engine Version
- Near real-time events (up to 5 minutes)
- Send notifications to SNS or subscribe to events
using EventBridge

### Amazon DynamoDB

- **Fully managed, highly available with replication across multiple AZs**
- NoSQL database - not a relational database - with transaction support
- Scales to massive workloads, distributed database
- Millions of requests per seconds, trillions of row, 100s of TB of storage - Fast and consistent in performance (single-digit millisecond)
- Integrated with IAM for security, authorization and administration
- Low cost and auto-scaling capabilities
- No maintenance or patching, always available
- Standard & Infrequent Access (IA) Table Class

### DynamoDB - Basics

- **DynamoDB is made of Tables**
- **RDS와 다르게 Column을 매우 쉽게 추가할 수 있다.**
- **Each table has a Primary Key (must be decided at creation time)**
- Each table can have an infinite number of items (= rows)
- Each item has attributes (can be added over time – can be null)
- **Maximum size of an item is 400KB**
- Data types supported are:
    - Scalar Types – String, Number, Binary, Boolean, Null
    - Document Types – List, Map
    - Set Types – String Set, Number Set, Binary Set
- **Therefore, in DynamoDB you can rapidly evolve schemas**

### DynamoDB **– Read/Write Capacity Modes**

- **Provisioned Mode (default)**
    - You specify the number of reads/writes per second
    - You need to plan capacity beforehand
    - Pay for provisioned Read Capacity Units (RCU) & Write Capacity Units (WCU)
    - Possibility to add auto-scaling mode for RCU & WCU
- **On-Demand Mode**
    - Read/writes automatically scale up/down with your workloads
    - No capacity planning needed
    - Pay for what you use, more expensive ($$$)
    - Great for unpredictable workloads, steep sudden spikes

### DynamoDB Accelerator (DAX)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20142.png)

- Fully-managed, highly available, seamless in- memory cache for DynamoDB
- **Help solve read congestion by caching**
- **Microseconds latency for cached data**
- Doesn’t require application logic modification (compatible with existing DynamoDB APIs)
- **5 minutes TTL for cache (default)**

### DynamoDB – Stream Processing

- Ordered stream of item-level modifications (create/update/delete) in a table
- **Use cases:**
    - React to changes in real-time (welcome email to users)
    - Real-time usage analytics
    - Insert into derivative tables
    - Implement cross-region replication
    - Invoke AWS Lambda on changes to your DynamoDB table

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20143.png)

- **두 가지가 있음 Dynamo DB Stream과 Kinesis Data Stream**

**DynamoDB Streams**

- 24 hours retention
- Limited # of consumers
- Process using AWS Lambda Triggers, or DynamoDB Stream Kinesis adapter

**Kinesis Data Streams (newer)**

- 1 year retention
- High # of consumers
- Process using AWS Lambda, Kinesis Data Analytics, Kineis Data Firehose, AWS Glue Streaming ETL...

### DynamoDB Global Tables

- **Make a DynamoDB table accessible with low latency in multiple-regions**
- Active-Active replication
- Applications can READ and WRITE to the table in any region
- Must enable DynamoDB Streams as a pre-requisite

### DynamoDB - Time To Live(TTL)

- **Automatically delete items after an expiry timestamp**
- Use cases: reduce stored data by keeping only current items, adhere to regulatory obligations, **web session handling...**
- Dynamo DB의 TTL을 사용해서 Web Session을 Handling 할 수 있다!
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20144.png)
    

### DynamoDB – Backups for disaster recovery

- **Continuous backups using point-in-time recovery (PITR)**
    - Optionally enabled for the last 35 days
    - Point-in-time recovery to any time within the backup window
    - The recovery process creates a new table
- **On-demand backups**
    - Full backups for long-term retention, until explicitely deleted
    - **Doesn’t affect performance or latency**
    - **Can be configured and managed in AWS Backup (enables cross-region copy)**
    - The recovery process creates a new table

### DynamoDB – Integration with Amazon S3

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20145.png)

**Export to S3 (must enable PITR)**

- Works for any point of time in the last 35 days
- Doesn’t affect the read capacity of your table
- Perform data analysis on top of DynamoDB
- Retain snapshots for auditing
- ETL on top of S3 data before importing back into DynamoDB
- Export in Dynamo DB JSON or ION format

**Import from S3**

- Import CSV, Dynamo DB JSON or ION format
- **Doesn’t consume any write capacity**
- Creates a new table
- Import errors are logged in CloudWatch ㅌLogs

### AWS API Gateway

- **AWS Lambda + API Gateway: No infrastructure to manage**
- Support for the WebSocket Protocol
- Handle API versioning (v1, v2...)
- Handle different environments (dev, test, prod...)
- **Handle security (Authentication and Authorization)**
- Create API keys, handle request throttling
- Swagger / Open API import to quickly define APIs - Transform and validate requests and responses
- Generate SDK and API specifications
- Cache API responses

### API Gateway – Integrations High Level

**Lambda Function**

- Invoke Lambda function
- Easy way to expose REST API backed by AWS Lambda

**HTTP**

- Expose HTTP endpoints in the backend
- Example: internal HTTP API on premise, Application Load Balancer...
- Why? Add rate limiting, caching, user authentications, API keys, etc...

**AWS Service**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20146.png)

- Expose any AWS API through the API Gateway
- Example: start an AWS Step Function workflow, post a message to SQS
- Why? Add authentication, deploy publicly, rate control...

### API Gateway - Endpoint Types

**Edge-Optimized (default): For global clients**

- **Requests are routed through the CloudFront Edge locations (improves latency)**
- The API Gateway still lives in only one region

**Regional:**

- **For clients within the same region**
- Could manually combine with CloudFront (more control over the caching strategies and the distribution)

**Private:**

- Can only be accessed from your VPC using an interface VPC endpoint (ENI)
- Use a resource policy to define access

### API Gateway – Security

**User Authentication through**

- IAM Roles (useful for internal applications)
- Cognito (identity for external users – example mobile users)
- Custom Authorizer (your own logic)

**Custom Domain Name HTTPS** - security through integration with AWS Certificate Manager (ACM)

- **If using Edge-Optimized endpoint, then the certificate must be in us-east-1**
- **If using Regional endpoint, the certificate must be in the API Gateway region**
- **Must setup CNAME or A-alias record in Route 53**

### AWS Step Functions

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20147.png)

- Build serverless visual workflow to orchestrate your Lambda functions
- Features: sequence, parallel, conditions, timeouts, error handling, ...
- Can integrate with EC2, ECS, On-premises servers, API Gateway, SQS queues, etc...
- **Possibility of implementing human approval feature**
- Use cases: order fulfillment, data processing, web applications, any workflow

### Amazon Cognito

- 강의에 없지만 슬라이드에 있으므로 정리..
- **Give users an identity to interact with our web or mobile application**
- **Cognito User Pools:**
    - Sign in functionality for app users
    - Integrate with API Gateway & Application Load Balancer
- **Cognito Identity Pools (Federated Identity):**
    - Provide AWS credentials to users so they can access AWS resources directly
    - Integrate with Cognito User Pools as an identity provider
- Cognito vs IAM: “hundreds of users”, ”mobile users”,“authenticate with SAML”

### Cognito User Pools (CUP) – User Features

- Create a serverless database of user for your web & mobile apps
- Simple login: Username (or email) / password combination
- Password reset
- Email & Phone Number Verification
- Multi-factor authentication (MFA)
- Federated Identities: users from Facebook, Google, SAML...

### Cognito User Pools (CUP) - Integrations

- CUP integrates with API Gateway and Application Load Balancer

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20148.png)

### Cognito Identity Pools (Federated Identities)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20149.png)

- **Get identities for “users” so they obtain temporary AWS credentials**
- Users source can be Cognito User Pools, 3rd party logins, etc...
- Users can then access AWS services directly or through API Gateway
- The IAM policies applied to the credentials are defined in Cognito
- They can be customized based on the user_id for fine grained control
- Default IAM roles for authenticated and guest users

### 문제

Question 7:

엣지 최적화 API 게이트웨이를 사용할 경우, API Gateway가 모든 AWS 리전의 CloudFront 엣지 로케이션에 존재하게 됩니다.
**• 아닙니다**
• 맞습니다

엣지 최적화 API Gateway는 지리적으로 분산된 클라이언트에 가장 적합합니다. API 요청은 가장 가까운 CloudFront 엣지 로케이션으로 라우팅되며, 이는 지연 시간을 향상시킵니다. **API Gateway는 여전히 하나의 AWS 리전에 존재합니다.**

Question 9:

CloudFront 배포를 통해 전역적으로 제공되는 애플리케이션이 있습니다. 인증 요청이 오리진까지 전달되게 하는 대신, CloudFront 엣지 로케이션에서 사용자를 인증하려 합니다. 이 요구 사항을 만족시키기 위해서는 어떤 방법을 사용해야 할까요?
**• Lambda@Edge**
• API Gateway
• DynamoDB
• AWS 글로벌 액셀러레이터

Lambda@Edge는 CloudFront의 기능으로, 사용자에 가깝게 코드를 실행하도록 해주어 성능을 향상시키고 지연 시간을 줄여 줍니다.

Question 13:

여러분이 DevOps 엔지니어로 일하고 있는 축구 회사에는 서버 쪽에 DynamoDB 테이블을 둔 웹 사이트가 있습니다. 현재 시청자 의견에 대한 보고서를 생성하기 위해 분석 팀과 함께 업무를 진행하고 있습니다. 분석 팀은 DynamoDB의 데이터를 JSON 포맷으로 S3 버킷에 호스팅한 다음, 거기서 작업을 시작하고 보고서를 생성하기를 원합니다. DynamoDB 데이터를 JSON 파일로 변환하는 데 가장 적합한 경제적인 방식은 무엇입니까?

**• DynamoDB 테이블을 선택하고 S3로 내보내기를 선택한다.**
• DynamoDB 데이터를 읽는 Lambda 함수를 만들어 JSON 파일로 변환하고 변환된 파일을 S3 버킷에 저장한다.(오답)
• AWS Transfer Family를 사용한다.
• AWS DataSync를 사용한다.

Question 14:

AWS에 호스팅할 예정인 웹 사이트가 현재 개발 진행 중에 있습니다. 이 웹 사이트에는 로그인한 사용자의 사용자 세션과 자동 만료 시간을 저장하고, 만료된 사용자 세션을 삭제해야 한다는 요구 사항이 있습니다. 다음 중 이런 경우에 가장 적합한 AWS 서비스는 무엇입니까?

• 사용자 세션을 S3 버킷에 저장하고 S3 수명 주기 정책을 활성화한다.
• 사용자 세션을 EC2 인스턴스에 로컬로 저장한다.
**• 사용자 세션을 DynamoDB 테이블에 저장하고 TTL을 활성화한다.**
• 사용자 세션을 EFS 파일 시스템에 저장한다.

Question 15:

여러분이 가진 모바일 애플리케이션에서 애플리케이션 사용자에게 S3 버킷에 있는 개인 공간에 액세스할 수 있는 권한을 부여하려고 합니다. 어떻게 해야 합니까?
• 각각의 애플리케이션 사용자에 대해 IAM 사용자 자격 증명 생성한다.
**• Amazon Cognito 아이덴티티 페더레이션을 사용한다.**
• SAML 아이덴티티 페더레이션을 사용한다.
• 버킷 정책을 사용해 버킷을 퍼블릭으로 만든다.

Question 16:

여러분은 AWS에 호스팅할 예정인 새로운 웹 및 모바일 애플리케이션을 개발하고 있으며, 현재 로그인 및 회원 가입 페이지를 구현하는 작업을 진행하고 있습니다. 애플리케이션 백엔드는 서버리스로 되어 있으며 구현에 Lambda, DynamoDB, API Gateway를 사용하고 있습니다. 다음 중 백엔드에 대한 인증을 구성하는 데 가장 쉽고 적합한 방식은 무엇입니까?

• KMS로 암호화된 DynamoDB 테이블에 사용자의 자격 증명을 저장한다.
• KMS로 암호화된 S3 버킷에 사용자의 자격 증명을 저장한다.
**• Cognito 사용자 풀을 사용한다.**
• 사용자 자격 증명을 AWS Secrets Manager에 저장한다.

## Data Analytics & Pipeline

### Amazon Athena

- **Serverless query service to analyze data stored in Amazon S3**
- Uses standard SQL language to query the files **(built on Presto)**
- SupportsCSV,JSON,ORC,Avro,and **Parquet**
- Pricing: $5.00 per TB of data scanned
- **Commonly used with Amazon Quicksight for reporting/dashboards**
- Use cases: Business intelligence / analytics / reporting, analyze & query VPC Flow Logs, ELB Logs, CloudTrail trails, etc...**(Log 분석할 때 자주 사용되는 듯)**
- **Exam Tip: analyze data in S3 using serverless SQL, use Athena**

### Amazon Athena – 성능 향상 방법

- **빅데이터를 지탱하는 기술을 참고하자**
- **Use columnar data for cost-savings (less scan)**
    - **Apache Parquet or ORC is recommended(columnar data를 저장하는게 Parquet, ORC 이기 때문임. )**
    - Huge performance improvement
    - Use Glue to convert your data to Parquet or ORC
- **Compress data** for smaller retrievals (bzip2, gzip, lz4, snappy, zlip, zstd...)
- **Partition datasets** in S3 for easy querying on virtual columns
    - s3://yourBucket/pathToTable /<PARTITION_COLUMN_NAME>=<VALUE>
    /<PARTITION_COLUMN_NAME>=<VALUE> /<PARTITION_COLUMN_NAME>=<VALUE>
    /etc...
    - Example:s3://athena-examples/flight/parquet/year=1991/month=1/day=1/
- **Use larger files (> 128 MB) to minimize overhead**

### Amazon Athena – Federated Query

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20150.png)

- **Allows you to run SQL queries across data stored in relational, non-relational, object, and custom data sources (AWS or on-premises)**
- Uses Data Source Connectors that run on AWS Lambda to run Federated Queries (e.g., CloudWatch Logs, DynamoDB, RDS, ...)
- Store the results back in Amazon S3

### Redshift Overview

- **Redshift is based on PostgreSQL, but it’s not used for OLTP**
    - OLTP(Online Transactional Processing)
    - OLAP(Online Analytical Processing
- **It’s OLAP – online analytical processing (analytics and data warehousing)**
- **10x better performance than other data warehouses, scale to PBs of data**
- Columnar storage of data (instead of row based) & parallel query engine
- Pay as you go based on the instances provisioned
- Has a SQL interface for performing the queries
- BI tools such as Amazon Quicksight or Tableau integrate with it
- **vs Athena: faster queries / joins / aggregations thanks to indexes**

### Redshift Cluster

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20151.png)

- **Leader node:** for query planning, results aggregation
- **Compute node:** for performing the queries, send results to leader
- You provision the node size in advance
- You can used Reserved Instances for cost savings

### Redshift – Snapshots & DR

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20152.png)

- **chatgpt-when you create an Amazon Redshift cluster, it is deployed as a single Availability Zone (AZ) deployment, which means all the data is stored in a single AZ.**
- **However, you can choose to create a multi-AZ deployment for improved availability and durability of your data. A multi-AZ deployment means that your data is automatically replicated to a standby cluster in a different AZ within the same region.**
- **Redshift has “Multi-AZ” mode for some clusters**
- **Snapshots are point-in-time backups of a cluster, stored internally in S3**
- Snapshots are incremental (only what has changed is saved)
- You can restore a snapshot into a new cluster
- Automated: every 8 hours, every 5 GB, or on a
schedule. Set retention between 1 to 35 days - Manual: snapshot is retained until you delete it
- **You can configure Amazon Redshift to automatically copy snapshots (automated or manual) of a cluster to another AWS Region**

### **Loading data into Redshift:Large inserts are MUCH better**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20153.png)

### Redshift Spectrum(잘 모르겠다..)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20154.png)

- Query data that is already in S3 without loading it
- **Must have a Redshift cluster available to start the query**
- The query is then submitted to thousands of Redshift Spectrum nodes

### Amazon OpenSearch Service - 솔직히 왜 써야하는지 모르겠음.

- Amazon OpenSearch is successor to Amazon ElasticSearch
- In DynamoDB, queries only exist by primary key or indexes...
- **With OpenSearch, you can search any field, even partially matches**
- It’s common to use OpenSearch as a complement to another database
- Provision a managed cluster of instances or use OpenSearch Serverless
- Does not natively support SQL (can be enabled via a plugin)
- Ingestion from Kinesis Data Firehose, AWS IoT, and CloudWatch Logs
- Security through Cognito & IAM, KMS encryption,TLS
- Comes with OpenSearch Dashboards (visualization)
- **아래와 같은 패턴들로 사용된다고 함.**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20155.png)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20156.png)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20157.png)

### Amazon EMR

- **EMR stands for “Elastic MapReduce”**
- **EMR helps creating Hadoop clusters (Big Data) to analyze and process vast amount of data**
- The clusters can be made of hundreds of EC2 instances
- EMR comes bundled with Apache Spark, HBase, Presto, Flink...
- EMR takes care of all the provisioning and configuration
- Auto-scaling and integrated with Spot instances
- **Use cases: data processing, machine learning, web indexing, big data...**

### Amazon EMR – Node types & purchasing

- **Master Node:** Manage the cluster, coordinate, manage health – long running
- **Core Node:** Run tasks and store data – long running
- Task Node (optional): Just to run tasks – usually Spot
- Purchasing options:
    - On-demand: reliable, predictable, won’t be terminated
    - Reserved (min 1 year): cost savings (EMR will automatically use if available) - Spot Instances: cheaper, can be terminated, less reliable
- Can have long-running cluster, or transient (temporary) cluster

### Amazon QuickSight - BI Tool

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20158.png)

- **Serverless machine learning-powered business intelligence service to create interactive dashboards**
- Fast, automatically scalable, embeddable, with per-session pricing
- Use cases:
    - Business analytics
    - Building visualizations
    - Perform ad-hoc analysis
    - Get business insights using data
- Integrated with RDS, Aurora, Athena, Redshift, S3...
- **In-memory computation using SPICE engine if data is imported into QuickSight**
- Enterprise edition: Possibility to setup Column-Level security (CLS)

### QuickSight – Dashboard & Analysis

- **Define Users (standard versions) and Groups (enterprise version)**
    - **These users & groups only exist within QuickSight, not IAM !!**
- A dashboard...
    - is a read-only snapshot of an analysis that you can share
    - preserves the configuration of the analysis (filtering, parameters, controls, sort)
- **You can share the analysis or the dashboard with Users or Groups(not same as IAM Role)**
- To share a dashboard, you must first publish it
- Users who see the dashboard can also see the underlying data

### AWS Glue

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20159.png)

- **Managed extract, transform, and load (ETL) service**
- Useful to prepare and transform data for analytics
- **Fully serverless service**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20160.png)

### Glue – things to know at a high-level

- **Glue Job Bookmarks:** prevent re-processing old data
- **Glue Elastic Views:**
    - Combine and replicate data across multiple data stores using SQL
    - No custom code, Glue monitors for changes in the source data, serverless
    - Leverages a “virtual table” (materialized view)
- **Glue DataBrew:** clean and normalize data using pre-built transformation
- **Glue Studio:** new GUI to create, run and monitor ETL jobs in Glue
- **Glue Streaming ETL (built on Apache Spark Structured Streaming)**: compatible with Kinesis Data Streaming, Kafka, MSK (managed Kafka)

### AWS Lake Formation

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20161.png)

- **Data lake = central place to have all your data for analytics purposes**
- Fully managed service that makes it easy to setup a data lake in days
- Discover, cleanse, transform, and ingest data into your Data Lake
- It automates many complex manual steps (collecting, cleansing, moving, cataloging data, ...) and de-duplicate (using ML Transforms)
- Combine structured and unstructured data in the data lake
- **Out-of-the-box source blueprints:** S3, RDS, Relational & NoSQL DB...
- **Fine-grained Access Control for your applications (row and column-level)**
- Built on top of AWS Glue

### **AWS Lake Formation - Centralized Permissions**

- **Data Lake를 쓰는 이유 Centralized Permissions!!!**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20162.png)

### Kinesis Data Analytics (SQL application)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20163.png)

- **Real-time analytics on Kinesis Data Streams & Firehose** **using SQL**
- Add reference data from Amazon S3 to enrich streaming data
- Fully managed, no servers to provision
- Automatic scaling
- Pay for actual consumption rate
- Output:
    - Kinesis Data Streams: create streams out of the real-time analytics queries
    - Kinesis Data Firehose: send analytics query results to destinations
- Use cases:
    - Time-series analytics
    - Real-time dashboards
    - Real-time metrics

### Kinesis Data Analytics for Apache Flink

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20164.png)

- Use Flink (Java, Scala or SQL) to process and analyze streaming data
- Run any Apache Flink application on a managed cluster on AWS
    - provisioning compute resources, parallel computation, automatic scaling
    - application backups (implemented as checkpoints and snapshots)
    - Use any Apache Flink programming features
    - **Flink does not read from Firehose (use Kinesis Analytics for SQL instead)**

### Amazon Managed Streaming for Apache Kafka (Amazon MSK)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20165.png)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20166.png)

- **Alternative to Amazon Kinesis**
- **Fully managed Apache Kafka on AWS**
    - Allow you to create, update, delete clusters
    - MSK creates & manages Kafka brokers nodes & Zookeeper nodes for you
    - **Deploy the MSK cluster in your VPC, multi-AZ (up to 3 for HA)**
    - Automatic recovery from common Apache Kafka failures
    - Data is stored on EBS volumes for as long as you want
- **MSK Serverless**
- Run Apache Kafka on MSK without managing the capacity
- MSK automatically provisions resources and scales compute & storage

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20167.png)

### Big Data Ingestion Pipeline

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20168.png)

### 문제

Question 3:

**솔루션 아키텍트로서 Redshift 클러스터에 대한 재해 복구 계획을 수립하는 업무를 맡았습니다. 어떤 작업을 해야 합니까?**

• 다중 AZ를 활성화한다.
**• 자동 스냅샷을 활성화한 다음, Redshift 클러스터가 스냅샷을 다른 AWS 리전으로 자동 복사하도록 설정한다.**
• 스냅샷을 만들고 Redshift 글로벌 클러스터로 복원한다.

Question 7:

한 회사가 AWS를 사용해 자사의 공용 웹 사이트와 내부 애플리케이션을 호스팅하고 있습니다. 이들 웹 사이트와 애플리케이션에서는 수많은 로그 및 트레이스가 생성됩니다. 로그를 중앙 집중식으로 저장하여 실시간으로 검색하고 분석해 오류와 악의적인 시도를 감지할 수 있도록 만들어야 합니다. 로그를 효율적으로 저장하고 분석하는 데 도움이 되는 AWS 서비스는 무엇입니까?
• Amazon S3
**• Amazon OpenSearch service**
• Amazon ElastiCache
• Amazon QLDB

## Machine Learning

### **Rekognition: face detection, labeling, celebrity recognition**

- Find objects, people, text, scenes in images and videos using ML
- Facial analysis and facial search to do user verification, people counting
- Create a database of “familiar faces” or compare against celebrities
- Use cases:
    - Labeling
    - Content Moderation
    - Text Detection
    - Face Detection and Analysis (gender, age range, emotions...)
    - Face Search and Verification
    - Celebrity Recognition
    - Pathing (ex: for sports game analysis)
- **Amazon Rekognition – Content Moderation**
    - **Detect content that is inappropriate, unwanted, or offensive (image and videos)**
    - Used in social media, broadcast media, advertising, and e-commerce situations to create a safer user experience
    - **Set a Minimum Confidence Threshold for items that will be flagged**
    - Flag sensitive content for manual review in Amazon Augmented AI (A2I)
    - Help comply with regulations

### **Transcribe: audio to text (ex: subtitles)**

- **Automatically convert speech to text**
- Uses a deep learning process called automatic speech recognition (ASR) to convert speech to text quickly and accurately
- **Automatically remove Personally Identifiable Information (PII) using Redaction**
- **Supports Automatic Language Identification for multi-lingual audio**
- Use cases:
    - transcribe customer service calls
    - automate closed captioning and subtitling
    - generate metadata for media assets to create a fully searchable archive

### **Polly: text to audio**

- **Turn text into lifelike speech using deep learning**
- Allowing you to create applications that talk
- Amazon Polly – Lexicon & SSML
    - Customize the pronunciation of words with Pronunciation lexicons
        - Stylized words: St3ph4ne => “Stephane”
        - Acronyms:AWS=>“AmazonWebServices”
    - Upload the lexicons and use them in the SynthesizeSpeech operation
    - Generate speech from plain text or from documents marked up with **Speech
    Synthesis Markup Language (SSML)** – enables more customization
        - emphasizing specific words or phrases
        - using phonetic pronunciation
        - including breathing sounds, whispering
        - using the Newscaster speaking style

### **Translate: translations**

- **Natural and accurate language translation**
- Amazon Translate allows you to localize content - such as websites and applications - for international users, and to easily translate large volumes of text efficiently.

### **Lex: build conversational bots – chatbots**

- **Amazon Lex: (same technology that powers Alexa)**
    - **Speech를 인식한다.**
    - Automatic Speech Recognition (ASR) to convert speech to text
    - Natural Language Understanding to recognize the intent of text, callers
    - Helps build chatbots, call center bots
- **Amazon Connect:**
    - Receive calls, create contact flows, cloud-based vir tual contact center
    - Can integrate with other CRM systems or AWS
    - No upfront payments, 80% cheaper than traditional contact center solutions

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20169.png)

### **Comprehend: natural language processing**

- **For Natural Language Processing – NLP**
- Fully managed and serverless service
- Uses machine learning to find insights and relationships in text - Language of the text
    - **Extracts key phrases, places, people, brands, orevents**
    - Understands how positive or negative the text is
    - Analyzes text using tokenization and parts of speech
    - Automatically organizes a collection of text files by topic
- Sample use cases:
    - analyze customer interactions (emails) to find what leads to a positive or negative experience
    - Create and groups articles by topics that Comprehend will uncover

### Amazon Comprehend Medical

- Amazon Comprehend Medical detects and returns useful information in unstructured clinical text:
    - Physician’s notes
    - Discharge summaries - Test results
    - Case notes
- **Uses NLP to detect Protected Health Information (PHI) – DetectPHI API**
- Store your documents in Amazon S3, analyze real-time data with Kinesis Data Firehose, or use Amazon Transcribe to transcribe patient narratives into text that can be analyzed by Amazon Comprehend Medical.

### **SageMaker: machine learning for every developer and data scientist**

- Fully managed service for developers / data scientists to build ML models - Typically, difficult to do all the processes in one place + provision servers - Machine learning process (simplified): predicting your exam score

### **Forecast: build highly accurate forecasts**

- **Fully managed service that uses ML to deliver highly accurate forecasts - Example: predict the future sales of a raincoat**
- 50% more accurate than looking at the data itself
- Reduce forecasting time from months to hours
- Use cases: Product Demand Planning, Financial Planning, Resource Planning, ...

### **Kendra: ML-powered search engine**

- **Fully managed document search service powered by Machine Learning**
- **Extract answers from within a document (text, pdf, HTML, PowerPoint, MS Word, FAQs...) - Natural language search capabilities**
- Learn from user interactions/feedback to promote preferred results (Incremental Learning) - Ability to manually fine-tune search results (importance of data, freshness, custom, ...)

### **Personalize: real-time personalized recommendations**

- Fully managed ML-service to build apps with real-time personalized recommendations
- Example: personalized product recommendations/re-ranking, customized direct marketing - Example:Userboughtgardeningtools,providerecommendationsonthenextonetobuy
- Same technology used by [Amazon.com](http://amazon.com/)
- Integrates into existing websites, applications, SMS, email marketing systems, ...
- Implement in days, not months (you don’t need to build, train, and deploy ML solutions) - Use cases: retail stores, media and entertainment...

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20170.png)

### **Textract: detect text and data in documents**

- **Automatically extracts text, handwriting, and data from any scanned documents using AI and ML**
- Extract data from forms and tables analyze result
- Read and process any type of document (PDFs, images, ...)
- **Use cases:**
    - Financial Services (e.g., invoices, financial reports)
    - Healthcare (e.g., medical records, insurance claims)
    - Public Sector (e.g., tax forms, ID documents, passports)