# UDemy AWS

## Global Services, Region

### Global Service

- IAM, Route 53, CloudFront, WAF 등
- Region을 선택할 필요가 없음.
- AWS Global infrastructure

### Region-scoped

- EC2, Elastic Beanstalk, Lambda …. 등

### Region

하나의 독립적인 서비스. Data Center의 집합이다. ~~서비스는 리전 크기를 벗어나지 못한다.(리전이 가장 큰 단위이며 그 이상을 초과하는 서비스는 존재하지 않는다.)~~  Global Service는 region을 넘는 서비스이다.

### Region 선택 기준

- compliance : 해당 국가의 법률 준수 여부
- proximity : low latency
- Available Services : 리전마다 제공 가능한 서비스가 다름
- Pricing : 리전마다 가격이 다름

### Availability Zones

- Region에 2 ~ 6 개의  AZ가 존재하며(보통 3개) AZ에는 2 ~ 4개의 Data Center가 존재한다.
- 물리적으로 분리되어 있기 때문에 재난 대비가 가능하다.

### Edge Locations

## IAM

### IAM 이란

- Identity and access management, **Global Service**
- Group으로 권한을 설정할 수 있다. Group 내부에는 사용자만 포함 가능하다.(Group 내부에 Group을 넣는 건 불가능하다.)
- 특정 사용자가 여러 그룹에 속할 수 있다.
- Json으로 권한을 부여한다.
- Least priviledge Principle : 제한된 권한을 제한된 사용자에게 준다.

### IAM Policy(정책)

- inline policy : user에 직접 적용하는 policy
- 직접 만들거나 기존에 있는 정책을 사용할 수 있음

### IAM Multi Factor Authentification(MFA)

- Password + Device = MFA
- virtual MFA Device : google authentificator
- Physical Device : u2f

## EC2

- Bootstrap : launching commands when a machine starts.(Docker의 cmd 맞나. 그거와 같은 기능인듯)
- EC2 Create의 Advanced Details ⇒ User data =  Boot strap이다.

### EC2 종류

- T, M : General Purpose ⇒ 범용 목적
- C : Compute Optimized ⇒ required High performance Cpu
- R,X,M : Memory Optimized
- I, D : Stroage Optimized

### Security Groups = Firewall on EC2

- 기본세팅으로 ec2로 들어오는 모든 Inbound는 통제하고outbound는 통제하지 않는다.
- EC2 외부에 존재하는 것 인만큼 알맞는 방식으로 Security Group 설정을 해야 EC2에 접근할 수 있다.
- EC2로 접속할 때 컴퓨터가 계속해서 대기하는 모습(Timeout 상황)이라면 Security Group 문제 때문이다.
- 허용 단위를 security Group으로도 설정할 수 있다. ex) A라는 EC2의 Security Group에 S1이라는 Security Group을 Inbound Traffic에 허용한다면, S1 Security Group을 사용하는 EC2들 모두는 A와 통신이 가능하게 된다.
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled.png)
    

### Classic Ports

- 22 = SSH(Secure Shell) - log into a linux instance
- 21 = FTP(File Transfer Protocol)
- 22 = SFTP(Secure File Transfer Protocol) - upload files using SSH
- 80 = HTTP
- 443 = HTTPS
- 3389 = RDP(Remote Desktop Protocol) - log into a window instance

### EC2 Purchasing Options

- On-Demand Instances – short workload, predictable pricing, pay by second
- Reserved (1 & 3 years)
• Reserved Instances – long workloads
• Convertible Reserved Instances – long workloads with flexible instances
- Savings Plans (1 & 3 years) –commitment to an amount of usage, long workload • Spot Instances – short workloads, cheap, can lose instances (less reliable)
• Dedicated Hosts – book an entire physical server, control instance placement
• Dedicated Instances – no other customers will share your hardware
- Capacity Reservations – reserve capacity in a specific AZ for any duration
- **EC2 On Demand**
• Pay for what you use:
• Linux or Windows - billing per second, after the first minute • All other operating systems - billing per hour
• Has the highest cost but no upfront payment
• No long-term commitment
• Recommended for short-term and un-interrupted workloads, where you can't predict how the application will behave
- **EC2 Reserved Instances**
• Up to 72% discount compared to On-demand
• You reserve a specific instance attributes (Instance Type, Region,Tenancy, OS)
    
    • Reservation Period – 1 year (+discount) or 3 years (+++discount)
    • Payment Options – No Upfront (+), Partial Upfront (++), All Upfront (+++) 
    
    • Reserved Instance’s Scope – Regional or Zonal (reserve capacity in an AZ)
    • Recommended for steady-state usage applications (think database)
    • You can buy and sell in the Reserved Instance Marketplace
    • Convertible Reserved Instance
    • Can change the EC2 instance type, instance family, OS, scope and tenancy • Up to 66% discount
    
- **EC2 Savings Plans**
• Get a discount based on long-term usage (up to 72% - same as RIs)
    
    • Commit to a certain type of usage ($10/hour for 1 or 3 years)
    • Usage beyond EC2 Savings Plans is billed at the On-Demand price
    • Locked to a specific instance family & AWS region (e.g., M5 in us-east-1)
    • Flexible across:
    
    • Instance Size (e.g., m5.xlarge, m5.2xlarge) • OS (e.g., Linux, Windows)
    • Tenancy (Host, Dedicated, Default)
    
- **EC2 Spot Instances**
• Can get a discount of up to 90% compared to On-demand
• Instances that you can “lose” at any point of time if your max price is less than the current spot price
• The MOST cost-efficient instances in AWS
• Useful for workloads that are resilient to failure
    
    • Batch jobs
    • Data analysis
    • Image processing
    • Any distributed workloads
    • Workloads with a flexible start and end time
    • Not suitable for critical jobs or databases
    

- **EC2 Dedicated Hosts**
• A physical server with EC2 instance capacity fully dedicated to your use
• Allows you address compliance requirements and use your existing server- bound software licenses (per-socket, per-core, pe—VM software licenses)
• Purchasing Options:
    
    • On-demand – pay per second for active Dedicated Host
    • Reserved - 1 or 3 years (No Upfront,Partial Upfront,All Upfront)
    
    • The most expensive option
    • Useful for software that have complicated licensing model (BYOL – Bring Your
    Own License)
    • Or for companies that have strong regulatory or compliance needs
    
- **EC2 Capacity Reservations**
• Reserve On-Demand instances capacity in a specific AZ for any duration
• You always have access to EC2 capacity when you need it
• No time commitment (create/cancel anytime), no billing discounts
• Combine with Regional Reserved Instances and Savings Plans to benefit from billing discounts
• You’re charged at On-Demand rate whether you run instances or not
• Suitable for short-term, uninterrupted workloads that needs to be in a
specific AZ

### Spot Request

- Spot instance 사용하는 옵션, request type을 설정 잘해야함. one-time은 한 번만  persistent는 자동으로  instance를 관리하는 기능임(kubernetes에도 있는 기능인데 이름이 기억나진 않음)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%201.png)

### Spot Fleets

- Spot Request를 통해 만들 수 있다.

## EC2-Network

### Public IP & Private IP

- Public IP : 인터넷에서 접근 가능
- Private IP : 사설 네트워크에서만 적용
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%202.png)
    

### Placement Groups

- EC2를 배치하는 전략
- Cluster—clusters instances into a low-latency group in a single Availability Zone
    - Pros: Great network (10 Gbps bandwidth between instances with Enhanced Networking enabled - recommended)
    • Cons: If the rack fails, all instances fails at the same time
    • Use case:
    • Big Data job that needs to complete fast
    • Application that needs extremely low latency and high network throughput
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%203.png)
    
- Spread—spreads instances across underlying hardware (max 7 instances per group per AZ)
    
    Pros:
    • Can span across Availability
    • Reduced risk is simultaneous failure
    • EC2 Instances are on different physical hardware
    Zones (AZ)
    • Cons:
    • Limited to 7 instances per AZ
    per placement group • Use case:
    • Application that needs to maximize high availability
    • Critical Applications where each instance must be isolated from failure from each other
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%204.png)
    
- Partition—spreads instances across many different partitions (which rely on different sets of racks) within an AZ. Scales to 100s of EC2 instances per group (Hadoop, Cassandra, Kafka)
    - Up to 7 partitions per AZ
    - Can span across multiple AZs in the
    - Up to 100s of EC2 instances
    - The instances in a partition do not share racks with the instances in the other partitions
    - A partition failure can affect many EC2 but won’t affect other partitions
    - EC2 instances get access to the partition information as metadata
    - Use cases: HDFS, HBase, Cassandra, Kafka
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%205.png)
    

### Elastic Network Interfaces(ENI)

- virtual network card
- ENI를 사용해서 네트워크 장애를 쉽게 해결 할 수 있다는데, 이해가 되진 않음.
- ENI에 대한 참고자료(나중에 필요하면 읽자.)
    - [https://aws.amazon.com/ko/blogs/aws/new-elastic-network-interfaces-in-the-virtual-private-cloud/](https://aws.amazon.com/ko/blogs/aws/new-elastic-network-interfaces-in-the-virtual-private-cloud/)

### Instance Stop과 Terminate 차이

- Stop – the data on disk (EBS) is kept intact in the next start
- Terminate – any EBS volumes (root) also set-up to be destroyed is lost

### EC2 Hibernate

- Hibernate = 동면(=겨울잠), 절전
- The in-memory (RAM) state is preserved
- The instance boot is much faster! (the OS is not stopped / restarted)
- Under the hood: the RAM state is written to a file in the root EBS volume
- The root EBS volume must be encrypted
- Use cases:
    - Long-running processing
    - Saving the RAM state
    - Services that take time to initialize
- 원리
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%206.png)
    

EC2 Hibernate – Good to know
• Supported Instance Families – C3, C4, C5, I3, M3, M4, R3, R4,T2,T3, ...
• Instance RAM Size – must be less than 150 GB.
• Instance Size – not supported for bare metal instances.
• AMI – Amazon Linux 2, Linux AMI, Ubuntu, RHEL, CentOS & Windows... • Root Volume – must be EBS, encrypted, not instance store, and large
• Available for On-Demand, Reserved and Spot Instances • An instance can NOT be hibernated more than 60 days

## Elastic Block Store(EBS)

- EC2에서 사용하는 Storage이자 network로 연결
- 같은 AZ에 있는 EC2만 연결 가능함. 다른 AZ에 있는 EC2에 사용하려면 Snapshot을 만들어서 사용해야한다.
- 하나의 EC2에 EBS 여러 개를 사용할 수 있음.

### EBS Snapshots

- 기본 기능

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%207.png)

- 추가 기능
    - EBS Snapshot Archive
    - Recycle Bin for EBS Snapshots
        - Snapshot을 바로 지우지 않고 Recycle Bin에서 삭제되도록 안전 장치를 만드는 서비스
    - Fast Sanpshot Restore(FSR)
- Snapshot을 만든 다음 Create from Snapshot 기능을 사용해 다른 AZ에서 만들 수 있음.

### AMAZON Machine Image(AMI)

- 도커 이미지와 같은 기능인듯

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%208.png)

### EC2 Instance Store

- EC2와 물리적으로 연결된 스토리지
- 고성능 하드웨어 디스크가 필요할 경우 사용한다.

### EBS Volumes come in 6 types

- gp2 / gp3 (SSD): General purpose SSD volume that balances price and performance for a wide variety of workloads
- io1 / io2 (SSD): Highest-performance SSD volume for mission-critical low-latency or high-throughput workloads
- st1 (HDD): Low cost HDD volume designed for frequently accessed, throughput- intensive workloads
- sc1 (HDD): Lowest cost HDD volume designed for less frequently accessed workloads
- EBS Volumes are characterized in Size | Throughput | IOPS (I/O Ops Per Sec) • When in doubt always consult the AWS documentation – it’s good!
- **Only gp2/gp3 and io1/io2 can be used as boot volumes**

### General Purpose SSD

- Cost effective storage, low-latency
- System boot volumes,Virtual desktops, Development and test environments • 1 GiB - 16TiB
- gp3: IOPS를 수동으로 설정 가능
    - Baseline of 3,000 IOPS and throughput of 125 MiB/s
    - Can increase IOPS up to 16,000 and throughput up to 1000 MiB/s independently
- gp2: IOPS와 용량이 연결되어 있음
    - Small gp2 volumes can burst IOPS to 3,000
    - Size of the volume and IOPS are linked, max IOPS is 16,000
    - 3 IOPS per GB, means at 5,334 GB we are at the max IOPS

### Provisioned IOPS (PIOPS) SSD

- IOPS 16000 이상이 필요할 경우
- Critical business applications with sustained IOPS performance Or applications that need more than 16,000 IOPS
- Great for databases workloads (sensitive to storage perf and consistency)
- io1/io2 (4 GiB - 16 TiB):
    - Max PIOPS: 64,000 for Nitro EC2 instances & 32,000 for other
    - Can increase PIOPS independently from storage size
    - io2 have more durability and more IOPS per GiB (at the same price as io1)
    - io2 Block Express (4 GiB – 64 TiB):
        - Sub-millisecond latency
        - Max PIOPS: 256,000 with an IOPS:GiB ratio of 1,000:1
    - **Supports EBS Multi-attach**

### EBS Multi-Attach – io1/io2 family

- **io1/io2 only support EBS Multi-Attach**
- Attach the same EBS volume to multiple EC2 instances in the same AZ
- Each instance has full read & write permissions to the high-performance volume
- Use case:
• Achieve higher application availability in clustered
Linux applications (ex:Teradata)
• Applications must manage concurrent write operations
- **Up to 16 EC2 Instances at a time**
- **Must use a file system that’s cluster-aware** (not
XFS, EXT4, etc...)

### Hard Disk Drives (HDD)

- Cannot be a boot volume
- 125 GiB to 16TiB
- Throughput Optimized HDD (st1)
- Big Data, Data Warehouses, Log Processing • Max throughput 500 MiB/s – max IOPS 500
- Cold HDD (sc1):
• For data that is infrequently accessed
• Scenarios where lowest cost is important
• Max throughput 250 MiB/s – max IOPS 250

### EBS Encryption

- encrypted volume 만들기
    - 방법 1 : EBS를 처음 만들때 encryption 기능을 사용한다.
    - 방법 2 : unencrpyted EBS의 snapshot을 활용해 volume을 새로 생성하는 과정에서 encryption을 활성화해서 만든다.
- encrypted volume snapshot 만들기
    - encrpted volume을 새로 만들어서 스냅샷을 만드는 것 외에는 없다.

### Elastic File System(EFS) = NFS (network file system

- 기본 개념
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%209.png)
    
- **EFS works with EC2 instances in multi-AZ**
- Highly available, scalable, expensive (3x gp2), pay per use
- Use cases: content management, web serving, data sharing,Wordpress
- Uses NFSv4.1 protocol
- Uses security group to control access to EFS
- **Compatible with Linux based AMI (not Windows)**
- Encryption at rest using KMS
- POSIX file system (~Linux) that has a standard file API
- **File system scales automatically, pay-per-use, no capacity planning!**

### EFS 모드

- **EFS Scale**
    - 1000s of concurrent NFS clients, 10 GB+ /s throughput
    - Grow to Petabyte-scale network file system, automatically
- **Performance Mode (set at EFS creation time)**
    - General Purpose (default) – latency-sensitive use cases (web server, CMS, etc...)
    - Max I/O – higher latency, throughput, highly parallel (big data, media processing)
- **Throughput Mode**
    - Bursting – 1TB = 50MiB/s + burst of up to 100MiB/s
    - Provisioned – set your throughput regardless of storage size, ex: 1 GiB/s for 1 TB storage
    - Elastic – automatically scales throughput up or down based on your workloads
    • Up to 3GiB/sforreadsand1GiB/sforwrites
        
        • Usedforunpredictableworkloads
        

### EFS - Storage Tiers

- Standard: for frequently accessed files
- Infrequent access (EFS-IA): cost to retrieve files, lower price to store. Enable EFS-IA with a Lifecycle Policy

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2010.png)

### Storage Class

- Standard: Multi-AZ, great for production
- One Zone: One AZ, great for dev, backup enabled by default, compatible with IA (EFS One Zone-IA)
    - **Over 90% in cost savings**

### EBS vs EFS – Elastic Block Storage

**EBS**

- one instance (except multi-attach io1/io2)
- are locked at the Availability Zone (AZ) level
- gp2: IO increases if the disk size increases
- io1: can increase IO independently

**To migrate an EBS volume across AZ** 

- Take a snapshot
- Restore the snapshot to another AZ
- EBS backups use IO and you shouldn’t run them while your application is handling a lot of traffic
- **Root EBS Volumes of instances get terminated by default if the EC2 instance gets terminated. (you can disable that)**

**EFS**

- **Mounting 100s of instances across AZ**
- EFS share website files (WordPress)
- **Only for Linux Instances (POSIX)**
- EFS has a higher price point than EBS
- Can leverage EFS-IA for cost savings
- Remember : EFS vs EBS vs Instance Store

## Scalability & Availability

**Vertical Scalability**

- Vertical scalability is very common for non
distributed systems, such as a database.
- RDS, ElastiCache are services that can scale
ver tically.
- There’s usually a limit to how much you can
vertically scale (hardware limit)

**Horizontal Scalability** 

- Horizontal scaling implies distributed systems.
- AWS에서는 Scale out / in이라는 용어를 사용함.

**High Availability**

- High availability means running your
application / system in at least 2 data
centers (== Availability Zones)
- The goal of high availability is to survive a data center loss
- The high availability can be passive (for RDS Multi AZ for example)

## Load Balancing

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2011.png)

### Why use a load balancer?

- Spread load across multiple downstream instances
- Expose a single point of access (DNS) to your application
- Seamlessly handle failures of downstream instances
- Do regular health checks to your instancesHealth Checks
• Health Checks are crucial for Load Balancers
• They enable the load balancer to know if instances it forwards traffic to are available to reply to requests
• The health check is done on a port and a route (/health is common)
• If the response is not 200 (OK), then the instance is unhealthy
- Provide SSL termination (HTTPS) for your websites
- Enforce stickiness with cookies
- High availability across zones
- Separate public traffic from private traffic

### Types of load balancer on AWS

- Application Load Balancer (v2 - new generation) – 2016
    - ALB HTTP, HTTPS,WebSocket
- Network Load Balancer (v2 - new generation) – 2017 – NLB
    - TCP,TLS(secureTCP),UDP
- Gateway Load Balancer – 2020 – GWLB
    - Operates at layer 3 (Network layer) – IP Protocol

### Load Balancer Security Groups

- EC2의 Security Group의 Source를 Load Balancer의 Security Group으로 설정해서, Traffic이 Load Balancer를 통해서 들어오게 할 수 있음.

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2012.png)

### Application Load Balacner - HTTP Based Traffic

- Layer 7(HTTP,HTTPS)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2013.png)

### APP Load Balancer의 Target Group 종류

• EC2 instances (can be managed by an Auto Scaling Group) – HTTP 
• ECS tasks (managed by ECS itself) – HTTP
• Lambda functions – HTTP request is translated into a JSON event 
• IP Addresses – must be private IPs

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2014.png)

### Network Load Balancer - TCP & UDP Based

- Network load balancers (Layer 4) allow to:
    - Forward TCP & UDP traffic to your instances
    - Handle millions of request per seconds
    - Less latency ~100 ms (vs 400 ms for ALB)
- **NLB has one static IP per AZ**, and supports assigning Elastic IP (helpful for whitelisting specific IP)
- NLB are used for extreme performance,TCP or UDP traffic
- Not included in the AWS free tier

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2015.png)

### Network Load Balancer - Target Groups

- EC2 instances
- IP Addresses – must be private IPs
- Application Load Balancer
- Health Checks support the TCP, HTTP and HTTPS Protocols

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2016.png)

### Gateway Load Balancer - Layer 3

- IP Packet 검사용으로 사용
- Example: Firewalls, Intrusion Detection and Prevention Systems, Deep Packet Inspection Systems, payload manipulation, …
- Operates at Layer 3 (Network Layer) – IP Packets
- Combines the following functions:
    - Transparent Network Gateway – single entry/exit
    - Load Balancer – distributes traffic to your virtual appliances
- **Uses the GENEVE protocol on port 6081**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2017.png)

### Gateway Load Balancer –Target Groups

- EC2 instances
- IP Addresses – must be private IPs

### Sticky Sessions

- Load Balancer를 사용할 때 client와 특정 instance를 계속 연결시키는 기능
- Application-based Cookies
- Duration-based Cookies

### Cross-Zone Load Balancing

- 기본개념

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2018.png)

- Application Load Balancer
• Enabled by default (can be disabled at the Target Group level)
    
    • No charges for inter AZ data
    
- Network Load Balancer & Gateway Load Balancer
    
    • Disabled by default
    • You pay charges ($) for inter AZ data if enabled
    

### Server Name Indication(SNI)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2019.png)

- **SNI solves the problem of loading multiple SSL certificates onto one web server (to serve multiple websites)**
- It’s a “newer” protocol, and requires the client to indicate the hostname of the target server in the initial SSL handshake
- The server will then find the correct certificate, or return the default one
- Application Load Balancer (v2)
• Supports multiple listeners with multiple SSL certificates
    
    • Uses Server Name Indication (SNI) to make it work
    
- Network Load Balancer (v2)
• Supports multiple listeners with multiple SSL certificates
• Uses Server Name Indication (SNI) to make it work

### Connection Draining

- Instance 연결을 종료하고자 할 때 중단 기간을 둬서 안정적으로 종료할 수 있게 만드는 기능

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2020.png)

### 문제

Question 5:

**Application Load Balancer를 사용해 EC2 인스턴스에서 호스팅된 웹사이트의 트래픽을 분배하고 있습니다. 그런데 여러분의 웹사이트가 Application Load Balancer의 IP 주소인 사설 IPv4 주소에서 들어오는 트래픽만을 확인하고 있는 것으로 나타났습니다. 이런 경우, 웹사이트로 연결된 클라이언트들의 IP 주소를 받으려면 어떻게 해야 할까요?**

Application Load Balancer를 사용하여 EC2 인스턴스에 트래픽을 배분하는 경우, 요청을 받게 되는 IP 주소는 ALB의 사설 IP 주소가 됩니다. 클라이언트의 IP 주소를 받기 위해, ALB는 클라이언트의 IP 주소를 포함하고 있는 X-Forwarded-For라는 헤더를 추가합니다.

Question 9:

**Application Load Balancer는 트래픽을 다른 대상 그룹으로 라우팅할 수 있습니다. 이때 확인할 내용으로 사용할 수 없는 것을 고르세요.**

답 : ALB는 URL 경로, 호스트 이름, HTTP 헤더 및 쿼리 문자열을 기반으로 트래픽을 다른 대상 그룹으로 라우팅할 수 있습니다.

Question 11:

**규정 준수를 위해, 고정된 정적 IP 주소를 최종 사용자에게 노출하여 사용자들이 안정적이고, 규제 기관의 승인을 받은 방화벽 규칙을 작성할 수 있도록 하려 합니다. 이런 경우, 다음 중 어떤 종류의 Elastic Load Balancer를 사용해야 할까요?**

Network Load Balancer는 AZ 당 하나의 정적 IP 주소를 가지며, 여기에 탄력적 IP 주소를 연결할 수 있습니다. Application Load Balancer와 Classic Load Balancer를 정적 DNS 이름으로 사용할 수 있습니다.

## Auto Scaling Group

- ASG are free (you only pay for the underlying EC2 instances)
- ASG Launch Template
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2021.png)
    

### Auto Scaling - CloudWatch Alarms & Scaling

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2022.png)

- Auto Scaling과 CloudWatch가 다이렉트로 연결 되어있음.
- It is possible to scale an ASG based on CloudWatch alarms
- An alarm monitors a metric (such as Average CPU, or a custom metric)
- Metrics such as Average CPU are computed for the overall ASG instances
- Based on the alarm:
• We can create scale-out policies (increase the number of instances)
• We can create scale-in policies (decrease the number of instances)

### Dynamic Scaling Policy

- **Target Tracking Scaling**
• Most simple and easy to set-up
• Example: I want the average ASG CPU to stay at around 40%
- **Simple / Step Scaling**
• When a CloudWatch alarm is triggered (example CPU > 70%), then add 2 units • When a CloudWatch alarm is triggered (example CPU < 30%), then remove 1
- **Scheduled Actions**
• Anticipate a scaling based on known usage patterns
• Example: increase the min capacity to 10 at 5 pm on Fridays

### Predictive Scaling

- Predictive scaling: continuously forecast load and schedule scaling ahead
    - Using Machine Learning

### Good Metrics to scale on

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2023.png)

- **CPUUtilization:** Average CPU utilization across your instances
- **RequestCountPerTarget:** to make sure the number of requests per EC2 instances is stable
- **Average Network In / Out** (if you’re application is network bound)
- Any custom metric (that you push using CloudWatch)

### Scaling Cooldowns

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2024.png)

- After a scaling activity happens, you are in the cooldown period (default 300 seconds)
- During the cooldown period, the ASG will not launch or terminate additional instances (to allow for metrics to stabilize)
- Advice: Use a ready-to-use AMI to reduce configuration time in order to be serving request fasters and reduce the cooldown period

## **Relational Database Service(**RDS)

### Advantage over using RDS versus deploying DB on EC2

- **RDS: Automates setup, operation, and scaling of database in AWS**
- RDS is a managed service:
    - Automated provisioning, OS patching
    - Continuous backups and restore to specific timestamp (Point in Time Restore)!
    - Monitoring dashboards
    - Read replicas for improved read performance
    - **Multi AZ setup for DR (Disaster Recovery)**
    - Maintenance windows for upgrades
    - Scaling capability (vertical and horizontal)
    - **Storage backed by EBS (gp2 or io1)**
    - **BUT you can’t SSH into your instances**

### RDS – Storage Auto Scaling

- Helps you increase storage on your RDS DB instance dynamically
- **When RDS detects you are running out of free database storage, it scales automatically**
- Avoid manually scaling your database storage
- You have to set Maximum Storage Threshold (maximum limit
- Automatically modify storage if:
    - Free storage is less than 10% of allocated storage
    - Low-storage lasts at least 5 minutes
    - 6 hours have passed since last modification
    for DB storage)
    - Useful for applications with unpredictable workloads
    - Supports all RDS database engines (MariaDB, MySQL,PostgreSQL, SQL Server, Oracle)

### RDS Read Replicas for read scalability

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2025.png)

- **Up to 5 Read Replicas**
- **Within AZ, Cross AZ or Cross Region**
- **Replication is ASYNC, so reads are eventually consistent**
- Replicas can be promoted to their own DB
- Applications must update the connection

### RDS Read Replicas – Network Cost

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2026.png)

- In AWS there’s a network cost when data goes from one AZ to another
- **For RDS Read Replicas within the same region, you don’t pay that fee**

### RDS Multi AZ (Disaster Recovery)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2027.png)

- **SYNC replication**
- One DNS name – automatic app
- **failover to standby**
- **Increase availability**
- Failover in case of loss of AZ, loss of network, instance or storage failure
- No manual intervention in apps
- Not used for scaling
- **Note:The Read Replicas be setup as Multi AZ for Disaster Recovery (DR)**

### RDS – From Single-AZ to Multi-AZ

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2028.png)

- **Zero downtime operation (no need to stop the DB)**
- Just click on “modify” for the database
- The following happens internally:
    - A snapshot is taken
    - A new DB is restored from the snapshot in a new AZ
    - Synchronization is established between the two databases

### **RDS Custom**

- **Managed Oracle and Microsoft SQL Server Database with OS and
database customization**

****

## Aurora

- Aurora is a proprietary technology from AWS (not open sourced)
- Postgres and MySQL are both supported as Aurora DB (that means your drivers will work as if Aurora was a Postgres or MySQL database)
- **Aurora is “AWS cloud optimized” and claims 5x performance improvement over MySQL on RDS, over 3x the performance of Postgres on RDS**
- **Aurora storage automatically grows in increments of 10GB, up to 128 TB.**
- **Aurora can have up to 15 replicas and the replication process is faster than MySQL (sub 10 ms replica lag)**
- **Failover in Aurora is instantaneous. It’s HA (High Availability) native.**
- Aurora costs more than RDS (20% more) – but is more efficient

### Aurora High Availability and Read Scaling

- 6 copies of your data across 3 AZ:
    - 4 copies out of 6 needed for writes
    - 3 copies out of 6 need for reads
    - Self healing with peer-to-peer replication
    - Storage is striped across 100s of volumes
- One Aurora Instance takes writes (master)
- Automated failover for master in less than 30 seconds
- Master + up to 15 Aurora Read Replicas serve reads
- Support for Cross Region Replication

### Aurora DB Cluseter

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2029.png)

### Features of Aurora

- Automatic fail-over
- Backup and Recovery
- Isolation and security
- Industry compliance
- Push-button scaling
- Automated Patching with Zero Downtime
- Advanced Monitoring
- Routine Maintenance
- Backtrack: restore data at any point of time without using backups

### Aurora Replicas-Auto Scaling

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2030.png)

### Aurora Specialty

- **Custom Endpoint**
    - Define a subset of Aurora Instances as a Custom Endpoint
    - Example: Run analytical queries on specific replicas
    - **The Reader Endpoint is generally not used after defining Custom Endpoints**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2031.png)
    

- **Serverless**
    - **Automated database instantiation and auto-scaling based on actual usage**
    - Good for infrequent, intermittent or unpredictable workloads
    - No capacity planning needed
    - Pay per second, can be more cost-effective
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2032.png)
    
- **Multi-Master**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2033.png)
    
- **Global Aurora**
    - Aurora Cross Region Read Replicas:
        - Useful for disaster recovery
        - Simple to put in place
    - Aurora Global Database (recommended):
        - 1 Primary Region (read / write)
        - **Up to 5 secondary (read-only) regions, replication lag is less than 1 second**
        - Up to 16 Read Replicas per secondary region
        - Helps for decreasing latency
        - Promoting another region (for disaster recovery) has an RTO of < 1 minute
        - Typical cross-region replication takes less than 1 second
- **Aurora Machine Learning**
    - Enables you to add ML-based predictions to your applications via SQL
    - Simple, optimized, and secure integration between Aurora and AWS ML services

### Backup

- **Restoring a RDS / Aurora backup or a snapshot creates a new database**
- **RDS Backups**
    - Automated backups:
    • Daily full backup of the database (during the backup window)
    • Transaction logs are backed-up by RDS every 5 minutes
    • => ability to restore to any point in time (from oldest backup to 5 minutes ago)
        
        • 1 to 35 days of retention, set 0 to disable automated backups
        
- Manual DB Snapshots
• Manually triggered by the user
• Retention of backup for as long as you want
- Restoring MySQL RDS database from S3
    
    • Create a backup of your on-premises database
    • Store it on Amazon S3 (object storage)
    • Restore the backup file onto a new RDS instance running MySQL
    
- **Trick: in a stopped RDS database, you will still pay for storage. If you plan on stopping it for a long time, you should snapshot & restore instead**
- **Aurora Backup**
    - Automated backups
    • 1 to 35 days (cannot be disabled)
    • point-in-time recovery in that timeframe
    - Manual DB Snapshots
    • Manually triggered by the user
    • Retention of backup for as long as you want
    - Restoring MySQL Aurora cluster from S3
    • Create a backup of your on-premises database using Percona XtraBackup
    • Store the backup file on Amazon S3
    • Restore the backup file onto a new Aurora cluster running MySQL
    - Aurora Database Cloning
    • Create a new Aurora DB Cluster from an existing one
    • Faster than snapshot & restore
    • Uses copy-on-write protocol
    • Initially, the new DB cluster uses the same data volume as the original DB cluster (fast and efficient – no copying is needed)
    • When updates are made to the new DB cluster data, then additional storage is allocated and data is copied to be separated
    • Very fast & cost-effective
    • Useful to create a “staging” database from a “production” database without impacting the production database

### RDS & Aurora Security

- **At-rest encryption:**
    - Database master & replicas encryption using AWS KMS – must be defined as launch time
    - If the master is not encrypted, the read replicas cannot be encrypted
    - To encrypt an un-encrypted database, go through a DB snapshot & restore as encrypted
- **In-flight encryption:** TLS-readybydefault,usetheAWSTLSrootcertificates client-side
- **IAM Authentication:** IAM roles to connect to your database (instead of username/pw)
- **Security Groups:** Control Network access to your RDS / Aurora DB
- **No SSH available except on RDS Custom**
- Audit Logs can be enabled and sent to CloudWatch Logs for longer retention

### RDS Proxy

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2034.png)

- Fully managed database proxy for RDS
- **Allows apps to pool and share DB connections established with the database**
- **Improving database efficiency by reducing the stress on database resources (e.g., CPU, RAM) and minimize open connections (and timeouts)**
- **Serverless, autoscaling, highly available (multi-AZ)**
- Reduced RDS & Aurora failover time by up 66%
- Supports RDS (MySQL, PostgreSQL, MariaDB, MS SQL Server) and Aurora (MySQL, PostgreSQL)
- No code changes required for most apps
- Enforce IAM Authentication for DB, and securely
- store credentials in AWS Secrets Manager
- **RDS Proxy is never publicly accessible (must be accessed from VPC)**

### 문제

Question 4:

**RDS 데이터베이스에 읽기 전용 복제본을 설정해 두었지만, 소셜 미디어 포스트를 업데이트할 시 업데이트가 바로 이루어지지 않는다는 점에 대해 사용자들이 불만을 토로하고 있습니다. 이 경우, 가능성이 있는 원인은 무엇일까요?**
• **애플리케이션에 버그가 존재함**
• **읽기 전용 복제본은 비동기 복제를 지니므로, 사용자들은 최종 일관성만을 읽게 됨**
• **그 대신 다중 AZ를 설정했었어야 함**

답 : 읽기 전용 복제본은 비동기 복제를 지니므로, 사용자들은 최종 일관성만을 읽게 됨

Question 11:

**RDS PostgreSQL 데이터베이스의 특정 리전에서 정전이 발생했을 때 데이터베이스가 신속하게 다른 AWS 리전에서 읽고 쓰는 작업을 할 수 있도록 재해 복구 전략을 수립하려고 합니다. DR 데이터베이스는 가용성이 매우 높아야 합니다. 가장 적합한 방식은 무엇입니까?**

답 : 다른 리전에 읽기 전용 복제본을 만들고 해당 읽기 전용 복제본에서 다중 AZ를 활성화한다.

Question 14:

**암호화되지 않은 RDS DB 인스턴스를 암호화하는 방법은 무엇인가요?**

답 : 암호화되지 않은 RDS DB 인스턴스의 스냅샷을 생성하고, 스냅샷을 복사해 암호화 활성화하기 박스를 체크한 뒤, RDS DB인스턴스를 암호화되지 않은 스냅샷에서 복구하기.

Question 18:**프로덕션에서 실행 중인 한 애플리케이션이 Aurora 클러스터를 데이터베이스로 사용하고 있습니다. 여러분의 개발 팀은 필요할 경우 많은 양의 워크로드를 수행할 수 있는, 스케일이 축소된 애플리케이션에서 애플리케이션의 버전을 실행하려 합니다. 애플리케이션은 대부분의 시간 동안 사용되지 않습니다. CIO는 여러분에게 팀을 도와 비용을 최소화하는 동시에 이를 달성해 줄 것을 요청했습니다. 어떤 방법을 사용해야 할까요?**

답
• Aurora 글로벌 데이터베이스 사용하기
• RDS 데이터베이스 사용하기
**• Aurora 서버리스 사용하기**
• EC2에 Aurora를 실행하고, EC2 인스턴스가 밤에는 차단되도록 하는 스크립트 작성하기

## Elastic Cache

• The same way RDS is to get managed Relational Databases...
• **ElastiCache is to get managed Redis or Memcached**
• Caches are in-memory databases with really high performance, low latency
• Helps reduce load off of databases for read intensive workloads
• Helps make your application stateless
• AWS takes care of OS maintenance / patching, optimizations, setup, configuration, monitoring, failure recovery and backups
• **Using ElastiCache involves heavy application code changes**

### ElastiCache Solution Architecture - DB Cache

• Applications queries ElastiCache, if not available, get from RDS and store in ElastiCache.
• Helps relieve load in RDS
• Cache must have an invalidation strategy to make sure only the most current data is used in there.

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2035.png)

### ElastiCache Solution Architecture – User Session Store

• User logs into any of the application
• The application writes the session data into ElastiCache
• The user hits another instance of our application
• The instance retrieves the data and the user is already logged in

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2036.png)

### **ElastiCache – Redis vs Memcached**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2037.png)

### Cache Security

- **ElastiCache do not supports IAM Authentication for Redis**
- **IAM policies on ElastiCache are only used for AWS API-level security**

### Patterns for Elastic Cache

- **Lazy Loading:** all the read data is cached, data can become stale in cache
- **Write Through:** Adds or update data in the cache when written to a DB (no stale data)
- **Session Store:** store temporary session data in a cache (using TTL features)
- Quote:There are only two hard things in Computer Science: cache invalidation and naming things

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2038.png)

## Route53

### DNS Terminologies

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2039.png)

- **Domain Registrar:** Amazon Route 53, GoDaddy, ...
- **DNS Records:** A, AAAA, CNAME, NS, ...
- **Zone File:** contains DNS records
- **Name Server:** resolves DNS queries (Authoritative or Non-Authoritative)
- **Top Level Domain (TLD)**: .com, .us, .in, .gov, .org, ...
- **Second Level Domain (SLD)**: [amazon.com](http://amazon.com/), [google.com](http://google.com/), ...

### How DNS Works

- Cache TTL을 설정하면 IP address가 바뀌더라도 설정한 기간 동안은 기존 IP address로 접속을 시도함.
- 

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2040.png)

### Route 53 – Records

- How you want to route traffic for a domain
- Each record contains:
    - Domain/subdomain Name – e.g., example.com
    - Record Type – e.g., A or AAAA
    - Value – e.g., 12.34.56.78
    - Routing Policy – how Route 53 responds to queries
    - TTL – amount of time the record cached at DNS Resolvers
- Route 53 supports the following DNS record types:
    - (must know)**A** /AAAA / **CNAME** / **NS**
    - **A:** Map a hostname to IPv4
    - **CNAME:** Map a hostname to another hostname
        
        **CNAME을 쓰기보단 Alias를 쓰는 방법이 더 효과적임.**
        
        • The target is a domain name which must have an A or AAAA record
        • Can’t create a CNAME record for the top node of a DNS namespace (Zone Apex)
        • Example: you can’t create for example.com, but you can create for www.example.com
        
    - **NS**: Name Servers for the Hosted Zone

### CNAME vs Alias

- **AWS Resources (Load Balancer, CloudFront...) expose an AWS hostname**: lb1-1234.us-east-2.elb.amazonaws.com and you want myapp.mydomain.com
- **CNAME:**
    - **Points a hostname to any other hostname**. (app.mydomain.com => blabla.anything.com)
    - ONLY FOR NON ROOT DOMAIN (aka. something.mydomain.com)
- **Alias:**
    - **Points a hostname to an AWS Resource** (app.mydomain.com => blabla.amazonaws.com)
    - Works for ROOT DOMAIN and NON ROOT DOMAIN (aka mydomain.com)
    - **Free of charge**
    - **Native health check**

### Alias

- Maps a hostname to an AWS resource
- An extension to DNS functionality
- Automatically recognizes changes in the resource’s IP addresses
- Unlike CNAME, it can be used for the top node of a DNS namespace (Zone Apex), e.g.: example.com
- **Alias Record is always of type A/AAAA for AWS resources (IPv4 / IPv6)**
- **You can’t set the TTL**
- **Alias Records Targets**
    - **You cannot set an ALIAS record for an EC2 DNS name**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2041.png)
    

### Route 53 – Hosted Zones

- **A container for records that define how to route traffic to a domain and its subdomains**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2042.png)
    
- **Public Hosted Zones** – contains records that specify how to route traffic on the Internet (public domain names) [application1.mypublicdomain.com](http://application1.mypublicdomain.com/)
- **Private Hosted Zones** – contain records that specify how you route traffic within one or more VPCs (private domain names) application1.company.internal
- You pay $0.50 per month per hosted zone

### Route 53 – RecordsTTL (TimeTo Live)

- High TTL – e.g., 24 hr
• Less traffic on Route 53
• Possibly outdated records
- Low TTL – e.g., 60 sec.
• More traffic on Route 53 ($$)
• Records are outdated for less time
• Easy to change records
- Except for Alias records,TTL is mandatory for each DNS record

### **Route 53 – Routing Policies**

- **Don’t get confused by the word *“Routing”***
    
    • It’s not the same as Load balancer routing which routes the traffic
    • DNS does not route any traffic, it only responds to the DNS queries
    
- **Simple**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2043.png)
    
    - **I**f multiple values are returned, a random one is chosen by the client
    - When Alias enabled, specify only one AWS resource
    - Can’t be associated with Health Checks
- **Weighted**
    - Can be associated with Health Checks
    - Assign a weight of 0 to a record to stop sending
    traffic to a resource
    ****
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2044.png)
    
- **Latency based**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2045.png)
    
    - Redirect to the resource that has the least latency close to us
    - Super helpful when latency for users is a priority
    - Latency is based on traffic between users and AWS
    Regions
    - Can be associated with Health Checks (has a failover
    capability)
- **Failover**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2046.png)
    
- **Geolocation**
    - Different from Latency-based!
    - This routing is based on user location Specify location by Continent, Country or by US State (if there’s overlapping, most precise location selected)
    - **Should create a “Default” record (in case there’s no match on location)**
- **Geoproximity (using Route 53 Traffic Flow feature)**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2047.png)
    
- **Multi-Value Answer**
    - **Use when routing traffic to multiple resources**
    - **Multi-Value is not a substitute for having an ELB**

### Health Checks

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2048.png)

- **HTTP Health Checks are only for public resources**
- Health Check => Automated DNS Failover:
    1. **Health checks that monitor an endpoint (application, server, other AWS resource)**
        1. **About 15 global health checkers will check the
        endpoint health**
            
            • Healthy/UnhealthyThreshold–3(default)
            • Interval – 30 sec (can set to 10 sec – higher cost)
            Supported protocol:HTTP, HTTPS and TCP
            • If > 18% of health checkers report the endpoint is
            healthy, Route 53 considers it Healthy. Otherwise, it’s Unhealthy
            • Ability to choose which locations you want Route 53 to use
            
        2. **Configure you router/firewall to allow incoming
        requests from Route 53 Health Checkers**
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2049.png)
        
    2. **Health checks that monitor other health
    checks (Calculated Health Checks)**
        1. Combine the results of multiple Health
        Checks into a single Health Check
        2. You can use OR, AND, or NOT
        Can monitor up to 256 Child Health Checks
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2050.png)
        
        1. 
    3. **Health checks that monitor CloudWatch
    Alarms (full control !!) – e.g., throttles of
    DynamoDB, alarms on RDS, custom metrics,
    ... (helpful for private resources)**
        1. **Route 53 health checkers are outside the
        VPC.**
        2. **They can’t access private endpoints
        (private VPC or on-premises resource)**
        3. You can create a CloudWatch Metric and
        associate a CloudWatch Alarm, then
        create a Health Check that checks the
        alarm itself
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2051.png)
        

## Beanstalk

- **Elastic Beanstalk is a developer centric view of deploying an application on AWS**
- It uses all the component’s we’ve seen before: EC2, ASG, ELB, RDS, ...
- Managed service
    - Automatically handles capacity provisioning, load balancing, scaling, application health monitoring, instance configuration, ...
    - Just the application code is the responsibility of the developer

### Components

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2052.png)

- **Application:** collection of Elastic Beanstalk components (environments,versions, configurations, ...)
- **Application Version:** an iteration of your application code
- **Environment**
    - Collection of AWS resources running an application version (only one application version at a time)
    - Tiers:
        - WebServerEnvironmentTier
            
            ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2053.png)
            
        - WorkerEnvironmentTier
            
            ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2054.png)
            

## S3

- **Many websites use Amazon S3 as a backbon**

### Use Case

- Backup and storage
- Disaster Recovery
- Archive
- Hybrid Cloud storage
- Application hosting
- Media hosting
- Data lakes & big data analytics
- Software delivery
- Static website

### Buckets

- Amazon S3 allows people to store objects (files) in “buckets” (directories)
- **Buckets must have a globally unique name (across all regions all accounts)**
- Buckets are defined at the region level
- **S3 looks like a global service but buckets are created in a region**

### S3 Object - Key

- Objects (files) have a Key
- **The key is the FULL path:**
    - s3://my-bucket/my_file.txt
    - s3://my-bucket/my_folder1/another_folder/my_file.txt
- The key is composed of prefix + object name
    - s3://my-bucket/my_folder1/another_folder/my_file.txt
- **There’s no concept of “directories” within buckets (although the UI will trick you to think otherwise)**

### S3 Object - Contents

- Object values are the content of the body:
    - Max. Object Size is 5TB (5000GB)
    - **If uploading more than 5GB, must use “multi-part upload”**
- **Metadata** (list of text key / value pairs – system or user metadata)
- **Tags** (Unicode key / value pair – up to 10) – useful for security / lifecycle
- **Version ID** (if versioning is enabled)

### Amazon S3 – Security

- **User-Based**
• IAM Policies – which API calls should be allowed for a specific user from IAM
- **Resource-Based**
• Bucket Policies – bucket wide rules from the S3 console - allows cross account 
• Object Access Control List (ACL) – finer grain (can be disabled)
• Bucket Access Control List (ACL) – less common (can be disabled)
- Note: an IAM principal can access an S3 object if
    - The user IAM permissions ALLOW it
    - **OR** the resource policy ALLOWS it
    - **AND** there’s no explicit DENY
- Encryption: encrypt objects in Amazon S3 using encryption keys

### S3 Bucket Policies

- JSON based policies
• Resources: buckets and objects
• Effect: Allow / Deny
• Actions: Set of API to Allow or Deny
• Principal:The account or user to apply the policy to
- **Use S3 bucket for policy to**:
• Grant public access to the bucket
• Force objects to be encrypted at upload
• Grant access to another account (Cross Account)
- **Public Access - use Bucket Policy**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2055.png)
    

### **IAM Permssions**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2056.png)

### **IAM Role**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2057.png)

### Bucket settings for Block Public Access

- **These settings were created to prevent company data leaks**
- I**f you know your bucket should never be public, leave these on**
- Can be set at the account level

### Amazon S3 - Versioning

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2058.png)

- **You can version your files in Amazon S3**
- **Protect against unintended deletes (ability to restore a version)**
- **Easy roll back to previous version**
- Notes:
    - **Any file that is not versioned prior to enabling versioning will have version “null”**
    - Suspending versioning does not delete the previous versions

### Amazon S3 – Replication (CRR & SRR)

- Must enable Versioning in source and destination buckets
- **Cross-Region Replication (CRR)**
- **Same-Region Replication (SRR)**
- Buckets can be in different AWS accounts
- **Copying is asynchronous**
- Must give proper IAM permissions to S3
- Use cases:
    - CRR – compliance, lower latency access, replication across accounts
    - SRR – log aggregation, live replication between production and test accounts

### Amazon S3 – Replication (Notes)

- **After you enable Replication, only new objects are replicated**
- For DELETE operations
    - Can replicate delete markers from source to target (optional setting)
    - Deletions with a version ID are not replicated (to avoid malicious deletes)
- **There is no “chaining” of replication**
    - If bucket 1 has replication into bucket 2, which has replication into bucket 3
    - Then objects created in bucket 1 are not replicated to bucket 3

### S3 Durability and Availability

- **Durability:**
    - High durability (99.999999999%, 11 9’s) of objects across multiple AZ
    - If you store 10,000,000 objects with Amazon S3, you can on average expect to incur a loss of a single object once every 10,000 years
    - Same for all storage classes
- **Availability:**
    - Measures how readily available a service is
    - Varies depending on storage class
    - Example: S3 standard has 99.99% availability = not available 53 minutes a year

### S3 Storage Class Comparision

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2059.png)

### Amazon S3 – Moving between Storage Classes

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2060.png)

- You can transit objects between storage classes
- For infrequently accessed object, move them to Standard IA
- For archive objects that you don’t need fast access to, move them to Glacier or Glacier Deep Archive
- **Moving objects can be automated using a Lifecycle Rules**

### Amazon S3 – Lifecycle Rules

- **Transition Actions** – configure objects to transition to another storage class
    - Move objects to Standard IA class 60 days after creation
    - Move to Glacier for archiving after 6 months
- **Expiration actions** – configure objects to expire (delete) after some time
    - Access log files can be set to delete after a 365 days
    - **Can be used to delete old versions of files (if versioning is enabled)**
    - **Can be used to delete incomplete Multi-Part uploads**
- Rules can be created for a certain prefix (example: s3://mybucket/mp3/*)
- Rules can be created for certain objectsTags (example:Department:Finance)

### Amazon S3 Analytics – Storage Class Analysis

- **Help you decide when to transition objects to the right storage class**
- Recommendations for Standard and Standard IA
- Does NOT work for One-Zone IA or Glacier
- Report is updated daily
- 24 to 48 hours to start seeing data analysis
- **Good first step to put together Lifecycle Rules (or improve them)!**

### **S3 – Requester Pays**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2061.png)

### S3 Event Notifications

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2062.png)

### **S3 Event Notifications with Amazon EventBridge**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2063.png)

### **S3 – Baseline Performance**

- Amazon S3 automatically scales to high request rates, latency 100-200 ms
- **Your application can achieve at least 3,500 PUT/COPY/POST/DELETE**
- **5,500 GET/HEAD requests per second per prefix in a bucket.**

### S3 Performance

- **Multi-Part upload:**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2064.png)
    
    - recommended for files > 100MB,must use for files > 5GB
    - Can help parallelize uploads (speed up transfers)
- **S3 Transfer Acceleration**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2065.png)
    
    - I**ncrease transfer speed by transferring file to an AWS edge location which will forward the data to the S3 bucket in the target region**
    - Compatible with multi-part upload
- **S3 Byte-Range Fetches**
    - Parallelize GETs by requesting specific byte ranges
    - Better resilience in case of failures
    - Can be used to speed up downloads
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2066.png)
        
    - Can be used to retrieve only partial data (for example the head of a file)
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2067.png)
        

### **S3 Select & Glacier Select**

- Retrieve less data using SQL by performing server-side filtering
- **Can filter by rows & columns (simple SQL statements)**
- Less network transfer, less CPU cost client-side

### S3 Batch Operations

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2068.png)

- S3 작업을 일정부분 자동화하기 위한 방법
- Perform bulk operations on existing S3 objects with a single request, example:
    - Modify object metadata & properties
    - Copy objects between S3 buckets
    - Encrypt un-encrypted objects
    - ModifyACLs,tags
    - Restore objects from S3 Glacier
    - Invoke Lambda function to perform custom action on
- A job consists of a list of objects, the action to perform, and optional parameters
- S3 Batch Operations manages retries, tracks progress, sends completion notifications, generate reports ...
- You can use S3 Inventory to get object list and use S3 Select to filter your objects

## S3 - Security

- You can encrypt objects in S3 buckets using one of 4 methods
- Server-Side Encryption (SSE)
    - **Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3) – Enabled by Default**
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2069.png)
        
        - **Encryption using keys handled, managed, and owned by AWS** - Object is encrypted server-side
        - Encryption type is AES-256
        - Must set header "x-amz-server-side-encryption": "AES256"
        - Enabled by default for new buckets & new objects
    - **Server-Side Encryption with KMS Keys stored in AWS KMS (SSE-KMS)**
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2070.png)
        
        - **Encryption using keys handled and managed by AWS KMS (Key Management Service)**
        - KMS advantages: user control + audit key usage using CloudTrail
        - Object is encrypted server side
        - Must set header "x-amz-server-side-encryption": "aws:kms"
        - **SSE-KMS Limitation**
            
            ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2071.png)
            
            - If you use SSE-KMS, you may be impacted by the KMS limits
            - When you upload, it calls the GenerateDataKey KMS API
            - When you download, it calls the Decrypt KMS API
    - **Server-Side Encryption with Customer-Provided Keys (SSE-C)**
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2072.png)
        
        - **Server-Side Encryption using keys fully managed by the customer outside of AWS**
        - Amazon S3 does NOT store the encryption key you provide
        - HTTPS must be used
        - **Encryption key must provided in HTTP headers, for every HTTP request made**
- **Client-Side Encryption**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2073.png)
    
    - **Use client libraries such as Amazon S3 Client-Side Encryption Library**
    - **Clients must encrypt data themselves before sending to Amazon S3**
    - Clients must decrypt data themselves when retrieving from Amazon S3
    - Customer fully manages the keys and encryption cycle
    

### CORS - Cross-Origin Resource Sharing

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2074.png)

- **Origin = scheme (protocol) + host (domain) + port**
    - example: [https://www.example.com](https://www.example.com/) (implied port is 443 for HTTPS, 80 for HTTP)
    - Web Browser based mechanism to allow requests to other origins while
    - Same origin: [**http://example.com/**app1](http://example.com/app1) & [**http://example.com/**app2](http://example.com/app2)
    - Different origins: [http://**www.**example.com](http://www.example.com/) & [http://**other**.example.com](http://other.example.com/)
- **The requests won’t be fulfilled unless the other origin allows for the requests, using CORS Headers (example: Access-Control-Allow-Origin)**

### **Amazon S3 – CORS**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2075.png)

- **If a client makes a cross-origin request on our S3 bucket, we need to enable the correct CORS headers**
- It’s a popular exam question
- You can allow for a specific origin or for * (all origins)

### S3- MFA

- MFA (Multi-Factor Authentication) – force users to generate a code on a device (usually a mobile phone or hardware) before doing important operations on S3
- **MFA will be required to:**
    - **Permanently delete an object version**
    - **Suspend Versioning on the bucket**
- MFA won’t be required to:
    - Enable Versioning
    - List deleted versions
- **To use MFA Delete, Versioning must be enabled on the bucket**
- Only the bucket owner (root account) can enable/disable MFA Delete

### S3 Access Logs

- **For audit purpose, you may want to log all access to S3 buckets**
- Any request made to S3, from any account, authorized or denied, will be logged into another S3 bucket
- That data can be analyzed using data analysis tools...
- **The target logging bucket must be in the same AWS region**
- **Do not set your logging bucket to be the monitored bucket**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2076.png)
    
    - **It will create a logging loop, and your bucket will grow exponentially**

### Amazon S3 – Pre-Signed URLs

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2077.png)

- Generate pre-signed URLs using the S3 Console, AWS CLI or SDK
- URL Expiration
    - S3 Console – 1 min up to 720 mins (12 hours)
    - AWS CLI – configure expiration with --expires-in parameter in seconds (default 3600 secs, max. 604800 secs ~ 168 hours)
- **Users given a pre-signed URL inherit the permissions of the user that generated the URL for GET / PUT**
- Examples:
    - **Allow only logged-in users to download a premium video from your S3 bucket**
    - Allow an ever-changing list of users to download files by generating URLs dynamically
    - **Allow temporarily a user to upload a file to a precise location in your S3 bucket**
    

### S3 Glacier Vault Lock

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2078.png)

- **Adopt a WORM (Write Once Read Many) model**
- Create a Vault Lock Policy
- Lock the policy for future edits
(can no longer be changed or deleted)
- Helpful for compliance and data retention

### S3 Object Lock (versioning must be enabled)

- **Adopt a WORM (Write Once Read Many) model**
- Block an object version deletion for a specified amount of time
- **Retention mode - Compliance:**
    - **Object versions can't be overwritten or deleted by any user, including the root user**
    - Objects retention modes can't be changed, and retention periods can't be shortened
- **Retention mode - Governance:**
    - **Most users can't overwrite or delete an object version or alter its lock settings**
    - **Some users have special permissions to change the retention or delete the object**
- **Retention Period:** protect the object for a fixed period, it can be extended
- **Legal Hold:**
    - protect the object indefinitely, independent from retention period
    - can be freely placed and removed using the s3:PutObjectLegalHold IAM permission

### **S3 – Access Points**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2079.png)

- **Access Points simplify security management for S3 Buckets**
- Each Access Point has:
    - **its own DNS name (Internet Origin or VPC Origin)**
    - an access point policy (similar to bucket policy) – manage security at scale
- **S3 - Access Points**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2080.png)
    
    - **We can define the access point to be accessible only from within the VPC**
    - You must create a VPC Endpoint to access the Access Point (Gateway or Interface Endpoint)
    - The VPC Endpoint Policy must allow access to the target bucket and Access Point

### S3 Object Lambda

- **Use AWS Lambda Functions to change the object before it is retrieved by the caller application**
- **Only one S3 bucket is needed, on top of which we create S3 Access Point and S3 Object Lambda Access Points.**
- **Use Cases:**
    - Redacting personally identifiable information for analytics or non- production environments.
    - Converting across data formats,such as converting XML to JSON.
    - Resizing and watermarking images on the fly using caller-specific details, such as the user who requested the object.

## Global Infrastructure

### Amazon CloudFront

- Content Delivery Network (CDN)
- Improves read performance, content is cached at the edge
- Improves users experience
- 216 Point of Presence globally (edge
locations)
- **DDoS protection (because worldwide), integration with Shield, AWS Web Application Firewall**

### CloudFront – Origins

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2081.png)

- **S3 bucket**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2082.png)
    
    - **For distributing files and caching them at the edge**
    - **Enhanced security with CloudFront Origin Access Control (OAC)**
    - OAC is replacing Origin Access Identity(OAI)
    - CloudFront can be used as an ingress (to upload files to S3)
- **CloudFront vs S3 Cross Region Replication**
    - CloudFront:
        - **Global Edge network**
        - Files are cached for a TTL (maybe a day)
        - Great for static content that must be available everywhere
    - Cross Region Replication:
        - **Must be setup for each region you want replication to happen**
        - Files are updated in near real-time
        - Read only
        - Great for dynamic content that needs to be available at low-latency in few regions
- **Custom Origin (HTTP)**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2083.png)
    
    - Application Load Balancer
    - EC2 instance
    - S3 website (must first enable the bucket as a static S3 website)
    - Any HTTP backend you want

### CloudFront Geo Restriction

- **You can restrict who can access your distribution**
    - **Allowlist:** Allow your users to access your content only if they're in one of the countries on a list of approved countries.
    - **Blocklist:** Prevent your users from accessing your content if they're in one of the countries on a list of banned countries.
- The “country” is determined using a 3rd party Geo-IP database
- Use case: Copyright Laws to control access to content

### CloudFront – Price Classes

- You can reduce the number of edge locations for cost reduction
    - Three price classes:
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2084.png)
        
    1. Price Class All: all regions – best performance
    2. Price Class 200: most regions, but excludes the most expensive regions
    3. Price Class 100: only the least expensive regions

### CloudFront -Cache Invalidations

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2085.png)

- **In case you update the back-end origin, CloudFront doesn’t know about it and will only get the refreshed content after the TTL has expired**
- **However, you can force an entire or partial cache refresh (thus bypassing the TTL) by performing a CloudFront Invalidation**
- You can invalidate all files (*) or a special path (/images/*)

### AWS Global Accelerator

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2086.png)

- **Leverage the AWS internal network to route to your application**
- 2 Anycast IP are created for your application
- The Anycast IP send traffic directly to Edge Locations
- The Edge locations send the traffic to your application
- **Global Accelerator Works with Elastic IP, EC2 instances, ALB, NLB, public or private**
- **Consistent Performance**
    - **Intelligent routing to lowest latency and fast regional failover**
    - No issue with client cache (because the IP doesn’t change)
    - **Internal AWS network**
- **Health Checks**
    - **Global Accelerator performs a health check of your applications**
    - Helps make your application global (failover less than 1 minute for unhealthy) - Great for disaster recovery (thanks to the health checks)
- **Security**
    - **only 2 external IP need to be whitelisted**
    - **DDoS protection thanks to AWS Shield**

### Unicast IP vs Anycast IP

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2087.png)

- **Unicast IP:** one server holds one IP address Client
- **Anycast IP: all servers hold the same IP address and the client is routed to the nearest one**

### AWS Global Accelerator vs CloudFront

- They both use the AWS global network and its edge locations around the world
- Both services integrate with AWS Shield for DDoS protection.
- **CloudFront**
    - **Improves performance for both cacheable content (such as images and videos)**
    - **Dynamic content(such as API acceleration and dynamic site delivery)**
    - Content is served at the edge
- **Global Accelerator**
    - Improves performance for a wide range of applications over TCP or UDP
    - **Proxying packets at the edge to applications running in one or more AWS Regions.**
    - Good fit for non-HTTP use cases,such as gaming(UDP),IoT(MQTT),or VoiceoverIP
    - Good for HTTP use cases that require static IP addresses
    - Good for HTTP use cases that required deterministic,fast regional failover

## **Advanced Storage on AWS**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2088.png)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2089.png)

### Snowball Edge (for data transfers)

- **Physical data transport solution:move TBs or PBs of data in or out of AWS**
- Alternative to moving data over the network (and paying network fees)
- Pay per data transfer job
- Provide block storage and Amazon S3-compatible object storage
- **Snowball Edge Storage Optimized**
    - **80 TB of HDD capacity for block volume and S3 compatible object storage**
- **Snowball Edge Compute Optimized**
    - 42 TB of HDD or 28TB NVMe capacity for block volume and S3 compatible object storage
- **Use cases: large data cloud migrations, disaster recovery**

### AWS Snowcone & Snowcone SSD

- **Small, portable computing, anywhere, rugged & secure, withstands harsh environments**
- Light (4.5 pounds, 2.1 kg)
- Device used for edge computing, storage, and data
transfer
- Snowcone – 8 TB of HDD Storage
- Snowcone SSD – 14 TB of SSD Storage
- Use Snowcone where Snowball does not fit (space- constrained environment)
- Must provide your own battery / cables
- **Can be sent back to AWS offline, or connect it to
internet and use AWS DataSync to send data**

### AWS Snowmobile

- Transfer exabytes of data (1 EB = 1,000 PB = 1,000,000 TBs)
- Each Snowmobile has 100 PB of capacity (use multiple in parallel)
- High security: temperature controlled, GPS, 24/7 video surveillance - Better than Snowball if you transfer more than 10 PB

### What is Edge Computing?

- **Process data while it’s being created on an edge location**
    - **A truck on the road,a ship on the sea,a mining station underground**
- **These locations may have**
    - Limited / no internet access
    - Limited / no easy access to computing power
- **We setup a Snowball Edge / Snowcone device to do edge computing**
- **Use cases of Edge Computing:**
    - Preprocess data
    - Machine learning at the edge
    - Transcoding media streams
- **Eventually (if need be) we can ship back the device to AWS (for transferring data for example)**

### Snow Family – Edge Computing

- Snowcone & Snowcone SSD (smaller)
    - 2 CPUs, 4 GB of memory, wired or wireless access - USB-C power using a cord or the optional battery
- Snowball Edge – Compute Optimized
    - 104 vCPUs, 416 GiB of RAM
    - Optional GPU (useful for video processing or machine learning) - 28 TB NVMe or 42TB HDD usable storage
- Snowball Edge – Storage Optimized
    - Upto 40 vCPUs,80 GiB of RAM, 80TBstorage
    - Object storage clustering available
- All: Can run EC2 Instances & AWS Lambda functions (using AWS IoT Greengrass)
- Long-term deployment options: 1 and 3 years discounted pricing

### AWS OpsHub

- Historically, to use Snow Family devices, you needed a CLI (Command Line Interface tool)
- Today, you can use AWS OpsHub (a software you install on your computer / laptop) to manage your Snow Family Device

### Solution Architecture: Snowball into Glacier

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2090.png)

- **Snowball cannot import to Glacier directly**
- **You must use Amazon S3 first, in combination with an S3 lifecycle policy**

### Amazon FSx

- **Launch 3rd party high-performance file systems on AWS**

### Amazon FSx for Windows (File Server)

- FSx for Windows is a fully managed Windows file system share drive
- **Supports SMB protocol & Windows NTFS**
- Microsoft Active Directory integration,ACLs,user quotas
- **Can be mounted on Linux EC2 instances**
- Supports Microsoft's Distributed File System (DFS) Namespaces (group files across multiple FS)
- Scale up to 10s of GB/s, millions of IOPS, 100s PB of data
- Storage Options:
    - SSD – latency sensitive workloads (databases, media processing, data analytics, ...)
    - HDD – broad spectrum of workloads (home directory, CMS, ...)
- Can be accessed from your on-premises infrastructure (VPN or Direct Connect)
- Can be configured to be Multi-AZ (high availability)
- **Data is backed-up daily to S3**

### Amazon FSx for Lustre

- Lustre is a type of parallel distributed file system, for large-scale computing
- The name Lustre is derived from “Linux” and “cluster
- **Machine Learning, High Performance Computing (HPC)**
- Video Processing, Financial Modeling, Electronic Design Automation
- Scales up to 100s GB/s, millions of IOPS, sub-ms latencies
- Storage Options:
    - SSD – low-latency, IOPS intensive workloads, small & random file operations
    - HDD – throughput-intensive workloads, large & sequential file operations
- Seamless integration with S3
    - Can “read S3” as a file system (through FSx)
    - Can write the output of the computations back to S3 (through FSx)
- Can be used from on-premises servers (VPN or Direct Connect)

### FSx Lustre - File System Deployment Options

- **Scratch File System - short-term processing**
    - **Temporary storage**
    - Data is not replicated (doesn’t persist if file server fails)
    - **High burst (6x faster, 200MBps per TiB)**
    - Usage: short-term processing, optimize
    costs
- **Persistent File System - long-term processing**
    - **Long-term storage**
    - **Data is replicated within same AZ**
    - Replace failed files within minutes
    - Usage: long-term processing, sensitive data

### Amazon FSx for NetApp ONTAP

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2091.png)

- Managed NetApp ONTAP on AWS
- **File System compatible with NFS, SMB, iSCSI protocol**
- Move workloads running on ONTAP or NAS to AWS
- Works with:
    - Linux
    - Windows
    - MacOS
    - VMware Cloud on AWS
    - Amazon Workspaces & AppStream 2.0
    - Amazon EC2, ECS and EKS
- Storage shrinks or grows automatically
- Snapshots,replication,low-cost,compression and data
- **Point-in-time instantaneous cloning (helpful for testing new workloads)**

### Amazon FSx for OpenZFS

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2092.png)

- Managed OpenZFS file system on AWS
- **File System compatible with NFS (v3, v4, v4.1, v4.2)**
- Move workloads running on ZFS to AWS
- Works with:
    - Linux
    - Windows
    - MacOS
    - VMware Cloud on AWS
- **Up to 1,000,000 IOPS with < 0.5ms latency**
- Snapshots, compression and low-cost
- **Point-in-time instantaneous cloning (helpful for testing new workloads)**

### Hybrid Cloud for Storage

- **”hybrid cloud” - Part of your infrastructure is on the cloud - Part of your infrastructure is on-premises**
- **This can be due to**
    - Long cloud migrations
    - Security requirements
    - Compliance requirements
    - IT strategy
- **S3 is a proprietary storage technology (unlike EFS / NFS), so how do you expose the S3 data on-premises?**
    - AWS Storage Gateway!

### AWS Gateway

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2093.png)

### AWS Storage Gateway

- **Bridge between on-premises data and cloud data**
- Use cases:
    - disaster recovery
    - backup & restore
    - tiered storage
    - on-premises cache & low-latency files access
- **S3 File Gateway**
    - **Configured S3 buckets are accessible using the NFS and SMB protocol**
    - **Most recently used data is cached in the file gateway**
    - Supports S3 Standard, S3 StandardIA, S3 OneZoneA, S3 IntelligentTiering
    - Transition to S3 Glacier using a Lifecycle Policy
    - Bucket access using IAM roles for each File Gateway
    - SMB Protocol has integration with Active Directory (AD) for user authentication
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2094.png)
    
- **FSx File Gateway**
    - Native access to Amazon FSx for Windows File Server
    - **Local cache for frequently accessed data**
    - Windows native compatibility (SMB, NTFS, Active Directory...) - Useful for group file shares and home directories
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2095.png)
    
- **Volume Gateway**
    - **Block storage using iSCSI protocol backed by S3**
    - **Backed by EBS snapshots which can help restore on-premises volumes!**
    - **Cached volumes: low latency access to most recent data**
    - **Stored volumes: entire dataset is on premise, scheduled backups to S3**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2096.png)
    
- **Tape Gateway**
    - Some companies have backup processes using physical tapes (!)
    - With Tape Gateway, companies use the same processes but, in the cloud - VirtualTape Library (VTL) backed by Amazon S3 and Glacier
    - Back up data using existing tape-based processes (and iSCSI interface)
    - Works with leading backup software vendors
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2097.png)
    
- **Hardware Appliance**
    - **Using Storage Gateway means you need on-premises virtualization**
    - Otherwise, you can use a Storage Gateway Hardware Appliance
    - You can buy it on [amazon.com](http://amazon.com/)
    - Works with File Gateway,Volume Gateway,
    - Has the required CPU, memory, network, SSD cache resources
    - Helpful for daily NFS backups in small data centers
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2098.png)
    
    ### AWS Transfer Familiy
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%2099.png)
    
    - **A fully-managed service for file transfers into and out of Amazon S3 or Amazon EFS using the FTP protocol**
    - Supported Protocols
        - AWS Transfer for FTP (File Transfer Protocol (FTP))
        - AWS Transfer for FTPS (File Transfer Protocol over SSL (FTPS))
        - AWS Transfer for SFTP (Secure File Transfer Protocol (SFTP))
    - Managed infrastructure, Scalable, Reliable, Highly Available (multi-AZ)
    - Pay per provisioned endpoint per hour + data transfers in GB
    - Store and manage users’ credentials within the service
    - Integrate with existing authentication systems (Microsoft Active Directory, LDAP, Okta, Amazon Cognito, custom)
    - Usage: sharing files, public datasets, CRM, ERP, ...
    
    ### AWS DataSync
    
    - **Move large amount of data to and from**
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20100.png)
        
        - On-premises / other cloud to AWS (NFS, SMB, HDFS, S3 API...) – needs agent
        - AWS to AWS (different storage services) – no agent needed
    - **Can synchronize to:**
        
        ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20101.png)
        
        - Amazon S3 (any storage classes – including Glacier)
        - Amazon EFS
        - Amazon FSx (Windows, Lustre, NetApp, OpenZFS...)
    - **Replication tasks can be scheduled hourly, daily, weekly**
    - File permissions and metadata are preserved (NFS POSIX, SMB...)
    - One agent task can use 10 Gbps, can setup a bandwidth limit

## **AWS Integration & Messaging**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20102.png)

### Amazon SQS

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20103.png)

### SQS – Producing Messages

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20104.png)

- **Produced to SQS using the SDK (SendMessage API)**
- **The message is persisted in SQS until a consumer deletes it**
- Message retention: default 4 days, up to 14 days
- Example: send an order to be processed
    - Order id
    - Customer id
    - Any attributes you want
- SQS standard: unlimited throughput

### SQS – Consuming Messages

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20105.png)

- **Consumers (running on EC2 instances, servers, or AWS Lambda)...**
- **Poll SQS for messages (receive up to 10 messages at a time)**
- Process the messages (example: insert the message into an RDS database)
- **Delete the messages using the DeleteMessage API**

### SQS – Multiple EC2 Instances Consumers

- **SQS with Auto Scaling Group (ASG)**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20106.png)

- **SQS to decouple between application tiers**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20107.png)

- **Consumers receive and process messages in parallel**
- At least once delivery
- Best-effort message ordering
- **Consumers delete messages after processing them**
- We can scale consumers horizontally to improve throughput of processing

### Amazon SQS - Security

- **Encryption:**
    - In-flight encryption using HTTPS API
    - At-rest encryption using KMS keys
    - Client-side encryption if the client wants to perform encryption/decryption itself
- **Access Controls:** IAM policies to regulate access to the SQS API
- **SQS Access Policies (similar to S3 bucket policies)**
    - Useful for cross-account access to SQS queues
    - Useful for allowing other services (SNS, S3...) to write to an SQS queue

### SQS – Message Visibility Timeout

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20108.png)

- After a message is polled by a consumer, it becomes invisible to other consumers
- By default, the “message visibility timeout” is 30 seconds
- That means the message has 30 seconds to be processed
- After the message visibility timeout is over, the message is “visible” in SQS
- If a message is not processed within the visibility timeout, it will be processed twice
- **A consumer could call the ChangeMessageVisibility API to get more time**
- If visibility timeout is high (hours), and consumer crashes, re-processing will take time
- If visibility timeout is too low (seconds), we may get duplicates

### Amazon SQS - Long Polling

- When a consumer requests messages from the queue, it can optionally “wait” for messages to arrive if there are none in the queue
- This is called Long Polling
- **LongPolling decreases the number of API calls made to SQS while increasing the efficiency and reducing latency of your application**
- The wait time can be between 1 sec to 20 sec (20 sec preferable)
- Long Polling is preferable to Short Polling
- Long polling can be enabled at the queue level
or at the API level using WaitTimeSeconds

### Amazon SQS – Standard Queue

- Oldest offering (over 10 years old)
- Fully managed service, used to decouple applications
- Attributes:
    - Unlimited throughput, unlimited number of messages in queue
    - Default retention of messages: 4 days, maximum of 14 days
    - **Low latency (<10 ms on publish and receive)**
    - **Limitation of 256KB per message sent**
- Can have duplicate messages (at least once delivery, occasionally)
- Can have out of order messages (best effort ordering)

### Amazon SQS – FIFO Queue

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20109.png)

- FIFO = First In First Out (ordering of messages in the queue)
- **Limited throughput: 300 msg/s without batching, 3000 msg/s with**
- Exactly-once send capability (by removing duplicates)
- **Messages are processed in order by the consumer**

### SQS as a buffer to database writes

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20110.png)

### Amazon SNS

- **Pub / Sub Pattern**

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20111.png)

- The “event producer” only sends message to one SNS topic
- As many “event receivers” (subscriptions) as we want to listen to the SNS topic notifications
- **Each subscriber to the topic will get all the messages (note: new feature to filter messages)**
- Up to 12,500,000 subscriptions per topic
- 100,000 topics limit

### Amazon SNS – How to publish

- **Topic Publish (using the SDK)**
    - Create a topic
    - Create a subscription (or many)
    - Publish to the topic
- **Direct Publish (for mobile apps SDK)**
    - Create a platform application
    - Create a platform endpoint
    - Publish to the platform endpoint
    - Works with Google GCM, Apple APNS, Amazon ADM...

### Amazon SNS – Security

- **Encryption:**
    - In-flight encryption using HTTPS API
    - At-rest encryption using KMS keys
    - Client-side encryption if the client wants to perform encryption/decryption itself
- **Access Controls:** IAM policies to regulate access to the SNS API
- **SNS Access Policies (similar to S3 bucket policies)**
    - Useful for cross-account access to SNS topics
    - **Useful for allowing other services ( S3...) to write to an SNS topic**

### SNS + SQS: Fan Out

- **Fanout - Chat GPT**
    
    In computer science and distributed systems, the fanout pattern is a messaging pattern where a message is broadcast to multiple recipients simultaneously. The term "fanout" refers to the branching out of a message as it is distributed to multiple recipients, much like the branches of a fan.
    
    In this pattern, a sender sends a single message to a message broker or message queue, which then distributes the message to multiple receivers. Each receiver consumes the message independently, and the sender is not aware of the number of receivers or their identities.
    
    The fanout pattern is commonly used in publish-subscribe messaging systems, where a message is published to a topic and is delivered to all subscribers who have subscribed to that topic. It can also be used in other messaging scenarios where a message needs to be delivered to multiple recipients in a scalable and efficient manner.
    

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20112.png)

- **Push once in SNS, receive in all SQS queues that are subscribers**
- Fully decoupled, no data loss
- SQS allows for: data persistence, delayed processing and retries of work
- Ability to add more SQS subscribers over time
- Make sure your SQS queue access policy allows for SNS to write
- Cross-Region Delivery: works with SQS Queues in other regions

### Application: S3 Events to multiple queues

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20113.png)

- For the same combination of: event type (e.g. object create) and prefix
(e.g. images/) you can only have one S3 Event rule
- If you want to send the same S3 event to many SQS queues, use fan-out

### **Application: SNS to Amazon S3 through Kinesis Data Firehose**

- **SNS can send to Kinesis and therefore we can have the following solutions architecture:**
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20114.png)
    

### FIFO Topic

- FIFO = First In First Out (ordering of messages in the topic)
- Similar features as SQS FIFO:
    - Ordering by Message Group ID (all messages in the same group are ordered)
    - Deduplication using a Deduplication ID or Content Based Deduplication
- **Can only have SQS FIFO queues as subscribers**
- Limited throughput (same throughput as SQS FIFO)

### Message Filtering

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20115.png)

### Kinesis Data Streams

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20116.png)

- **Stream Data Storage라고 보는게 좋을 듯**
- **개별 Shard에 Partition Key와 DataBlob으로 구성 된 Record를 저장한다.**
- Retention between 1 day to 365 days
- Ability to reprocess (replay) data
- Once data is inserted in Kinesis, it can’t be deleted (immutability)
- Data that shares the same partition goes to the same shard (ordering)
- **Producers: AWS SDK, Kinesis Producer Library (KPL), Kinesis Agent**
- **Consumers:**
    - Write your own: Kinesis Client Library (KCL), AWS SDK
    - Managed: AWS Lambda, Kinesis Data Firehose, Kinesis Data Analytics,

### Kinesis Data Streams – Capacity Modes

- **Provisioned mode:**
    - You choose the number of shards provisioned, scale manually or using API
    - **Each shard gets 1MB/s in (or 1000 records per second)**
    - **Each shard gets 2MB/s out (classic or enhanced fan-out consumer)**
    - You pay per shard provisioned per hour
- **On-demand mode:**
    - No need to provision or manage the capacity
    - **Default capacity provisioned (4 MB/s in or 4000 records per second)**
    - Scales automatically based on observed throughput peak during the last 30 days
    - Pay per stream per hour & data in/out per GB

### Kinesis Data Streams Security

- Control access / authorization using IAM policies
- Encryption in flight using HTTPS endpoints
- Encryption at rest using KMS
- You can implement encryption/decryption of data on client side (harder)
- VPC Endpoints available for Kinesis to access within VPC
    
    ![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20117.png)
    
- Monitor API calls using CloudTrail

### Kinesis Firehose

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20118.png)

- **ETL 서비스**
- **주로 Kinesis Data Stream에 저장된 Record를 ETL하여 필요한 서비스에 저장한다.**
- Fully Managed Service, no administration, automatic scaling, serverless - AWS: Redshift / Amazon S3 / OpenSearch
    - 3rd party partner: Splunk / MongoDB / DataDog / NewRelic / ...
    - Custom: send to any HTTP endpoint
    - Pay for data going through Firehose
- **Near Real Time**
    - **60 seconds latency minimum for non full batches**
    - **Or minimum 1MB of data at a time**
- Supports many data formats, conversions, transformations, compression
- Supports custom data transformations using AWS Lambda
- **Can send failed or all data to a backup S3 bucket**

### Kinesis Data Streams vs Firehose

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20119.png)

### Ordering data into kinesis

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20120.png)

- Imagine you have 100 trucks (truck_1, truck_2, ... truck_100) on the road sending their GPS positions regularly into AWS.
- You want to consume the data in order for each truck, so that you can track their movement accurately.
- How should you send that data into Kinesis?
- Answer : send using a “Partition Key” value of the “truck_id”
- **The same key will always go to the same shard**

### Ordering data into SQS

- For SQS standard, there is no ordering.
- For SQS FIFO, if you don’t use a Group ID, messages are consumed in the order they are sent, with only one consumer
- You want to scale the number of consumers, but you want messages to be “grouped” when they are related to each other
- Then you use a Group ID (similar to Partition Key in Kinesis)

### **Kinesis vs SQS ordering**

- **Kinesis Data Streams:**
    - On average you’ll have 20 trucks per shard
    - Trucks will have their data ordered within each shard
    - The maximum amount of consumers in parallel we can have is 5
    - Can receive up to 5 MB/s of data
- **SQS FIFO**
    - You only have one SQS FIFO queue
    - You will have 100 Group ID
    - You can have up to 100 Consumers (due to the 100 Group ID)
    - You have up to 300 messages per second (or 3000 if using batching)

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20121.png)

### Amazon MQ

- SQS, SNS are “cloud-native” services: proprietary protocols from AWS
- **Traditional applications running from on-premises may use open protocols such as:MQTT,AMQP,STOMP,Openwire,WSS**
- When migrating to the cloud, instead of re-engineering the application to use SQS and SNS, we can use Amazon MQ
- **Amazon MQ is a managed message broker service for**
- Amazon MQ doesn’t “scale” as much as SQS / SNS
- Amazon MQ runs on servers, can run in Multi-AZ with failover
- Amazon MQ has both queue feature (~SQS) and topic features (~SNS)

### Amazon MQ - High Availability

![Untitled](UDemy%20AWS%202b59be6a38524858b63a4b507501541a/Untitled%20122.png)